{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcdfea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from dataloaders import *\n",
    "from util import Config\n",
    "from viz_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b644810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC-6-BERT\n",
      "Loading TREC-6 -- ada -- BERT\n",
      "Loading TREC-6 -- ada-besov -- BERT\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"MRPC\", \"TREC-2\", \"SUBJ\", \"AGN-2\", \"TREC-6\", \"AGN-4\", \"SST\"]\n",
    "dataset_map = {\n",
    "    \"TREC-2\": \"TREC-2\",\n",
    "    \"SUBJ\": \"SUBJ\",\n",
    "    \"AGN-2\": \"AGN-2\",\n",
    "    \"TREC-6\": \"TREC-full\",\n",
    "    \"SST\": \"SST\",\n",
    "    \"COLA\": \"COLA\",\n",
    "    \"AGN-4\": \"ag_news-full\",\n",
    "}\n",
    "models = [\"BERT\", \"ELECTRA\"]\n",
    "load_anti = False\n",
    "n = 0  # AL step at which evaluation (AUC) starts\n",
    "model = \"BERT\"\n",
    "mode = \"ada\"\n",
    "dataset = \"TREC-6\"\n",
    "\n",
    "aucs = []\n",
    "trs = []\n",
    "try:\n",
    "    experiments, meta = load_results(\n",
    "        base_dir=f\"results/\",\n",
    "        dataset=dataset,\n",
    "        model=model,\n",
    "    )\n",
    "except:\n",
    "    print(f\"No experiments for {dataset}-{model}-{mode}\")\n",
    "for load_mode in [\"last\", \"best\"]:\n",
    "    if mode == \"short\" and load_mode == \"best\":\n",
    "        continue\n",
    "    mode_print = mode if load_mode == \"last\" else f\"{mode}-besov\"\n",
    "    print(f\"Loading {dataset} -- {mode_print} -- {model}\")\n",
    "    df_tr_i = results_to_df(experiments, mode=load_mode)\n",
    "\n",
    "    df_tr_i[\"model\"] = model\n",
    "    df_tr_i[\"mode\"] = mode_print\n",
    "    df_tr_i[\"dataset\"] = dataset\n",
    "    df_tr_i = df_tr_i.reset_index().set_index(\n",
    "        [\"dataset\", \"model\", \"mode\", \"sampler\", \"experiment\", \"al_iter\"]\n",
    "    )\n",
    "    trs.append(df_tr_i)\n",
    "\n",
    "    df_auc_i = al_auc(df_tr_i)\n",
    "    df_auc_i[\"mode\"] = mode_print\n",
    "    df_auc_i = df_auc_i.reset_index().set_index([\"mode\", \"sampler\"])\n",
    "    aucs.append(df_auc_i)\n",
    "\n",
    "\n",
    "# plot_besov_index(df_tr, ci=0)\n",
    "# plot_al_accuracy(df_tr, metric=\"f1_micro\", ci=0)\n",
    "df_tr = pd.concat(trs)\n",
    "df_auc = pd.concat(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2b3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 1000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"ada-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"test_accuracy\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=95,\n",
    "    linewidth=3,\n",
    ")\n",
    "# plt.legend(loc='lower right')\n",
    "g.set_ylim(0.89, 0.98)\n",
    "g.set_xlim(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5628051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>labeled</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>sampler</th>\n",
       "      <th>experiment</th>\n",
       "      <th>al_iter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">TREC-2</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">ada-besov</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">random</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.657703</td>\n",
       "      <td>0.674897</td>\n",
       "      <td>0.674897</td>\n",
       "      <td>0.673964</td>\n",
       "      <td>[1549, 1546, 1179, 111, 561, 1832, 619, 56, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.662511</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.701160</td>\n",
       "      <td>[364, 841, 941, 922, 152, 1904, 903, 450, 447,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.651112</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.691073</td>\n",
       "      <td>[142, 543, 930, 872, 865, 1646, 95, 589, 513, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>0.633320</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>[1630, 1187, 1237, 1552, 682, 1424, 357, 178, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.642351</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>[499, 1225, 1423, 438, 1077, 1637, 566, 1410, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>14</th>\n",
       "      <td>800</td>\n",
       "      <td>0.658221</td>\n",
       "      <td>0.775720</td>\n",
       "      <td>0.775720</td>\n",
       "      <td>0.771635</td>\n",
       "      <td>[1416, 1090, 83, 524, 1923, 1278, 1293, 882, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>850</td>\n",
       "      <td>0.649009</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.806466</td>\n",
       "      <td>[1763, 240, 1153, 246, 1013, 1552, 1818, 1850,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>900</td>\n",
       "      <td>0.659438</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>[168, 1248, 1598, 714, 784, 1841, 1253, 1873, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>950</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.818820</td>\n",
       "      <td>[1455, 1577, 1788, 1880, 1023, 1458, 1126, 791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.648496</td>\n",
       "      <td>0.816872</td>\n",
       "      <td>0.816872</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>[1606, 456, 1572, 1407, 57, 1461, 463, 294, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    labeled  train_loss  \\\n",
       "dataset model mode      sampler experiment al_iter                        \n",
       "TREC-2  BERT  ada-besov random  0          0            100    0.657703   \n",
       "                                           1            150    0.662511   \n",
       "                                           2            200    0.651112   \n",
       "                                           3            250    0.633320   \n",
       "                                           4            300    0.642351   \n",
       "...                                                     ...         ...   \n",
       "                        entropy 4          14           800    0.658221   \n",
       "                                           15           850    0.649009   \n",
       "                                           16           900    0.659438   \n",
       "                                           17           950    0.656500   \n",
       "                                           18          1000    0.648496   \n",
       "\n",
       "                                                    test_accuracy  f1_micro  \\\n",
       "dataset model mode      sampler experiment al_iter                            \n",
       "TREC-2  BERT  ada-besov random  0          0             0.674897  0.674897   \n",
       "                                           1             0.709877  0.709877   \n",
       "                                           2             0.695473  0.695473   \n",
       "                                           3             0.738683  0.738683   \n",
       "                                           4             0.732510  0.732510   \n",
       "...                                                           ...       ...   \n",
       "                        entropy 4          14            0.775720  0.775720   \n",
       "                                           15            0.806584  0.806584   \n",
       "                                           16            0.800412  0.800412   \n",
       "                                           17            0.818930  0.818930   \n",
       "                                           18            0.816872  0.816872   \n",
       "\n",
       "                                                    f1_macro  \\\n",
       "dataset model mode      sampler experiment al_iter             \n",
       "TREC-2  BERT  ada-besov random  0          0        0.673964   \n",
       "                                           1        0.701160   \n",
       "                                           2        0.691073   \n",
       "                                           3        0.738194   \n",
       "                                           4        0.732143   \n",
       "...                                                      ...   \n",
       "                        entropy 4          14       0.771635   \n",
       "                                           15       0.806466   \n",
       "                                           16       0.799964   \n",
       "                                           17       0.818820   \n",
       "                                           18       0.816853   \n",
       "\n",
       "                                                                                             selected  \n",
       "dataset model mode      sampler experiment al_iter                                                     \n",
       "TREC-2  BERT  ada-besov random  0          0        [1549, 1546, 1179, 111, 561, 1832, 619, 56, 51...  \n",
       "                                           1        [364, 841, 941, 922, 152, 1904, 903, 450, 447,...  \n",
       "                                           2        [142, 543, 930, 872, 865, 1646, 95, 589, 513, ...  \n",
       "                                           3        [1630, 1187, 1237, 1552, 682, 1424, 357, 178, ...  \n",
       "                                           4        [499, 1225, 1423, 438, 1077, 1637, 566, 1410, ...  \n",
       "...                                                                                               ...  \n",
       "                        entropy 4          14       [1416, 1090, 83, 524, 1923, 1278, 1293, 882, 1...  \n",
       "                                           15       [1763, 240, 1153, 246, 1013, 1552, 1818, 1850,...  \n",
       "                                           16       [168, 1248, 1598, 714, 784, 1841, 1253, 1873, ...  \n",
       "                                           17       [1455, 1577, 1788, 1880, 1023, 1458, 1126, 791...  \n",
       "                                           18       [1606, 456, 1572, 1407, 57, 1461, 463, 294, 12...  \n",
       "\n",
       "[475 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf138bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>labeled</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>model</th>\n",
       "      <th>sampler</th>\n",
       "      <th>experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"25\" valign=\"top\">TREC-2</th>\n",
       "      <th rowspan=\"25\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"25\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">core_set</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6469762802124024, 0.636...</td>\n",
       "      <td>[0.6748971193415638, 0.551440329218107, 0.5452...</td>\n",
       "      <td>[0.6748971193415638, 0.551440329218107, 0.5452...</td>\n",
       "      <td>[0.6739639945652174, 0.45776695054045197, 0.44...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6821997761726379, 0.616...</td>\n",
       "      <td>[0.6748971193415638, 0.49588477366255146, 0.56...</td>\n",
       "      <td>[0.6748971193415638, 0.49588477366255146, 0.56...</td>\n",
       "      <td>[0.6708333333333334, 0.3350830657545721, 0.486...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6754907011985779, 0.601...</td>\n",
       "      <td>[0.6152263374485597, 0.5061728395061729, 0.5, ...</td>\n",
       "      <td>[0.6152263374485597, 0.5061728395061729, 0.5, ...</td>\n",
       "      <td>[0.6121904696881121, 0.36681649403947625, 0.34...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6158845901489258, 0.592...</td>\n",
       "      <td>[0.5555555555555556, 0.49794238683127573, 0.49...</td>\n",
       "      <td>[0.5555555555555556, 0.49794238683127573, 0.49...</td>\n",
       "      <td>[0.4830601953986763, 0.33955622883621456, 0.33...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6353173375129699, 0.6251...</td>\n",
       "      <td>[0.49176954732510286, 0.49382716049382713, 0.4...</td>\n",
       "      <td>[0.49176954732510286, 0.49382716049382713, 0.4...</td>\n",
       "      <td>[0.3296551724137931, 0.3305785123966942, 0.339...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dal</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6642346858978272, 0.663...</td>\n",
       "      <td>[0.6748971193415638, 0.6604938271604939, 0.666...</td>\n",
       "      <td>[0.6748971193415638, 0.6604938271604939, 0.666...</td>\n",
       "      <td>[0.6739639945652174, 0.6492540251151437, 0.648...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6488877415657044, 0.636...</td>\n",
       "      <td>[0.6748971193415638, 0.6893004115226338, 0.703...</td>\n",
       "      <td>[0.6748971193415638, 0.6893004115226338, 0.703...</td>\n",
       "      <td>[0.6708333333333334, 0.6868489888925396, 0.699...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.651800012588501, 0.6412...</td>\n",
       "      <td>[0.6152263374485597, 0.7078189300411523, 0.713...</td>\n",
       "      <td>[0.6152263374485597, 0.7078189300411522, 0.713...</td>\n",
       "      <td>[0.6121904696881121, 0.7060216739367502, 0.706...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6310327291488648, 0.683...</td>\n",
       "      <td>[0.5555555555555556, 0.6851851851851852, 0.716...</td>\n",
       "      <td>[0.5555555555555556, 0.6851851851851852, 0.716...</td>\n",
       "      <td>[0.4830601953986763, 0.6752514510571208, 0.715...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6481092929840088, 0.6514...</td>\n",
       "      <td>[0.49176954732510286, 0.654320987654321, 0.703...</td>\n",
       "      <td>[0.49176954732510286, 0.654320987654321, 0.703...</td>\n",
       "      <td>[0.3296551724137931, 0.6377318306859525, 0.703...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6654908657073975, 0.656...</td>\n",
       "      <td>[0.6748971193415638, 0.6728395061728395, 0.699...</td>\n",
       "      <td>[0.6748971193415638, 0.6728395061728395, 0.699...</td>\n",
       "      <td>[0.6739639945652174, 0.6620084242018659, 0.698...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6613013267517089, 0.672...</td>\n",
       "      <td>[0.6748971193415638, 0.6008230452674898, 0.707...</td>\n",
       "      <td>[0.6748971193415638, 0.6008230452674898, 0.707...</td>\n",
       "      <td>[0.6708333333333334, 0.5784343533704148, 0.697...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6476762533187866, 0.629...</td>\n",
       "      <td>[0.6152263374485597, 0.7119341563786008, 0.563...</td>\n",
       "      <td>[0.6152263374485597, 0.7119341563786008, 0.563...</td>\n",
       "      <td>[0.6121904696881121, 0.6991989248262569, 0.490...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6380608439445495, 0.643...</td>\n",
       "      <td>[0.5555555555555556, 0.7016460905349794, 0.646...</td>\n",
       "      <td>[0.5555555555555556, 0.7016460905349794, 0.646...</td>\n",
       "      <td>[0.4830601953986763, 0.6958658996059679, 0.637...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.642036247253418, 0.67306...</td>\n",
       "      <td>[0.49176954732510286, 0.7160493827160493, 0.68...</td>\n",
       "      <td>[0.49176954732510286, 0.7160493827160493, 0.68...</td>\n",
       "      <td>[0.3296551724137931, 0.7139127764127764, 0.689...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy_dropout</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6431065201759338, 0.632...</td>\n",
       "      <td>[0.6748971193415638, 0.5267489711934157, 0.707...</td>\n",
       "      <td>[0.6748971193415638, 0.5267489711934157, 0.707...</td>\n",
       "      <td>[0.6739639945652174, 0.425531914893617, 0.7068...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6572281002998352, 0.609...</td>\n",
       "      <td>[0.6748971193415638, 0.6954732510288066, 0.520...</td>\n",
       "      <td>[0.6748971193415638, 0.6954732510288066, 0.520...</td>\n",
       "      <td>[0.6708333333333334, 0.6904352017628426, 0.392...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6576382756233216, 0.652...</td>\n",
       "      <td>[0.6152263374485597, 0.7222222222222222, 0.722...</td>\n",
       "      <td>[0.6152263374485597, 0.7222222222222222, 0.722...</td>\n",
       "      <td>[0.6121904696881121, 0.7212296318327633, 0.712...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6216179490089416, 0.625...</td>\n",
       "      <td>[0.5555555555555556, 0.6213991769547325, 0.724...</td>\n",
       "      <td>[0.5555555555555556, 0.6213991769547325, 0.724...</td>\n",
       "      <td>[0.4830601953986763, 0.5993548387096774, 0.722...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6512132883071899, 0.6700...</td>\n",
       "      <td>[0.49176954732510286, 0.6625514403292181, 0.62...</td>\n",
       "      <td>[0.49176954732510286, 0.6625514403292181, 0.62...</td>\n",
       "      <td>[0.3296551724137931, 0.6558133107629591, 0.598...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">random</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6625113010406494, 0.651...</td>\n",
       "      <td>[0.6748971193415638, 0.7098765432098766, 0.695...</td>\n",
       "      <td>[0.6748971193415638, 0.7098765432098766, 0.695...</td>\n",
       "      <td>[0.6739639945652174, 0.7011604530171343, 0.691...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6732913494110108, 0.649...</td>\n",
       "      <td>[0.6748971193415638, 0.5987654320987654, 0.730...</td>\n",
       "      <td>[0.6748971193415638, 0.5987654320987654, 0.730...</td>\n",
       "      <td>[0.6708333333333334, 0.5652173913043478, 0.730...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6374668717384339, 0.640...</td>\n",
       "      <td>[0.6152263374485597, 0.5534979423868313, 0.547...</td>\n",
       "      <td>[0.6152263374485597, 0.5534979423868313, 0.547...</td>\n",
       "      <td>[0.6121904696881121, 0.48521723850107634, 0.46...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6433198928833008, 0.631...</td>\n",
       "      <td>[0.5555555555555556, 0.6090534979423868, 0.730...</td>\n",
       "      <td>[0.5555555555555556, 0.6090534979423868, 0.730...</td>\n",
       "      <td>[0.4830601953986763, 0.589527027027027, 0.7304...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6340792775154114, 0.6493...</td>\n",
       "      <td>[0.49176954732510286, 0.588477366255144, 0.722...</td>\n",
       "      <td>[0.49176954732510286, 0.588477366255144, 0.722...</td>\n",
       "      <td>[0.3296551724137931, 0.5326293924182102, 0.721...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          labeled  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    dal             0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    entropy         0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    entropy_dropout 0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    random          0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "\n",
       "                                                                                       train_loss  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6577029973268509, 0.6469762802124024, 0.636...   \n",
       "                                    1           [0.6459900438785553, 0.6821997761726379, 0.616...   \n",
       "                                    2           [0.6794537752866745, 0.6754907011985779, 0.601...   \n",
       "                                    3           [0.6245803534984589, 0.6158845901489258, 0.592...   \n",
       "                                    4           [0.650259718298912, 0.6353173375129699, 0.6251...   \n",
       "                    dal             0           [0.6577029973268509, 0.6642346858978272, 0.663...   \n",
       "                                    1           [0.6459900438785553, 0.6488877415657044, 0.636...   \n",
       "                                    2           [0.6794537752866745, 0.651800012588501, 0.6412...   \n",
       "                                    3           [0.6245803534984589, 0.6310327291488648, 0.683...   \n",
       "                                    4           [0.650259718298912, 0.6481092929840088, 0.6514...   \n",
       "                    entropy         0           [0.6577029973268509, 0.6654908657073975, 0.656...   \n",
       "                                    1           [0.6459900438785553, 0.6613013267517089, 0.672...   \n",
       "                                    2           [0.6794537752866745, 0.6476762533187866, 0.629...   \n",
       "                                    3           [0.6245803534984589, 0.6380608439445495, 0.643...   \n",
       "                                    4           [0.650259718298912, 0.642036247253418, 0.67306...   \n",
       "                    entropy_dropout 0           [0.6577029973268509, 0.6431065201759338, 0.632...   \n",
       "                                    1           [0.6459900438785553, 0.6572281002998352, 0.609...   \n",
       "                                    2           [0.6794537752866745, 0.6576382756233216, 0.652...   \n",
       "                                    3           [0.6245803534984589, 0.6216179490089416, 0.625...   \n",
       "                                    4           [0.650259718298912, 0.6512132883071899, 0.6700...   \n",
       "                    random          0           [0.6577029973268509, 0.6625113010406494, 0.651...   \n",
       "                                    1           [0.6459900438785553, 0.6732913494110108, 0.649...   \n",
       "                                    2           [0.6794537752866745, 0.6374668717384339, 0.640...   \n",
       "                                    3           [0.6245803534984589, 0.6433198928833008, 0.631...   \n",
       "                                    4           [0.650259718298912, 0.6340792775154114, 0.6493...   \n",
       "\n",
       "                                                                                    test_accuracy  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6748971193415638, 0.551440329218107, 0.5452...   \n",
       "                                    1           [0.6748971193415638, 0.49588477366255146, 0.56...   \n",
       "                                    2           [0.6152263374485597, 0.5061728395061729, 0.5, ...   \n",
       "                                    3           [0.5555555555555556, 0.49794238683127573, 0.49...   \n",
       "                                    4           [0.49176954732510286, 0.49382716049382713, 0.4...   \n",
       "                    dal             0           [0.6748971193415638, 0.6604938271604939, 0.666...   \n",
       "                                    1           [0.6748971193415638, 0.6893004115226338, 0.703...   \n",
       "                                    2           [0.6152263374485597, 0.7078189300411523, 0.713...   \n",
       "                                    3           [0.5555555555555556, 0.6851851851851852, 0.716...   \n",
       "                                    4           [0.49176954732510286, 0.654320987654321, 0.703...   \n",
       "                    entropy         0           [0.6748971193415638, 0.6728395061728395, 0.699...   \n",
       "                                    1           [0.6748971193415638, 0.6008230452674898, 0.707...   \n",
       "                                    2           [0.6152263374485597, 0.7119341563786008, 0.563...   \n",
       "                                    3           [0.5555555555555556, 0.7016460905349794, 0.646...   \n",
       "                                    4           [0.49176954732510286, 0.7160493827160493, 0.68...   \n",
       "                    entropy_dropout 0           [0.6748971193415638, 0.5267489711934157, 0.707...   \n",
       "                                    1           [0.6748971193415638, 0.6954732510288066, 0.520...   \n",
       "                                    2           [0.6152263374485597, 0.7222222222222222, 0.722...   \n",
       "                                    3           [0.5555555555555556, 0.6213991769547325, 0.724...   \n",
       "                                    4           [0.49176954732510286, 0.6625514403292181, 0.62...   \n",
       "                    random          0           [0.6748971193415638, 0.7098765432098766, 0.695...   \n",
       "                                    1           [0.6748971193415638, 0.5987654320987654, 0.730...   \n",
       "                                    2           [0.6152263374485597, 0.5534979423868313, 0.547...   \n",
       "                                    3           [0.5555555555555556, 0.6090534979423868, 0.730...   \n",
       "                                    4           [0.49176954732510286, 0.588477366255144, 0.722...   \n",
       "\n",
       "                                                                                         f1_micro  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6748971193415638, 0.551440329218107, 0.5452...   \n",
       "                                    1           [0.6748971193415638, 0.49588477366255146, 0.56...   \n",
       "                                    2           [0.6152263374485597, 0.5061728395061729, 0.5, ...   \n",
       "                                    3           [0.5555555555555556, 0.49794238683127573, 0.49...   \n",
       "                                    4           [0.49176954732510286, 0.49382716049382713, 0.4...   \n",
       "                    dal             0           [0.6748971193415638, 0.6604938271604939, 0.666...   \n",
       "                                    1           [0.6748971193415638, 0.6893004115226338, 0.703...   \n",
       "                                    2           [0.6152263374485597, 0.7078189300411522, 0.713...   \n",
       "                                    3           [0.5555555555555556, 0.6851851851851852, 0.716...   \n",
       "                                    4           [0.49176954732510286, 0.654320987654321, 0.703...   \n",
       "                    entropy         0           [0.6748971193415638, 0.6728395061728395, 0.699...   \n",
       "                                    1           [0.6748971193415638, 0.6008230452674898, 0.707...   \n",
       "                                    2           [0.6152263374485597, 0.7119341563786008, 0.563...   \n",
       "                                    3           [0.5555555555555556, 0.7016460905349794, 0.646...   \n",
       "                                    4           [0.49176954732510286, 0.7160493827160493, 0.68...   \n",
       "                    entropy_dropout 0           [0.6748971193415638, 0.5267489711934157, 0.707...   \n",
       "                                    1           [0.6748971193415638, 0.6954732510288066, 0.520...   \n",
       "                                    2           [0.6152263374485597, 0.7222222222222222, 0.722...   \n",
       "                                    3           [0.5555555555555556, 0.6213991769547325, 0.724...   \n",
       "                                    4           [0.49176954732510286, 0.6625514403292181, 0.62...   \n",
       "                    random          0           [0.6748971193415638, 0.7098765432098766, 0.695...   \n",
       "                                    1           [0.6748971193415638, 0.5987654320987654, 0.730...   \n",
       "                                    2           [0.6152263374485597, 0.5534979423868313, 0.547...   \n",
       "                                    3           [0.5555555555555556, 0.6090534979423868, 0.730...   \n",
       "                                    4           [0.49176954732510286, 0.588477366255144, 0.722...   \n",
       "\n",
       "                                                                                         f1_macro  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6739639945652174, 0.45776695054045197, 0.44...   \n",
       "                                    1           [0.6708333333333334, 0.3350830657545721, 0.486...   \n",
       "                                    2           [0.6121904696881121, 0.36681649403947625, 0.34...   \n",
       "                                    3           [0.4830601953986763, 0.33955622883621456, 0.33...   \n",
       "                                    4           [0.3296551724137931, 0.3305785123966942, 0.339...   \n",
       "                    dal             0           [0.6739639945652174, 0.6492540251151437, 0.648...   \n",
       "                                    1           [0.6708333333333334, 0.6868489888925396, 0.699...   \n",
       "                                    2           [0.6121904696881121, 0.7060216739367502, 0.706...   \n",
       "                                    3           [0.4830601953986763, 0.6752514510571208, 0.715...   \n",
       "                                    4           [0.3296551724137931, 0.6377318306859525, 0.703...   \n",
       "                    entropy         0           [0.6739639945652174, 0.6620084242018659, 0.698...   \n",
       "                                    1           [0.6708333333333334, 0.5784343533704148, 0.697...   \n",
       "                                    2           [0.6121904696881121, 0.6991989248262569, 0.490...   \n",
       "                                    3           [0.4830601953986763, 0.6958658996059679, 0.637...   \n",
       "                                    4           [0.3296551724137931, 0.7139127764127764, 0.689...   \n",
       "                    entropy_dropout 0           [0.6739639945652174, 0.425531914893617, 0.7068...   \n",
       "                                    1           [0.6708333333333334, 0.6904352017628426, 0.392...   \n",
       "                                    2           [0.6121904696881121, 0.7212296318327633, 0.712...   \n",
       "                                    3           [0.4830601953986763, 0.5993548387096774, 0.722...   \n",
       "                                    4           [0.3296551724137931, 0.6558133107629591, 0.598...   \n",
       "                    random          0           [0.6739639945652174, 0.7011604530171343, 0.691...   \n",
       "                                    1           [0.6708333333333334, 0.5652173913043478, 0.730...   \n",
       "                                    2           [0.6121904696881121, 0.48521723850107634, 0.46...   \n",
       "                                    3           [0.4830601953986763, 0.589527027027027, 0.7304...   \n",
       "                                    4           [0.3296551724137931, 0.5326293924182102, 0.721...   \n",
       "\n",
       "                                                                                         selected  \n",
       "dataset model model sampler         experiment                                                     \n",
       "TREC-2  BERT  BERT  core_set        0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    dal             0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    entropy         0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    entropy_dropout 0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    random          0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.groupby([\"dataset\", \"model\", \"model\", \"sampler\", \"experiment\"]).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa2b72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr.groupby([\"dataset\", \"model\", \"model\", \"sampler\", \"experiment\"]).agg(list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f7c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from podium import Vocab, Field, LabelField, Iterator  # , BucketIterator\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.datasets.hf import HFDatasetConverter\n",
    "from podium.vectorizers import GloVe\n",
    "from podium.utils.general_utils import repr_type_and_attrs\n",
    "\n",
    "from typing import Iterator as PythonIterator\n",
    "from typing import NamedTuple, Tuple\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from util import Config\n",
    "\n",
    "\n",
    "class BucketIterator(Iterator):\n",
    "    \"\"\"\n",
    "    Creates a bucket iterator which uses a look-ahead heuristic to batch\n",
    "    examples in a way that minimizes the amount of necessary padding.\n",
    "\n",
    "    Uses a bucket of size N x batch_size, and sorts instances within the bucket\n",
    "    before splitting into batches, minimizing necessary padding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset=None,\n",
    "        batch_size=32,\n",
    "        sort_key=None,\n",
    "        shuffle=True,\n",
    "        seed=1,\n",
    "        matrix_class=np.array,\n",
    "        internal_random_state=None,\n",
    "        look_ahead_multiplier=100,\n",
    "        bucket_sort_key=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates a BucketIterator with the given bucket sort key and look-ahead\n",
    "        multiplier (how many batch_sizes to look ahead when sorting examples for\n",
    "        batches).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        look_ahead_multiplier : int\n",
    "            Multiplier of ``batch_size`` which determines the size of the\n",
    "            look-ahead bucket.\n",
    "            If ``look_ahead_multiplier == 1``, then the BucketIterator behaves\n",
    "            like a normal Iterator.\n",
    "            If ``look_ahead_multiplier >= (num_examples / batch_size)``, then\n",
    "            the BucketIterator behaves like a normal iterator that sorts the\n",
    "            whole dataset.\n",
    "            Default is ``100``.\n",
    "            The callable object used to sort examples in the bucket.\n",
    "            If ``bucket_sort_key=None``, then the ``sort_key`` must not be ``None``,\n",
    "            otherwise a ``ValueError`` is raised.\n",
    "            Default is ``None``.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If sort_key and bucket_sort_key are both None.\n",
    "        \"\"\"\n",
    "\n",
    "        if sort_key is None and bucket_sort_key is None:\n",
    "            raise ValueError(\n",
    "                \"For BucketIterator to work, either sort_key or \"\n",
    "                \"bucket_sort_key must be != None.\"\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            sort_key=sort_key,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            matrix_class=matrix_class,\n",
    "            internal_random_state=internal_random_state,\n",
    "        )\n",
    "\n",
    "        self.bucket_sort_key = bucket_sort_key\n",
    "        self.look_ahead_multiplier = look_ahead_multiplier\n",
    "\n",
    "    def __iter__(self) -> PythonIterator[Tuple[NamedTuple, NamedTuple]]:\n",
    "        step = self.batch_size * self.look_ahead_multiplier\n",
    "        dataset = self._dataset\n",
    "\n",
    "        # Fix: Shuffle dataset if the shuffle is turned on, only IF sort key is not none\n",
    "        if self._shuffle and self._sort_key is None:\n",
    "            indices = list(range(len(dataset)))\n",
    "            # Cache state prior to shuffle so we can use it when unpickling\n",
    "            self._shuffler_state = self.get_internal_random_state()\n",
    "            self._shuffler.shuffle(indices)\n",
    "            # dataset.shuffle_examples(random_state=self._shuffler_state)\n",
    "            dataset = dataset[indices]\n",
    "\n",
    "        # Determine the step where iteration was stopped for lookahead & within bucket\n",
    "        lookahead_start = (\n",
    "            self.iterations // self.look_ahead_multiplier * self.look_ahead_multiplier\n",
    "        )\n",
    "        batch_start = self.iterations % self.look_ahead_multiplier\n",
    "\n",
    "        if self._sort_key is not None:\n",
    "            dataset = dataset.sorted(key=self._sort_key)\n",
    "        for i in range(lookahead_start, len(dataset), step):\n",
    "            bucket = dataset[i : i + step]\n",
    "\n",
    "            if self.bucket_sort_key is not None:\n",
    "                bucket = bucket.sorted(key=self.bucket_sort_key)\n",
    "\n",
    "            for j in range(batch_start, len(bucket), self.batch_size):\n",
    "                batch_dataset = bucket[j : j + self.batch_size]\n",
    "                batch = self._create_batch(batch_dataset)\n",
    "\n",
    "                yield batch\n",
    "                self._iterations += 1\n",
    "\n",
    "        # prepare for new epoch\n",
    "        self._iterations = 0\n",
    "        self._epoch += 1\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        attrs = {\n",
    "            \"batch_size\": self._batch_size,\n",
    "            \"epoch\": self._epoch,\n",
    "            \"iteration\": self._iterations,\n",
    "            \"shuffle\": self._shuffle,\n",
    "            \"look_ahead_multiplier\": self.look_ahead_multiplier,\n",
    "        }\n",
    "        return repr_type_and_attrs(self, attrs, with_newlines=True)\n",
    "\n",
    "\n",
    "class TokenizerVocabWrapper:\n",
    "    def __init__(self, tokenizer):\n",
    "        # wrap BertTokenizer so the method signatures align with podium\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def get_padding_index(self):\n",
    "        return self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenizer)\n",
    "\n",
    "    def numericalize(self, instance):\n",
    "        # Equivalent to .encode, but I want to delineate the steps\n",
    "        return self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(instance))\n",
    "\n",
    "\n",
    "def load_embeddings(vocab, name=\"glove\"):\n",
    "    if name == \"glove\":\n",
    "        glove = GloVe()\n",
    "        embeddings = glove.load_vocab(vocab)\n",
    "        return embeddings\n",
    "    else:\n",
    "        raise ValueError(f\"Wrong embedding key provided {name}\")\n",
    "\n",
    "\n",
    "def make_iterable(dataset, device, batch_size=32, train=False, indices=None):\n",
    "    \"\"\"\n",
    "    Construct a DataLoader from a podium Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def instance_length(instance):\n",
    "        raw, tokenized = instance.text\n",
    "        return -len(tokenized)\n",
    "\n",
    "    def cast_to_device(data):\n",
    "        return torch.tensor(np.array(data), device=device)\n",
    "\n",
    "    # Selects examples at given indices to support subset iteration.\n",
    "    if indices is not None:\n",
    "        dataset = dataset[indices]\n",
    "\n",
    "    # iterator = BucketIterator(\n",
    "    #     dataset,\n",
    "    #     batch_size=batch_size,\n",
    "    #     sort_key=instance_length,\n",
    "    #     shuffle=train,\n",
    "    #     matrix_class=cast_to_device,\n",
    "    #     look_ahead_multiplier=20,\n",
    "    # )\n",
    "\n",
    "    iterator = Iterator(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=train,\n",
    "        matrix_class=cast_to_device,\n",
    "    )\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "class Instance:\n",
    "    def __init__(self, index, text, label, extras=None):\n",
    "        self.index = index\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.extras = extras\n",
    "        self.length = len(text)  # text is already tokenized & filtered\n",
    "\n",
    "    def set_mask(self, masked_text, masked_labels):\n",
    "        # Set the masking as an attribute\n",
    "        self.masked_text = masked_text\n",
    "        self.masked_labels = masked_labels\n",
    "\n",
    "    def set_numericalized(self, indices, target):\n",
    "        self.numericalized_text = indices\n",
    "        self.numericalized_label = target\n",
    "        self.length = len(indices)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.index}: {self.length}, {self.label}\"\n",
    "\n",
    "\n",
    "def generate_eraser_rationale_mask(tokens, evidences):\n",
    "    mask = torch.zeros(len(tokens))  # zeros for where you can attend to\n",
    "\n",
    "    any_evidence_left = False\n",
    "    for ev in evidences:\n",
    "        if ev.start_token > len(tokens) or ev.end_token > len(tokens):\n",
    "            continue  # evidence out of span\n",
    "\n",
    "        if not any_evidence_left:\n",
    "            any_evidence_left = True\n",
    "        # 1. Validate\n",
    "\n",
    "        assert ev.text == \" \".join(\n",
    "            tokens[ev.start_token : ev.end_token]\n",
    "        ), \"Texts dont match; did you filter some tokens?\"\n",
    "\n",
    "        mask[ev.start_token : ev.end_token] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def load_tse(\n",
    "    train_path=\"data/TSE/train.csv\", test_path=\"data/TSE/test.csv\", max_size=20000\n",
    "):\n",
    "\n",
    "    vocab = Vocab(max_size=max_size)\n",
    "    fields = [\n",
    "        Field(\"id\", numericalizer=None),\n",
    "        Field(\"text\", numericalizer=vocab, include_lengths=True),\n",
    "        Field(\"rationale\", numericalizer=vocab),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "    train_dataset = TabularDataset(\n",
    "        train_path, format=\"csv\", fields=fields, skip_header=True\n",
    "    )\n",
    "    test_dataset = TabularDataset(\n",
    "        test_path, format=\"csv\", fields=fields, skip_header=True\n",
    "    )\n",
    "    train_dataset.finalize_fields()\n",
    "    return (train_dataset, test_dataset), vocab\n",
    "\n",
    "\n",
    "class MaxLenHook:\n",
    "    def __init__(self, max_len):\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, raw, tokenized):\n",
    "        return raw, tokenized[: self.max_len]\n",
    "\n",
    "\n",
    "def lowercase_hook(raw, tokenized):\n",
    "    return raw, [tok.lower() for tok in tokenized]\n",
    "\n",
    "\n",
    "def isalnum(token):\n",
    "    return any(c.isalnum() for c in token)\n",
    "\n",
    "\n",
    "def remove_nonalnum(raw, tokenized):\n",
    "    # Remove non alphanumeric tokens\n",
    "    return raw, [tok for tok in tokenized if isalnum(tok)]\n",
    "\n",
    "\n",
    "def load_imdb(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/IMDB\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_isear(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/ISEAR\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_agn2(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/AGN-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_agn4(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/AGN-4\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_mnli(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/MNLI\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_mrpc(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/MRPC\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_qqp(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/QQP\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def test_load_cola(meta, tok):\n",
    "    splits, vocab = load_cola(meta, tok)\n",
    "    print(vocab)\n",
    "    train, valid, test = splits\n",
    "    print(len(train), len(valid), len(test))\n",
    "\n",
    "    print(train)\n",
    "    print(train[0])\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_iter = make_iterable(test, device, batch_size=2)\n",
    "    batch = next(iter(train_iter))\n",
    "\n",
    "    print(batch)\n",
    "    text, length = batch.text\n",
    "    print(length[0])\n",
    "    print(vocab.get_padding_index())\n",
    "\n",
    "\n",
    "def load_sequence_pair_dataset(\n",
    "    data_dir, meta, tokenizer=None, max_vocab_size=20_000, max_seq_len=200\n",
    "):\n",
    "\n",
    "    # Use BERT subword tokenization\n",
    "    vocab = TokenizerVocabWrapper(tokenizer)\n",
    "    print(vocab.get_padding_index())\n",
    "    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    fields = [\n",
    "        Field(\"id\", disable_batch_matrix=True),\n",
    "        Field(\n",
    "            \"sequence1\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "        Field(\n",
    "            \"sequence2\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "\n",
    "    train = TabularDataset(\n",
    "        os.path.join(data_dir, \"train.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    val = TabularDataset(\n",
    "        os.path.join(data_dir, \"validation.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    test = TabularDataset(\n",
    "        os.path.join(data_dir, \"test.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "\n",
    "    train.finalize_fields()\n",
    "\n",
    "    meta.vocab = vocab\n",
    "    meta.num_tokens = len(vocab)\n",
    "    meta.padding_idx = vocab.get_padding_index()\n",
    "    meta.num_labels = len(train.field(\"label\").vocab)\n",
    "\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    data_dir, meta, tokenizer=None, max_vocab_size=20_000, max_seq_len=200\n",
    "):\n",
    "\n",
    "    # Use BERT subword tokenization\n",
    "    vocab = TokenizerVocabWrapper(tokenizer)\n",
    "    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    fields = [\n",
    "        Field(\"id\", disable_batch_matrix=True),\n",
    "        Field(\n",
    "            \"text\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "#         LabelField(\"label\"),\n",
    "    ]\n",
    "\n",
    "    train = TabularDataset(\n",
    "        os.path.join(data_dir, \"train.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    val = TabularDataset(\n",
    "        os.path.join(data_dir, \"validation.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    test = TabularDataset(\n",
    "        os.path.join(data_dir, \"test.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "\n",
    "    train.finalize_fields()\n",
    "\n",
    "    meta.vocab = vocab\n",
    "    meta.num_tokens = len(vocab)\n",
    "    meta.padding_idx = vocab.get_padding_index()\n",
    "    meta.num_labels = len(train.field(\"label\").vocab)\n",
    "\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def load_sst(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_dataset(\n",
    "        \"data/GLUE/SST-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def test_load_sst(max_vocab_size=20_000, max_seq_len=200):\n",
    "    splits, vocab = load_sst()\n",
    "    print(vocab)\n",
    "    train, valid, test = splits\n",
    "    print(len(train), len(valid), len(test))\n",
    "\n",
    "    print(train)\n",
    "    print(train[0])\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_iter = make_iterable(train, device, batch_size=2)\n",
    "    batch = next(iter(train_iter))\n",
    "\n",
    "    print(batch)\n",
    "    text, length = batch.text\n",
    "    print(vocab.reverse_numericalize(text[0]))\n",
    "    print(length[0])\n",
    "    print(vocab.get_padding_index())\n",
    "\n",
    "\n",
    "def load_trec2(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/TREC-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_trec6(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/TREC-6\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_cola(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/GLUE/COLA\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_polarity(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/POL\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_subj(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/SUBJ\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_trec_hf(label=\"label-coarse\", max_vocab_size=20_000, max_seq_len=200):\n",
    "    vocab = Vocab(max_size=max_vocab_size)\n",
    "    fields = [\n",
    "        Field(\n",
    "            \"text\",\n",
    "            numericalizer=vocab,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[MaxLenHook(max_seq_len)],\n",
    "            keep_raw=True,\n",
    "        ),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "    hf_dataset = load_dataset(\"trec\")\n",
    "    hf_dataset = hf_dataset.rename_column(label, \"label\")\n",
    "    print(hf_dataset)\n",
    "    hf_train_val, hf_test = (\n",
    "        hf_dataset[\"train\"],\n",
    "        hf_dataset[\"test\"],\n",
    "    )\n",
    "    train_val_conv = HFDatasetConverter(hf_train_val, fields=fields)\n",
    "    test_conv = HFDatasetConverter(hf_test, fields=fields)\n",
    "    train_val, test = (\n",
    "        train_val_conv.as_dataset(),\n",
    "        test_conv.as_dataset(),\n",
    "    )\n",
    "    train, val = train_val.split(split_ratio=0.8, random_state=0)\n",
    "    train.finalize_fields()\n",
    "    print(train)\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def add_ids_to_files(root_folder):\n",
    "    split_ins = [\"train_old.csv\", \"dev_old.csv\", \"test_old.csv\"]\n",
    "    split_outs = [\"train.csv\", \"dev.csv\", \"test.csv\"]\n",
    "\n",
    "    for split_in, split_out in zip(split_ins, split_outs):\n",
    "        with open(os.path.join(root_folder, split_in), \"r\") as infile:\n",
    "            with open(os.path.join(root_folder, split_out), \"w\") as outfile:\n",
    "                for idx, line in enumerate(infile):\n",
    "                    parts = line.strip().split(\",\")\n",
    "                    if idx == 0:\n",
    "                        continue\n",
    "                    outfile.write(f\"{idx-1},{parts[0]},{parts[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f7155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from args import *\n",
    "\n",
    "args = Config()\n",
    "args.lr = 2e-5\n",
    "args.l2 = 0\n",
    "args.model = \"BERT\"\n",
    "args.data = \"TREC-6\"\n",
    "args.adapter = \"unipelt\"\n",
    "args.batch_size = 32\n",
    "args.epochs = 10\n",
    "args.clip = 1\n",
    "\n",
    "meta = Config()\n",
    "\n",
    "dataloader = dataset_loaders[args.data]\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMERS[args.model])\n",
    "(train, val, test), vocab = dataloader(meta=meta, tokenizer=tokenizer)\n",
    "\n",
    "if args.data in pair_sequence_datasets:\n",
    "    meta.pair_sequence = True\n",
    "else:\n",
    "    meta.pair_sequence = False\n",
    "\n",
    "if meta.num_labels == 2:\n",
    "    # Binary classification\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    meta.num_targets = 1\n",
    "else:\n",
    "    # Multiclass classification\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    meta.num_targets = meta.num_labels\n",
    "    \n",
    "model = Transformer(args, meta, args.model, adapter=args.adapter)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_iterable(dataset, device, batch_size=32, train=False, indices=None):\n",
    "    \"\"\"\n",
    "    Construct a DataLoader from a podium Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def instance_length(instance):\n",
    "        raw, tokenized = instance.text\n",
    "        return -len(tokenized)\n",
    "\n",
    "    def cast_to_device(data):\n",
    "        return torch.tensor(np.array(data), device=device)\n",
    "\n",
    "    # Selects examples at given indices to support subset iteration.\n",
    "    if indices is not None:\n",
    "        dataset = dataset[indices]\n",
    "\n",
    "    iterator = BucketIterator(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=instance_length,\n",
    "        shuffle=train,\n",
    "        matrix_class=cast_to_device,\n",
    "        look_ahead_multiplier=20,\n",
    "    )\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=True,\n",
    "#     indices=indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1a6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from al.experiment import Experiment\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_iter):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    accuracy, confusion_matrix = 0, np.zeros(\n",
    "        (meta.num_labels, meta.num_labels), dtype=int\n",
    "    )\n",
    "\n",
    "    logit_list = []\n",
    "    y_true_list = []\n",
    "    ids = []\n",
    "    for batch_num, batch in enumerate(train_iter, 1):\n",
    "        t = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids.extend([int(id[0]) for id in batch.id])\n",
    "\n",
    "        # Unpack batch & cast to device\n",
    "        if meta.pair_sequence:\n",
    "            (x_sequence1, sequence1_lengths) = batch.sequence1\n",
    "            (x_sequence2, sequence2_lengths) = batch.sequence2\n",
    "        else:\n",
    "            (x, lengths) = batch.text\n",
    "\n",
    "        y = batch.label\n",
    "        y_true_list.append(y.squeeze(0) if y.numel() == 1 else y.squeeze())\n",
    "\n",
    "        if meta.pair_sequence:\n",
    "            # PSQ\n",
    "            lengths = (sequence1_lengths, sequence2_lengths)\n",
    "            logits, return_dict = model(x_sequence1, x_sequence2, lengths)\n",
    "        else:\n",
    "            # SSQ\n",
    "            logits, return_dict = model(x, lengths)\n",
    "        logit_list.append(logits)\n",
    "\n",
    "        # Bookkeeping and cast label to float\n",
    "        accuracy, confusion_matrix = Experiment.update_stats(\n",
    "            accuracy, confusion_matrix, logits, y\n",
    "        )\n",
    "        if logits.shape[-1] == 1:\n",
    "            # binary cross entropy, cast labels to float\n",
    "            y = y.type(torch.float)\n",
    "\n",
    "        loss = criterion(logits.view(-1, meta.num_targets).squeeze(), y.squeeze())\n",
    "\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Batch]: {}/{} in {:.5f} seconds\".format(\n",
    "                batch_num, len(train_iter), time.time() - t\n",
    "            ),\n",
    "            end=\"\\r\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    loss = total_loss / len(train_iter)\n",
    "    result_dict = {\"loss\": loss}\n",
    "    logit_tensor = torch.cat(logit_list)\n",
    "    y_true = torch.cat(y_true_list)\n",
    "    return result_dict, logit_tensor, y_true, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022001ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/10\n",
      "{'loss': 1.5692268680123722}seconds\n",
      "Training epoch: 2/10\n",
      "{'loss': 1.233461660107756} seconds\n",
      "Training epoch: 3/10\n",
      "{'loss': 0.8343249787302578}seconds\n",
      "Training epoch: 4/10\n",
      "{'loss': 0.5697764279016482}seconds\n",
      "Training epoch: 5/10\n",
      "{'loss': 0.4263514495558209}seconds\n",
      "Training epoch: 6/10\n",
      "{'loss': 0.349474528207888} seconds\n",
      "Training epoch: 7/10\n",
      "{'loss': 0.30121782519458945}econds\n",
      "Training epoch: 8/10\n",
      "{'loss': 0.25657056335335465}econds\n",
      "Training epoch: 9/10\n",
      "{'loss': 0.22974231799005293}econds\n",
      "Training epoch: 10/10\n",
      "{'loss': 0.2082190094820035}seconds\n"
     ]
    }
   ],
   "source": [
    "train_results = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(f\"Training epoch: {epoch}/{args.epochs}\")\n",
    "    # a) Train for one epoch\n",
    "    result_dict_train, logits, y_true, ids = train_model(\n",
    "        model, optimizer, criterion, train_iter\n",
    "    )\n",
    "    print(result_dict_train)\n",
    "    train_results.append(result_dict_train)\n",
    "\n",
    "    # b) Evaluate model (test set)\n",
    "#     eval_result_dict = self._evaluate_model(model)\n",
    "#     acc.append(eval_result_dict[\"accuracy\"])\n",
    "#     loss.append(result_dict_train[\"loss\"])\n",
    "#     eval_results.append(eval_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57b1c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "name = model.get_classifier_name()\n",
    "clf = model.classifier #getattr(model.classifier, name)\n",
    "config = model.classifier.config\n",
    "num_layers = config.num_hidden_layers\n",
    "\n",
    "print(num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b69027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.3900,  4.1626, -0.7429, -1.9608, -1.0143, -2.7310],\n",
       "        [ 5.2413, -1.1506,  1.8984, -2.0992, -2.6798, -1.6891],\n",
       "        [ 1.3242,  0.6738, -1.9786,  4.5847, -2.2803, -2.1135],\n",
       "        [ 4.9922, -0.5433,  0.5287, -1.2219, -2.0188, -2.5741],\n",
       "        [ 4.2137, -2.3493,  2.1044, -1.1609, -1.4063, -1.8276],\n",
       "        [-1.3099, -1.3617, -0.6319,  5.9067, -0.7854, -1.7350],\n",
       "        [ 4.2988, -0.2366,  1.2845, -2.0587, -1.3539, -2.1875],\n",
       "        [ 2.4077,  0.5523,  1.4256, -1.0230, -1.4068, -2.6421],\n",
       "        [ 4.7827, -0.8779,  1.7367, -1.8129, -2.4295, -2.4101],\n",
       "        [-0.0487,  0.8461, -0.9498,  0.4986,  1.3494, -2.3525],\n",
       "        [ 3.9158,  1.9345, -0.3427, -2.2640, -1.8074, -2.4878],\n",
       "        [ 3.3428, -1.2677,  2.7778, -1.1901, -1.8196, -2.5822],\n",
       "        [ 0.2694,  6.6043, -1.8484, -2.0286, -1.0732, -2.7626],\n",
       "        [ 1.1058,  3.6770, -1.5612, -0.3926, -0.4904, -2.9746],\n",
       "        [ 1.4879,  0.1173,  0.7719, -1.5803,  0.6612, -1.8502],\n",
       "        [ 3.0174,  1.3685,  1.8667, -2.6324, -2.1333, -2.4993],\n",
       "        [ 2.3652,  0.1952,  0.8562, -1.5894, -0.4130, -2.1312],\n",
       "        [ 4.5141,  2.1809, -0.6321, -1.9391, -2.3707, -2.8040],\n",
       "        [ 4.3300,  0.0322,  0.3474, -2.2454, -2.4219, -0.9529],\n",
       "        [-0.4264, -2.3082,  0.1749,  5.6889, -0.9003, -1.9197],\n",
       "        [ 3.7701,  0.5494, -0.5658, -0.4464, -0.8054, -3.1860],\n",
       "        [ 2.0797,  1.9312, -0.7664, -1.6480, -0.0572, -2.2358],\n",
       "        [-1.1809,  1.7517, -0.9914, -2.1966,  4.0061, -2.4559],\n",
       "        [ 5.1302,  1.1403, -0.5296, -1.6445, -2.5823, -2.5666],\n",
       "        [-0.0652,  5.6830, -1.4196, -1.9067, -0.7593, -2.3454],\n",
       "        [ 1.5925,  4.0513, -0.4621, -2.0958, -0.8604, -3.3495],\n",
       "        [ 6.2674,  0.2471, -0.5005, -1.3074, -3.1454, -2.0666],\n",
       "        [ 4.6570, -1.3299,  2.3918, -2.0621, -2.4432, -1.7714],\n",
       "        [-1.3338, -1.4758, -0.7488,  5.4782, -0.0182, -1.7354],\n",
       "        [-0.8941, -2.3177,  4.7722, -0.3214, -0.0271, -0.9140],\n",
       "        [ 2.9613, -0.2610,  2.7579, -1.9908, -2.2702, -2.0449],\n",
       "        [ 2.8808,  0.6748, -0.4252,  1.4215, -2.5883, -2.0736]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89806f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tr[\n",
    "    (df_tr.index.get_level_values(\"sampler\") == \"entropy\")\n",
    "    & (df_tr.index.get_level_values(\"mode\") == \"ada-besov\")\n",
    "    & (df_tr.index.get_level_values(\"experiment\") == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "411273be",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df.selected.agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc11b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [s for ss in selected for s in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de75de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b640940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['929'], ['3557'], ['2485'], ['4861'], ['4268'], ['4895'], ['4261'], ['3601'], ['2526'], ['4800'], ['5375'], ['515'], ['1395'], ['253'], ['2173'], ['3307'], ['2827'], ['1692'], ['2269'], ['3664'], ['1148'], ['3327'], ['3923'], ['4443'], ['3472'], ['1296'], ['2737'], ['2024'], ['580'], ['1773'], ['1002'], ['4585']],\n",
      "    text: (tensor([[ 2171,  1996,  4802,  ...,  4895, 15464,  2098],\n",
      "            [ 2054,  2003,  1996,  ...,     0,     0,     0],\n",
      "            [ 2054,  2280,  2548,  ...,     0,     0,     0],\n",
      "            ...,\n",
      "            [ 2129,  2064,  1045,  ...,     0,     0,     0],\n",
      "            [ 2054,  2001,  2928,  ...,     0,     0,     0],\n",
      "            [ 2054, 17727,  8625,  ...,     0,     0,     0]], device='cuda:0'), tensor([32, 29, 26, 24, 24, 23, 23, 23, 23, 23, 22, 22, 21, 21, 21, 21, 21, 21,\n",
      "            20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2175'], ['2037'], ['2386'], ['4238'], ['819'], ['3143'], ['2980'], ['3867'], ['1114'], ['2018'], ['2288'], ['2095'], ['3069'], ['4674'], ['4628'], ['5420'], ['994'], ['1153'], ['2261'], ['588'], ['1033'], ['4314'], ['3510'], ['5340'], ['1305'], ['2607'], ['2066'], ['4928'], ['1181'], ['1646'], ['1988'], ['417']],\n",
      "    text: (tensor([[ 2054, 15138,  2100,  3507,  2288,  1996, 14101,  3642,  5585,  2581,\n",
      "              2487,  2013,  1996,  1057,  1055, 10690,  2326,  1999,  3699],\n",
      "            [ 2054,  2165,  2034,  3396,  1999, 18168,  3490,  2932,  1055,  5049,\n",
      "              2000,  2424,  1996,  7209, 14477,  3619, 13777,  3085,  3160],\n",
      "            [ 2029,  1997,  1996,  2206,  2106,  2025,  4374,  1037,  3172,  5151,\n",
      "              2388,  2400,  2013,  1996,  2120,  2388,  1055,  2154,  2837],\n",
      "            [ 2054, 26529,  3555,  1996,  2206,  2065,  2643,  2106,  2025,  4839,\n",
      "              2009,  2052,  2022,  4072,  2000,  1999, 15338,  2032,     0],\n",
      "            [ 2054,  2106,  4907,  1037, 15922, 13238,  2094,  1998,  2198, 19337,\n",
      "             20668,  2072,  8046,  5095,  2305,  2444,  2000,  2468,     0],\n",
      "            [ 2073,  2064,  2019,  3265,  2131,  1037,  3967, 10014,  7718,  2008,\n",
      "              5296,  1996,  2972,  3302,  1997,  3239,  2043,  2047,     0],\n",
      "            [ 2054,  2001,  2761,  4225,  2004,  2028,  1015,  2454,  2705,  1997,\n",
      "              1996,  3292,  2013,  1996, 26640,  2000,  1996,  6536,     0],\n",
      "            [ 2040,  2106, 15467,  2154,  2812,  2043,  2016,  2056,  1045,  2655,\n",
      "              2032, 14637,  2138,  2002,  1055,  5121,  2053,  2600,     0],\n",
      "            [ 2054,  9469,  1996,  2522,  4405,  1997,  1996,  4372,  6030,  5637,\n",
      "              2000,  4607,  2069,  2026,  2643,  1999,  2010,  8833,     0],\n",
      "            [ 2054,  2764,  1037,  8579,  1999, 10150,  2096,  9565,  2075,  1996,\n",
      "              2331,  1997,  1057,  1055,  2708,  3425,  2198,  5832,     0],\n",
      "            [ 2054,  2848,  1038, 20051,  3723,  3117, 23412,  1996, 22812,  1997,\n",
      "             16964,  6097, 27276,  1055,  6664,  2011,  1996,  6548,     0],\n",
      "            [ 2054,  2665,  3016, 15285,  2873,  6316, 19137, 21850,  5422,  2045,\n",
      "              1055,  2498,  2008, 18716,  1996,  2543,  2066,  5223,     0],\n",
      "            [ 2054,  2003,  1996,  7835,  1997,  9413,  2571,  6156, 11764,  1055,\n",
      "              1996,  2553,  1997,  1996, 10215,  5939, 18136,  2102,     0],\n",
      "            [ 2054,  2647,  2406,  4704, 22981, 12133,  1999,  4927,  2138,  8021,\n",
      "              2068,  3465,  2062,  2084,  2037,  2227,  3643,     0,     0],\n",
      "            [ 2054, 14731,  7461,  1996,  2181,  1997,  1996, 25552,  3470,  1998,\n",
      "              2030, 26993,  3470,  1999,  1996,  2167,  2712,     0,     0],\n",
      "            [ 2054,  2106,  1996,  2830,  3241,  4079,  3428, 18112,  1997,  3190,\n",
      "             19274,  2046,  4524,  9050,  2000, 12992,  2449,     0,     0],\n",
      "            [ 2054,  2001,  4114,  2004,  1037,  8055,  8244,  2591,  2252,  1999,\n",
      "             16405,  8523,  3211,  1999,  5298,  1999,  7647,     0,     0],\n",
      "            [ 2054, 15550,  2098,  9476,  3494,  2079,  8936,  3619,  2113,  2004,\n",
      "              1058,  2721,  3900, 11721,  3900,  1998, 10164,     0,     0],\n",
      "            [ 2054, 15607,  5093,  2977,  1055,  2273,  1055,  3895,  2516,  2001,\n",
      "              5965,  6890,  1996,  2197, 25244,  2000,  2663,     0,     0],\n",
      "            [ 2054,  2079,  2017,  2131,  2011,  5815, 18749,  3406,  3676,  6895,\n",
      "             20159, 20934, 27887,  7277,  2271,  2000,  6501,     0,     0],\n",
      "            [ 2054,  2515,  1996, 15068, 24847, 21194,  3319,  1997,  7695,  5051,\n",
      "              4817,  2655,  2019,  1999, 25918,  8082,  4861,     0,     0],\n",
      "            [ 2043,  2170,  2588,  2000,  7806,  2054,  2137,  2236,  3880,  2909,\n",
      "              1045,  2031,  2025,  2664,  5625,  2000,  2954,     0,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  4268,  2265,  2013,  3010,\n",
      "              2270,  2694,  2007,  1996,  4823,  7222, 23804,     0,     0],\n",
      "            [ 2054,  2003,  1999,  3336,  9898,  1998,  3336,  2843,  3258,  2008,\n",
      "              3084,  2009,  5437,  1996,  2126,  2009,  2515,     0,     0],\n",
      "            [ 2054,  8316,  2106,  8101,  2224,  1999,  3015,  2000,  2022,  2030,\n",
      "              2025,  2000,  2022,  2008,  2003,  1996,  3160,     0,     0],\n",
      "            [ 2129,  2116,  1997,  2296,  2184,  2372,  1997,  1996, 18936, 11666,\n",
      "              2523,  2031,  2196,  2499,  1037,  8086,     0,     0,     0],\n",
      "            [ 2054,  5043,  3303,  1996, 24549,  1997,  1037,  6465,  3034,  2090,\n",
      "             16551,  1998,  1047,  8093, 20668, 16179,     0,     0,     0],\n",
      "            [ 2054,  2003,  1996,  2922,  1998,  2087,  6450, 10846,  2810,  2622,\n",
      "              1999,  1996,  1057,  1055,  2157,  2085,     0,     0,     0],\n",
      "            [ 2054,  4706,  4438,  6401,  2006,  1996,  3945,  2005,  1037,  8813,\n",
      "              1999,  2751,  4276,  1021,  1014,  7038,     0,     0,     0],\n",
      "            [ 2054,  2323,  1996, 17428,  2022,  2275,  2012,  2005, 21522, 18237,\n",
      "              2100,  1051,  4017, 14163, 15379,  2015,     0,     0,     0],\n",
      "            [ 2054,  1055,  1996,  7098,  4366,  2000,  4476,  1997,  1996,  2402,\n",
      "              2308,  2040,  2719, 16000,  6541, 23963,     0,     0,     0],\n",
      "            [ 2054,  3185,  2778,  1997,  1996,  3142,  3400,  2838,  1996,  4748,\n",
      "              8202, 22753,  5216,  2092,  1998,  2444,     0,     0,     0]],\n",
      "           device='cuda:0'), tensor([19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17,\n",
      "            17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2515'], ['1734'], ['680'], ['2581'], ['5112'], ['2583'], ['1172'], ['990'], ['1614'], ['3347'], ['2859'], ['2174'], ['558'], ['3608'], ['634'], ['3770'], ['2274'], ['1944'], ['1183'], ['4886'], ['3812'], ['388'], ['2102'], ['456'], ['2442'], ['4588'], ['1938'], ['2965'], ['3690'], ['1920'], ['1405'], ['5004']],\n",
      "    text: (tensor([[ 2054,  2003,  8965, 10556, 24316,  2050,  1055,  2460,  2466,  1037,\n",
      "              2406,  3460,  2667,  2000,  2425,  2149],\n",
      "            [ 2054,  2106,  1037,  5767,  2301, 25245,  8258,  2131,  2005,  5128,\n",
      "              1037,  8903,  3608,  2083,  1037,  3614],\n",
      "            [ 2054,  2079,  2867,  3046,  2000,  2079,  2043,  1996,  2189,  6762,\n",
      "              1999,  1037,  2208,  1997,  3315,  8397],\n",
      "            [ 2029,  2217,  1997,  1996,  2227,  2079,  2087,  3324,  7166,  2000,\n",
      "              2265,  2062,  1997,  1999,  2969,  9668],\n",
      "            [ 2054,  2001,  1996,  2030,  3540,  1055,  2171,  2008,  2351,  1997,\n",
      "              1037, 28079,  8985,  2012,  2712,  2088],\n",
      "            [ 2054,  9575,  2052,  2017,  5987,  2000,  3191,  2055,  1999,  1996,\n",
      "              7058,  4772,  1996,  2502, 13064,  2739],\n",
      "            [ 2054,  9983,  1055,  2171,  3544,  2006,  1996,  3356,  2187,  3420,\n",
      "              1997,  1037, 13007, 19845,  8043,  3830],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  3379,  2008,  2003,  2284,\n",
      "              2379,  1996,  3007,  2103,  1997, 15786],\n",
      "            [ 2054,  2079,  8594,  2140,  6243, 19971, 24865, 16391,  9579,  1998,\n",
      "             12120, 17017,  2035,  2031,  1999,  2691],\n",
      "            [ 2054,  2024,  1996, 10818, 10826,  1997,  1051, 11030,  5207,  1998,\n",
      "             14163, 20389,  5092,  1996,  6452,  2867],\n",
      "            [ 2129,  2515,  1996,  3177,  1996, 16853, 23371,  1999,  1037, 13103,\n",
      "              7461,  1996,  6434,  1997,  1996, 13103],\n",
      "            [ 2054,  2003,  1996,  2197,  2171,  1997,  7004,  1998, 11409,  2271,\n",
      "              2013,  1996, 21443,  1055,  5021,  6167],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996, 13130,  2008, 26442, 21613,\n",
      "              5652,  1999,  2007,  4116,  4907,  4143],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  1996,  3729, 12495, 25832,  1055,\n",
      "              2030, 11754, 22824,  2026,  2171,  2003],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  3185,  2008,  5652, 10666,\n",
      "              2962,  1998,  7779, 29058,  8625, 13327],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  4315, 22043,  2094,  3565,\n",
      "              4735,  8064, 13323, 18891,  2271,  3594],\n",
      "            [ 2054,  2003,  1996, 10479,  2518,  2464,  2104,  1996,  2087,  3928,\n",
      "             24635,  1998,  2129,  2502,  2003,  2009],\n",
      "            [ 1996, 16994, 14913,  2375,  3813,  2018,  2019,  2436,  1999,  1048,\n",
      "              1037,  2005,  2129,  2116,  2086,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996, 27701,  4169,  2008,  3065,\n",
      "              2048,  2398,  2007,  3093,  7244,     0],\n",
      "            [ 1999,  2026, 24272,  2129,  2003,  2720, 11895,  5017,  2850,  2041,\n",
      "              1997,  2173,  2006,  1996,  3888,     0],\n",
      "            [ 2054,  2047,  5979,  1040,  1037,  3555,  2026,  3095,  1998,  1045,\n",
      "             13332,  1996, 10102,  3134,  3283,     0],\n",
      "            [ 2054,  6568,  7815,  3850,  2001,  7153,  2011,  1996, 13146,  1997,\n",
      "              2198,  1042,  5817,  1055, 10102,     0],\n",
      "            [ 2006,  2029,  3462,  2106,  6904,  4213,  2480,  2017,  8977, 10797,\n",
      "              2250, 24386,  1998, 13446,  2635,     0],\n",
      "            [ 2054,  2394,  2773,  3310,  2013,  1996,  2214,  2413,  2522, 12229,\n",
      "              7959,  2226,  3574,  3104,  2543,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  2922,  2300,  9530,  8043,\n",
      "              6212,  5666,  2622,  1999,  2859,     0],\n",
      "            [ 2129,  2064,  1045,  2131,  2619,  1055,  3042,  2193,  2065,  1045,\n",
      "              2069,  2031,  2037,  3898,  2171,     0],\n",
      "            [ 2054,  1055,  2019,  3733,  2126,  2000,  4175,  1996, 15796,  2193,\n",
      "              1997,  3869,  1999,  1037,  2697,     0],\n",
      "            [ 2054,  2447, 26783,  2015,  2019,  2779,  1997,  1017,  2335,  2076,\n",
      "              1037,  3598,  3313,  4974,  2121,     0],\n",
      "            [ 2054,  2003,  1996,  2744,  2005,  1996,  7680,  1997,  2035,  7403,\n",
      "              3430,  1999,  1037,  2445, 15923,     0],\n",
      "            [ 2054,  1055,  1996,  4292,  1997,  2198,  3393, 12385,  2063,  1055,\n",
      "              1037,  2235,  2237,  1999,  2762,     0],\n",
      "            [ 2054,  2343,  1055,  5440, 10213, 20563,  3508,  2001,  2272,  2085,\n",
      "              1998,  2292,  2149,  3114,  2362,     0],\n",
      "            [ 2054,  2515,  1054,  1041,  1049,  3233,  2005,  2004,  1999,  1996,\n",
      "              2600,  2177,  1054,  1041,  1049,     0]], device='cuda:0'), tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [5]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1995'], ['2922'], ['1802'], ['389'], ['4891'], ['3758'], ['2043'], ['3607'], ['5073'], ['1857'], ['3593'], ['4149'], ['1652'], ['2826'], ['1593'], ['2901'], ['2570'], ['3888'], ['3616'], ['3687'], ['61'], ['2941'], ['1225'], ['3373'], ['421'], ['259'], ['5382'], ['3901'], ['5144'], ['1689'], ['192'], ['3403']],\n",
      "    text: (tensor([[ 2054,  2106, 14420,  3472,  8446,  8117,  5004, 13520,  2694,  2000,\n",
      "              2022,  2006,  2089,  1023,  3777],\n",
      "            [ 2054, 25850, 24667, 16263, 14925,  4371,  2863,  7367, 12821, 25032,\n",
      "              5243,  1998,  8827, 11069,  6190],\n",
      "            [ 2054,  9348,  2340, 19748, 13128,  1996,  3573,  2096,  9143,  1998,\n",
      "              2632, 13626,  2378,  2081,  2381],\n",
      "            [ 2054,  2003,  1996,  2224,  1997,  1037,  2484,  3178,  5119,  2612,\n",
      "              1997,  1037,  2260,  3178,  5119],\n",
      "            [ 2171,  1996,  9476, 22519,  9530, 26949,  2011,  1996,  3894,  3614,\n",
      "              4207,  2011,  7912,  1998,  8057],\n",
      "            [ 2054,  8637,  3059,  4825,  2064,  2022,  2179,  2012, 23688,  2225,\n",
      "             27787,  2395,  2047,  2259,  2103],\n",
      "            [ 2054,  5021,  1997,  2694,  1055,  3585,  2287,  2253,  2011,  1996,\n",
      "             12652,  2505,  2005,  1037,  4756],\n",
      "            [ 2054, 25068,  2180,  2019,  3378,  2811,  8554,  2004,  1996,  4602,\n",
      "              3586,  1997,  1996,  3983,  2301],\n",
      "            [ 2054,  2079,  1996,  2417,  1998,  2317, 13560,  2006,  1037, 13362,\n",
      "             22231,  2361,  6536,  3233,  2005],\n",
      "            [ 1999,  2054,  2143,  2106,  7112, 28740,  1055,  3899,  2732,  2004,\n",
      "              1996,  2364,  2839,  1055,  3899],\n",
      "            [ 2054,  2236,  3257,  2515,  1996,  4990,  1999,  2105,  1996,  2088,\n",
      "              1999,  3770,  2420, 10838,  1999],\n",
      "            [ 2054,  3299,  2784,  3759, 17598,  3640,  1996,  2877,  3203,  2007,\n",
      "              1037,  2117,  2474, 18143,  2595],\n",
      "            [16994,  1998, 14913,  2018,  2019,  2436,  1999,  3050,  3349,  2005,\n",
      "              2129,  2146,  2077,  5494,  2009],\n",
      "            [ 2054,  2003,  1996,  2744,  2005,  1996,  2217,  1997,  1996,  3137,\n",
      "              2008,  5344,  1996, 19283,  7266],\n",
      "            [ 2054,  4435,  2193,  4519,  2015,  1996,  2304,  3830,  1997,  1037,\n",
      "              5835,  1997,  2990,  3817,  1055],\n",
      "            [ 2054,  2024, 18712,  2705, 15460, 10668,  7295,  2891, 14262, 11514,\n",
      "             15006,  1998,  2026, 19648,  2891],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  6011, 15185,  1037, 26035,\n",
      "              1999,  2051, 13169,  3157,     0],\n",
      "            [ 2054,  1055,  1996,  4555,  2193,  1997,  4184,  1037, 20601,  2089,\n",
      "              2224,  1999,  1037,  2461,     0],\n",
      "            [ 2054, 15873,  1057,  1055,  2343, 10964,  2010,  2219,  9450,  2044,\n",
      "              3773,  1037, 19083,  2674,     0],\n",
      "            [ 6990, 10654,  3468,  2078,  2003,  2641,  2000,  2022,  1996,  2034,\n",
      "              4823, 11762,  1997,  2054,     0],\n",
      "            [ 2054,  2515,  3668,  6210,  2812,  1998,  2129,  2052,  2028,  4339,\n",
      "              1037,  3259,  2006,  2009,     0],\n",
      "            [ 2054,  2932,  3825,  8471, 27299,  2321,  1037,  2773,  2000,  4339,\n",
      "              1037,  7087, 22158,  3720,     0],\n",
      "            [ 2129,  2003,  1996,  2047,  4811, 17338,  3630,  4179,  3158,  1042,\n",
      "             17788,  1058,  2487,  3194,     0],\n",
      "            [ 2029, 16082,  5510, 26734,  2034,  1055, 13542,  2545,  2030,  1017,\n",
      "             14163, 17140, 17389,  2869,     0],\n",
      "            [ 2073,  2442,  1037,  4715,  3125,  2666,  3233,  2000,  2022,  7936,\n",
      "              2000,  5047,  1996,  3608,     0],\n",
      "            [ 2054,  5869,  7136,  3309,  5296,  1999,  2281,  3150,  2007,  1996,\n",
      "              3279,  1997,  6391,  3268,     0],\n",
      "            [ 2054,  2112,  2106,  6425,  5951,  2377,  1999,  1996,  2458,  1997,\n",
      "              1996,  3780,  1999,  2637,     0],\n",
      "            [ 2054,  5661,  1999,  7397,  2020,  5360,  2011,  1996,  4654, 22500,\n",
      "             11748, 24601,  3514, 14437,     0],\n",
      "            [ 2054,  2515,  2019, 13402,  2078,  4320,  1041, 13820, 10727,  3945,\n",
      "              2041,  1996,  4598,  1997,     0],\n",
      "            [ 2054, 18236,  8637,  2001,  2034,  3107,  1999,  1996, 10646, 13941,\n",
      "              1997,  1996,  3878,  1055,     0],\n",
      "            [ 2029, 21151,  2221,  2610,  2533,  8243,  1996,  2922, 16034, 22613,\n",
      "              1999,  2009,  1055,  2381,     0],\n",
      "            [ 2054,  2106, 25244,  2198, 13835,  4088,  4855,  2000,  2047,  2088,\n",
      "             15526,  1999, 16734,  2475,     0]], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14,\n",
      "            14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1572'], ['4785'], ['5020'], ['5357'], ['4703'], ['165'], ['1357'], ['1950'], ['3266'], ['1529'], ['3747'], ['2146'], ['1439'], ['3189'], ['5216'], ['4743'], ['3370'], ['1516'], ['3875'], ['5312'], ['4782'], ['3'], ['2790'], ['4595'], ['2483'], ['1298'], ['1451'], ['5092'], ['4926'], ['3422'], ['2508'], ['2602']],\n",
      "    text: (tensor([[ 2029,  1997,  1996,  2206,  2600,  1050,  4897,  3340,  2038,  1037,\n",
      "              2732,  2006,  5365,  8459],\n",
      "            [ 2054,  1055,  1996,  6904, 28362, 25311, 20175,  5662,  1997,  5717,\n",
      "              5445,  9358,  8004, 13662],\n",
      "            [ 2054,  2694,  2186,  2838,  1996,  7357,  1997,  1037,  2496,  3232,\n",
      "              2315,  5655,  1998,  7673],\n",
      "            [ 2054,  2003,  1996,  4338,  1997,  1037,  2374,  2004,  3090,  1999,\n",
      "              1996,  5088,  3627,  8654],\n",
      "            [ 2054,  2001, 28722,  6262,  2725,  2000,  7796,  1015,  2199,  1999,\n",
      "              1996,  2220,  3925,  1055],\n",
      "            [ 2029,  2887,  2482,  9338,  2018,  2049,  5221,  7017,  1997,  5096,\n",
      "              1999,  1996,  4968,  3006],\n",
      "            [ 1997,  2336,  2090,  1996,  5535,  1997,  2048,  1998,  5408,  2054,\n",
      "              7017,  3422,  1996, 19047],\n",
      "            [ 2054,  2024,  1996,  2536,  3971,  1999,  2029,  2028,  2064,  5468,\n",
      "              2009,  5310,  9967,  2504],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  2343,  1997, 11721, 17830,\n",
      "              2102,  1057,  1055,  1037],\n",
      "            [ 2054,  2079,  2057,  2655,  1996, 15344,  2240,  2247,  1996,  2327,\n",
      "              1997,  1996,  6857,  4020],\n",
      "            [ 2054,  2079,  2017,  2655,  1037,  3058,  2008,  3397, 24558,  3616,\n",
      "              2066,  1023,  1022,  5818],\n",
      "            [ 2054,  2001,  1996,  8367,  1997,  2446,  3909,  9078, 19149,  3854,\n",
      "              4138,  2705, 11253,  2368],\n",
      "            [ 2054,  6531,  2686,  3658,  2090, 11275,  3927,  1998,  3752,  4296,\n",
      "              2006,  1037, 15404,  2604],\n",
      "            [ 2054, 15607,  6080,  3122, 14574,  3013,  2046,  1996,  5779,  1997,\n",
      "             12883, 17866,  1055, 11018],\n",
      "            [ 3415,  1997,  2808,  2011,  2508,  1037, 23025, 10222,  2121,  2275,\n",
      "              1999,  1996,  2206,  5269],\n",
      "            [ 2054,  2416,  3329, 23372,  8175, 15536, 14273,  2098,  2014, 11300,\n",
      "              3388,  2006, 17078,  2015],\n",
      "            [ 2171,  1996,  4031,  2008,  2003,  2012,  2115, 24665, 10085,  2121,\n",
      "              1055,  2012,  2115, 12206],\n",
      "            [ 2054,  2024,  5696,  9388, 27663,  1055,  1998,  8101,  1055,  4706,\n",
      "              5857,  2000,  2394,  3906],\n",
      "            [ 2054,  2024,  1996,  2034,  2416,  2616,  1997, 19675,  1055,  1037,\n",
      "              6925,  1997,  2048,  3655],\n",
      "            [ 2054,  2079,  2017,  2655,  1037,  2930,  1997,  2115,  4344,  2013,\n",
      "              2028,  4101,  2000,  2178],\n",
      "            [ 2054,  3972,  5555,  5666,  2003,  2124, 27427, 20806, 16280,  2135,\n",
      "              2004,  4060,  3709, 20944],\n",
      "            [ 2054,  1042,  5004,  2140, 13273,  1996, 17763,  2044,  1996,  2822,\n",
      "              2095,  1997,  1996, 10608],\n",
      "            [ 2054,  2047,  7035,  8429,  9466,  2220,  2000,  3789,  2034,  1999,\n",
      "              1057,  1055,  4883,  3864],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  2149,  7739,  4405,  2915,\n",
      "              2091,  2058,  2167,  4420],\n",
      "            [ 2054,  2024,  2070,  4569,  2477,  2000,  2079,  1999,  2522,  9759,\n",
      "             10199,  3290,  2005, 12908],\n",
      "            [ 2043,  2020,  1996,  4386,  2399,  1999,  2029, 14942, 16571,  2638,\n",
      "              6895,  2150,  2759,  2209],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996, 13608, 21435,  2017,  2128,\n",
      "             18243,  2078,  2205,  7629],\n",
      "            [ 1996,  4386,  2399,  1999,  2029,  2095,  3039, 14942, 16571,  2638,\n",
      "              6895,  2000,  2468,  2759],\n",
      "            [ 2054,  2003,  1996,  2812,  3318,  1997,  1996,  2327,  2184,  2327,\n",
      "              1019,  1998,  2327,  1015],\n",
      "            [ 2054,  3435,  2833,  2003,  4810,  2007,  1037,  3595, 12586,  1997,\n",
      "              2340, 17561,  1998, 21729],\n",
      "            [ 2054, 11075,  1999,  1996,  1057,  1055,  4552,  2089,  2025,  2022,\n",
      "              2904,  8776,  2030, 13266],\n",
      "            [ 2054,  2003,  1996,  4816,  5080,  2109,  2000,  3965,  5107,  8834,\n",
      "              7978,  2000,  3751,  7755]], device='cuda:0'), tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "            14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4857'], ['4160'], ['5165'], ['2888'], ['3369'], ['563'], ['2032'], ['3153'], ['3567'], ['3639'], ['4215'], ['1553'], ['3900'], ['4736'], ['4163'], ['1664'], ['16'], ['2154'], ['118'], ['1740'], ['509'], ['1047'], ['4611'], ['716'], ['1046'], ['5348'], ['2947'], ['2666'], ['3172'], ['5309'], ['2875'], ['1343']],\n",
      "    text: (tensor([[ 2054,  2024,  2216,  2210,  2630,  8339,  5668,  1999,  1996,  2690,\n",
      "              1997,  1996,  2346,  2005],\n",
      "            [ 2054,  2003,  1996,  2712, 14971,  2075,  2171,  2005,  1996,  2670,\n",
      "              5955,  1997,  2148,  2637],\n",
      "            [ 2054,  7966,  2003,  2025,  2061,  7968,  2000,  4558,  2019, 11292,\n",
      "              2000,  2663,  1037,  9097],\n",
      "            [ 2054,  2785,  1997,  2111,  2165,  2112,  1999, 18789,  2015,  7417,\n",
      "              1999,  4404,  1999, 16057],\n",
      "            [ 2054,  2024,  2310, 28550,  6895,  6894, 17557,  3775,  1062,  9956,\n",
      "              3490,  1998,  7270,  6916],\n",
      "            [ 2054,  2003,  1996,  4860,  2005, 21522, 18237,  2100,  1051,  4017,\n",
      "             14163, 15379,  2015,     0],\n",
      "            [ 2129,  2116,  2335,  1037,  2154,  2515,  1996,  5171,  2711,  2175,\n",
      "              2000,  1996,  5723,     0],\n",
      "            [ 2054,  2003,  1996,  6587,  2287,  1037,  2879,  2030,  2611,  2064,\n",
      "              2031,  2019, 13892,     0],\n",
      "            [ 2054,  2301,  1055,  1996,  4292,  2005,  2694,  1055,  1996,  7357,\n",
      "              1997,  5863,  7415,     0],\n",
      "            [ 2054,  2003,  1996,  6210,  1997,  1996,  8040,  2527, 11362,  2773,\n",
      "             25353,  9096,  6292,     0],\n",
      "            [ 2054,  2280,  3060,  3003,  2218,  2010,  2406,  1055,  8362,  2516,\n",
      "              2005,  3157,  2086,     0],\n",
      "            [ 2054,  2001,  1996,  3017,  2171,  1997,  1996,  2516,  2839,  1999,\n",
      "              2256,  3335,  8379,     0],\n",
      "            [ 2054,  2374,  2873,  1055,  2466,  2001,  2409,  1999,  1996,  3185,\n",
      "              2448,  2000, 11695,     0],\n",
      "            [ 2054,  2479,  2001,  1996,  4539,  1997,  1996,  1057,  1055,  1055,\n",
      "              3169, 13661,  8111,     0],\n",
      "            [ 2054,  2003,  1996,  2381,  1997,  2980,  7787,  3765,  1998,  2129,\n",
      "              2024,  2027,  2550,     0],\n",
      "            [ 2054,  2106,  1050,  1056,  6857, 22548,  3630,  2079,  1999,  2010,\n",
      "              4013,  8362,  2476,     0],\n",
      "            [ 2054,  2106,  1996,  2069, 21492,  7450,  2000,  1996,  1057,  1055,\n",
      "              4552,  3066,  2007,     0],\n",
      "            [ 2054,  2079,  1996,  2193,  1015,  1016,  1998,  1018,  2812,  2006,\n",
      "              2852, 11565, 11015,     0],\n",
      "            [ 2054,  1055,  1996,  2691,  2171,  2005,  9078,  3723,  4877, 27072,\n",
      "              8516,  2594,  5648,     0],\n",
      "            [ 1999,  2054,  2152,  3891,  2449,  6957,  2106,  5261,  1996,  3306,\n",
      "              6655,  1998,  4558,     0],\n",
      "            [ 2054,  4398,  4322,  3397,  1037, 14257,  3608,  3608, 13959,  1998,\n",
      "              2058, 12314,  7270,     0],\n",
      "            [ 2054,  2106,  2329,  3316,  6293, 12862,  1014,  6197,  1997,  5572,\n",
      "              2046,  1999,  3196,     0],\n",
      "            [ 1999, 16621,  1996, 12156,  2457,  2001,  3140,  2000,  2693,  2013,\n",
      "              4199,  2000,  2073,     0],\n",
      "            [ 2054,  3661,  2003,  2000,  1996,  2157,  1997,  1047,  2006,  1037,\n",
      "              2828, 15994,  9019,     0],\n",
      "            [ 2054,  2515,  1037,  5572, 13102,  7828,  1997,  3043, 17042,  1999,\n",
      "              1037,  2304,  4920,     0],\n",
      "            [ 2129,  2064,  1045,  2298,  2039,  2619,  1055,  1041,  5653,  4769,\n",
      "              2006,  1996,  4274,     0],\n",
      "            [ 2054,  2003,  1996,  6749,  3679,  9095,  2005,  1042, 23518,  5648,\n",
      "              2005,  6875,  2308,     0],\n",
      "            [ 2054,  2003,  3214,  2011,  1996,  2744, 10750,  2000, 16736,  1999,\n",
      "              4431,  2000,  9547,     0],\n",
      "            [ 2054,  2003,  1996,  2087,  4141,  2109,  1015,  3661,  2773,  1999,\n",
      "              1996,  2394,  2653,     0],\n",
      "            [ 2054,  2003,  1996, 20137,  2005,  1996,  5790,  2291,  2005,  2250,\n",
      "              4650,  2121,  8122,     0],\n",
      "            [ 2043, 10646,  3791,  2000,  2131,  2185,  2013,  2009,  2035,  2073,\n",
      "              2515,  2002,  2175,     0],\n",
      "            [ 2054,  2088,  2162,  1045,  2645,  2387,  1020,  1014,  3629,  2730,\n",
      "              1999,  2028,  2154,     0]], device='cuda:0'), tensor([14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "            13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['420'], ['3445'], ['5081'], ['700'], ['3350'], ['4260'], ['3845'], ['2562'], ['1707'], ['3851'], ['301'], ['4853'], ['4719'], ['367'], ['3351'], ['997'], ['4419'], ['1487'], ['1905'], ['4124'], ['4745'], ['1714'], ['3874'], ['2918'], ['2316'], ['5005'], ['2894'], ['1410'], ['3123'], ['2122'], ['4316'], ['1582']],\n",
      "    text: (tensor([[ 2507,  1037,  3114,  2005,  2137,  6505,  2411,  7292,  2015,  7510,\n",
      "              2041,  1997,  2082],\n",
      "            [ 2054,  3220,  1055,  4323,  2299,  2001,  2043,  1996,  4231,  3310,\n",
      "              2058,  1996,  3137],\n",
      "            [ 2054,  8366, 10423,  2001,  2124,  2004,  1996,  3748,  7087,  1997,\n",
      "              1996, 14089, 19707],\n",
      "            [ 2129,  2521,  2079,  2017,  2031,  2000,  2448,  2065,  2017,  2718,\n",
      "              1037,  2188,  2448],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996, 20516,  3116,  1997,  8573,\n",
      "             10888,  1998, 13125],\n",
      "            [ 2054,  2001,  1996,  4366,  2000,  4476,  1997, 10566,  1045,  3390,\n",
      "              2337,  1015,  3845],\n",
      "            [ 2043,  2025, 13896, 12228,  2006, 26312,  2054,  2515,  4205,  4326,\n",
      "              2655,  2010,  9518],\n",
      "            [ 2040,  2356,  1996,  3315,  3160,  2031,  2017,  2412,  2042,  2000,\n",
      "              3751,  3203,  2455],\n",
      "            [ 2054,  2442,  1037,  5869,  7136,  2304, 17364, 11033,  2079,  2043,\n",
      "              2002,  6561,  2385],\n",
      "            [ 2054,  2662,  3099,  2056, 27118,  7542,  2089,  2022,  1996,  3284,\n",
      "              2433,  1997,  2895],\n",
      "            [ 2054,  9121,  2194,  2003,  1996,  2088,  1055,  2053,  1015,  9338,\n",
      "              1997,  2931, 26278],\n",
      "            [ 2054,  3780,  2513,  1037, 17618,  3396,  2005,  1996, 27105,  2466,\n",
      "              5261,  1055,  2088],\n",
      "            [ 2054,  2001,  1996, 10576,  2008,  4930,  1996,  2103,  1997,  3899,\n",
      "              4665,  1999,  6166],\n",
      "            [ 2054,  3644,  6209,  2387,  1996,  2707,  1997,  1996,  3381,  3054,\n",
      "              5243,  3367,  2162],\n",
      "            [ 2054,  2024,  1996,  2069,  2867,  7792,  2000,  3556,  2685,  1999,\n",
      "             11220,  7350,  2170],\n",
      "            [ 2054,  2003,  2019,  2742,  1997,  2019,  5025,  2553,  1997,  2478,\n",
      "              1996, 15276,  7450],\n",
      "            [ 2171,  1996,  2775,  2187,  2006,  1037, 26581,  2012,  1996,  2927,\n",
      "              1997, 13753,  8975],\n",
      "            [ 2054,  2024,  2017,  4994,  2043,  2017,  2404,  1037, 11915, 18223,\n",
      "              2000,  2115,  4540],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  3899,  2006,  1996,  8579,\n",
      "              2121,  2990,  3482],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  6722,  8475,  1997,  1996, 19898,\n",
      "              1055,  2599,  3899],\n",
      "            [ 2054,  2240,  4055,  1996,  2167,  1998,  2148,  1999,  1996,  1057,\n",
      "              1055,  2942,  2162],\n",
      "            [ 2129,  2052,  1045,  2424,  1996,  3976,  1997,  2367, 11595,  2008,\n",
      "              2031,  2042,  6955],\n",
      "            [ 2054,  2079,  9180,  7158,  5261,  5954,  1998,  4922,  1047,  3044,\n",
      "              2031,  1999,  2691],\n",
      "            [ 2054,  2024,  1996,  3616,  2008,  4906,  2046, 10768, 10867, 12162,\n",
      "              1055,  2197,  9872],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  1057,  1055,  1055,  2034,\n",
      "             15371,  2686,  2565],\n",
      "            [ 2054,  8592,  2240,  2515, 10645,  4048,  2063,  3389, 29360,  4748,\n",
      "             16874,  5562,  2005],\n",
      "            [ 2054,  2079,  2751,  7529,  4558,  2065,  2921,  1999, 25361,  5507,\n",
      "              2030,  2770,  2300],\n",
      "            [ 2054,  2001,  1996,  5372,  4756,  1999, 24501, 29513,  2015,  2000,\n",
      "              2360, 22708,  5980],\n",
      "            [ 2054,  2318,  1999,  9037,  2043,  2751,  2001,  3603,  2012, 10514,\n",
      "             12079,  1055,  4971],\n",
      "            [ 2054,  2003,  1996,  2028,  2518,  2017,  2342,  2077,  2017,  2064,\n",
      "              5309,  2166,  5427],\n",
      "            [ 2054,  2038,  2000,  2022,  2550,  1999,  1037, 25697,  1997,  5292,\n",
      "              4783,  3022, 13931],\n",
      "            [ 2054,  2003,  1037,  2204,  2338,  2000,  3191,  2005,  2111,  2040,\n",
      "              5223,  2000,  3191]], device='cuda:0'), tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "            13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2186'], ['14'], ['3866'], ['1933'], ['127'], ['4319'], ['1769'], ['1266'], ['1762'], ['825'], ['5363'], ['2313'], ['3066'], ['3451'], ['3359'], ['1097'], ['5182'], ['4089'], ['3141'], ['3384'], ['1718'], ['3662'], ['445'], ['5444'], ['242'], ['219'], ['2939'], ['5373'], ['319'], ['5381'], ['1934'], ['3460']],\n",
      "    text: (tensor([[ 2054,  3696,  2003,  1996,  2190,  2293,  2674,  2005,  1037,  7570,\n",
      "              7352, 16186,  3696],\n",
      "            [ 2054,  2003,  2641,  1996,  3465, 21292,  7071,  1996,  5427,  3068,\n",
      "              2038,  2412,  4320],\n",
      "            [ 2054,  2210,  2417,  2482,  2003,  3855,  1999,  3769,  3220,  3159,\n",
      "              1055,  2718,  2299],\n",
      "            [ 2054,  2003,  1996, 13104,  2466,  4953,  5055, 17415,  1998,  5055,\n",
      "              1999,  4234,  3628],\n",
      "            [ 2054, 13675,  7828,  2121,  2587,  1996,  9261,  5208,  2005,  8779,\n",
      "              5308,  2378,  9588],\n",
      "            [ 2054,  5816,  1997,  6688,  2000,  4877, 29578,  5421,  2162,  1998,\n",
      "              3521,  2809,  2335],\n",
      "            [ 2054,  2003,  7150, 10654,  8591,  1055,  2535,  1999,  1996,  2047,\n",
      "              2732,  5233, 28280],\n",
      "            [ 2129,  2172,  5949,  2515,  2019,  2779, 11825, 11190,  3965,  1999,\n",
      "              1037,  2154,     0],\n",
      "            [ 2054,  5522,  2395, 27566,  2015,  2007, 15607,  2533,  5324,  1998,\n",
      "             15479,  2015,     0],\n",
      "            [ 2054,  2103,  3506,  1996,  1057,  1055,  4075,  1997,  4013, 21162,\n",
      "              1998, 18503,     0],\n",
      "            [ 2339,  2079, 27681,  2015,  6170,  2012,  2274,  1051,  5119,  1999,\n",
      "              1996,  2851,     0],\n",
      "            [ 2339,  2106,  2585, 12849, 21898,  3198,  1996,  8495,  2005,  1037,\n",
      "              2773, 13151,     0],\n",
      "            [ 2171,  1996,  2093,  3837, 22416,  2011,  1996, 17617,  2015,  1999,\n",
      "              8348,  5888,     0],\n",
      "            [ 2040,  2003,  6857,  1055,  1998,  7087, 10105, 19099,  1055,  2412,\n",
      "              2439,  2767,     0],\n",
      "            [ 2054,  1057,  1055,  5205,  2320,  2209,  3455,  2005,  1996,  2047,\n",
      "              2259, 27817,     0],\n",
      "            [ 2054,  1055,  1996,  2670,  9841,  2081,  1997, 14695,  2235, 20014,\n",
      "              4355, 10586,     0],\n",
      "            [ 2054,  2882,  9555,  5439,  2977,  2347,  1056,  2218,  2090,  3878,\n",
      "              1998,  3386,     0],\n",
      "            [ 2054,  1055,  1996,  2117,  2087,  2109,  4028,  5195,  1999,  1996,\n",
      "              1057,  1055,     0],\n",
      "            [ 2054,  8682,  2039,  2012,  2697, 10510,  2047,  3933,  2006,  2089,\n",
      "              1020,  3355,     0],\n",
      "            [ 2054,  1055,  1996,  9183,  2744,  2005,  1996, 13563, 13548,  1997,\n",
      "              1037,  9983,     0],\n",
      "            [ 2054, 13552,  3092,  2007,  1037,  3510,  1999,  5612,  2006,  2233,\n",
      "              2538,  6607,     0],\n",
      "            [ 2000,  2131,  1996,  2087, 24689,  7959,  3170,  2054, 14904,  2323,\n",
      "              1045,  4392,     0],\n",
      "            [ 2054,  2299,  2366,  2004,  1996,  5494,  4323,  1997,  1996,  5206,\n",
      "              5356,  2265,     0],\n",
      "            [ 2054,  2106,  2990,  3863,  2007,  1996, 14998,  2005,  1037,  9210,\n",
      "              1997, 13435,     0],\n",
      "            [ 2129,  2116,  2148,  2137,  3032,  2031,  1996,  3661,  1062,  1999,\n",
      "              2037,  3415,     0],\n",
      "            [ 2054,  3029,  1055,  4822,  2020,  3714,  2046,  2012,  2300,  5867,\n",
      "              1999,  3285,     0],\n",
      "            [ 2054,  2003,  1996,  4435,  2171,  1997,  1996,  5072,  5477,  5740,\n",
      "              5831,  3207,     0],\n",
      "            [ 2054,  2616,  1999,  1996,  2394,  2031,  2048,  1057,  1055,  2067,\n",
      "              2000,  2067,     0],\n",
      "            [ 2054,  2194, 21628, 18969,  1996, 17069,  1999,  6830,  2005,  1996,\n",
      "              2914,  2982,     0],\n",
      "            [ 2054,  4475,  2106,  1996,  2093,  2210, 14695,  2224,  2000,  3857,\n",
      "              2037,  3506,     0],\n",
      "            [ 2054,  2024,  1996,  2088,  1055,  2093,  2922, 17401,  1999,  2344,\n",
      "              1997,  2946,     0],\n",
      "            [ 2054,  2106,  3235,  9678,  2695,  2006,  1996,  2277,  2341,  2012,\n",
      "             15966, 21806,     0]], device='cuda:0'), tensor([13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "            12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4428'], ['1983'], ['2138'], ['465'], ['797'], ['5257'], ['1029'], ['1041'], ['2080'], ['1854'], ['480'], ['3083'], ['1415'], ['3829'], ['77'], ['3931'], ['1468'], ['128'], ['2085'], ['2967'], ['2747'], ['1282'], ['1629'], ['133'], ['1374'], ['4206'], ['4567'], ['1683'], ['1476'], ['1594'], ['2207'], ['3818']],\n",
      "    text: (tensor([[ 2054,  4773,  4573,  2024,  5799,  2000,  1996,  3189,  2006, 11046,\n",
      "              6422, 16302],\n",
      "            [ 2054,  2106,  2198,  1042,  5817,  5136,  2010,  4602, 14154, 11563,\n",
      "              1999,  2436],\n",
      "            [ 2054,  2744,  2965,  1037,  4424,  8432,  2090,  1037,  3287,  1998,\n",
      "              1037,  2931],\n",
      "            [ 1999,  2054,  2181,  1997,  1996,  2088,  2001,  1996,  2416,  2154,\n",
      "              2162,  4061],\n",
      "            [ 1996,  3059,  3063,  5003,  9496, 12426, 21877,  6216, 24860,  2003,\n",
      "              2129,  2214],\n",
      "            [ 2054,  2515,  1037,  2158,  6114,  2013, 16510,  9892,  2594, 28774,\n",
      "              6790,  2031],\n",
      "            [ 2054,  2024,  1996,  3415,  1997,  2035,  1996,  1057,  1055,  3212,\n",
      "              2948, 11363],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  2744,  1996,  6613,  2217,\n",
      "              1999,  9116],\n",
      "            [ 2054,  2024,  1996,  3284,  7079, 10238,  2006,  1037, 20996,  9307,\n",
      "              4674,  2795],\n",
      "            [ 2054,  2020,  1996,  2093, 17678,  5369,  9243,  1996, 12566,  2191,\n",
      "              2000, 25182],\n",
      "            [ 2054,  2079, 10506, 26736,  2015,  2079,  1999, 13675,  2319,  9766,\n",
      "             22132,  2015],\n",
      "            [ 2054,  2020,  8670, 15379, 10424, 16429,  4509,  2121,  1998,  5951,\n",
      "              2559,  2005],\n",
      "            [ 2054,  2064,  2017,  2022, 16981,  2005,  2383,  1037,  3899,  2006,\n",
      "              1037,  3509],\n",
      "            [ 2054,  2024,  1996,  3415,  1997,  7445,  2522, 19966, 10207,  1055,\n",
      "              2048,  4124],\n",
      "            [ 1996, 13931,  2655,  2891,  2819,  2003,  1999,  2054,  2112,  1997,\n",
      "              1996,  2303],\n",
      "            [ 2054,  8511, 10423,  2001,  2915,  2757,  2648,  1037,  7756, 27308,\n",
      "              1999,  2089],\n",
      "            [ 2029,  2557,  3703,  2250,  1996,  3958,  8945,  4819,  8540,  2557,\n",
      "              2831,  2265],\n",
      "            [ 2054,  3682,  2194,  4447,  2049,  4031,  2003,  1996,  6602,  1997,\n",
      "              1996, 26796],\n",
      "            [ 2054,  2515,  1996,  1039,  3233,  2005,  1999,  1996,  8522,  1041,\n",
      "             11338,  2475],\n",
      "            [ 2129,  2116,  2053,  6998,  2001,  1996,  2054,  1055,  2026,  2240,\n",
      "              5997,  3039],\n",
      "            [ 2054,  2148,  3060,  3135,  2018,  1037,  2997,  5618,  1997,  6640,\n",
      "              2575,  2454],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  2026,  2126,  2517,  2011,  2703,\n",
      "              2019,  2912],\n",
      "            [ 2171,  1996,  2176,  3441,  4838,  1999, 13257, 24249,  1055,  2214,\n",
      "              2047,  2259],\n",
      "            [ 2054,  5365,  3899,  2351,  1999,  1996,  2608,  1997,  3744, 22545,\n",
      "              1999,  4673],\n",
      "            [ 2054,  2106,  2720, 23848,  9541, 13109,  8649,  2006,  2694,  2005,\n",
      "              2236,  3751],\n",
      "            [ 2054,  2161,  2515,  1037,  7632, 14545,  2140,  4023,  5373,  2202,\n",
      "              2173,  1999],\n",
      "            [ 2054,  2001,  1996,  2171,  1997, 15462, 22132,  8445,  1055,  2252,\n",
      "              1999, 24592],\n",
      "            [ 2054,  3047,  1999,  3899,  4665,  1999,  6166,  2000,  2191,  2008,\n",
      "              2095,  4622],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  3813,  2008,  3084, 11867,\n",
      "             19042,  2618],\n",
      "            [ 2054,  2079,  1045,  2655,  1996,  4124,  1998,  5727,  1997,  2026,\n",
      "              2034, 12334],\n",
      "            [ 2073,  2515,  1996,  6881,  4338,  1997,  1996,  4596,  3869,  5442,\n",
      "             21754,  2013],\n",
      "            [ 2054,  6804,  3084,  1037, 21688,  9004,  2130,  2056,  2000,  6807,\n",
      "              2049,  3040]], device='cuda:0'), tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "            12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [5],\n",
      "            [4],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1058'], ['3283'], ['5'], ['3492'], ['2379'], ['769'], ['3554'], ['3076'], ['3140'], ['1349'], ['3038'], ['4442'], ['1940'], ['3757'], ['3299'], ['3809'], ['5298'], ['3917'], ['2609'], ['2273'], ['4456'], ['2608'], ['5245'], ['2292'], ['1984'], ['1786'], ['1961'], ['2143'], ['4894'], ['2067'], ['589'], ['1424']],\n",
      "    text: (tensor([[ 1999,  2029,  4901,  3465,  3678,  3185,  2106, 16615,  6505,  2377,\n",
      "              1037,  2535],\n",
      "            [ 2054,  2024,  2017,  3236,  1999,  2065,  1037,  5292,  5092, 16429,\n",
      "             13783,  2039],\n",
      "            [ 2054, 17152,  7028,  8040, 28819, 16570, 10312,  1996,  8513,  2013,\n",
      "              2026,  6265],\n",
      "            [ 2054,  2003,  1996,  4602,  3120,  1997,  2317,  3894,  1999,  1996,\n",
      "              8348,  5304],\n",
      "            [ 2054,  2003,  1996, 12066,  2744,  2109,  2005,  1996,  2120,  4879,\n",
      "              1997,  4812],\n",
      "            [ 2029,  2606,  2729,  4031,  2409,  2149,  5223,  2008,  3897,  9378,\n",
      "              2009,  2185],\n",
      "            [ 2054,  2048,  6470,  4061,  1996,  2034,  2712,  2645,  2090,  3707,\n",
      "              3139,  3719],\n",
      "            [ 2054,  2003,  1996, 13296,  3252,  1997,  1996,  2047,  6768, 28232,\n",
      "             12338,  3199],\n",
      "            [ 2171,  1037,  3185,  2008,  1996,  3883, 12834, 25200,  2018,  1037,\n",
      "              2535,  1999],\n",
      "            [ 2054,  2079,  1996,  4144,  1040,  1039,  3233,  2005,  1999,  2899,\n",
      "              1040,  1039],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  8235,  2329, 11708,  2369,\n",
      "              2049,  4325],\n",
      "            [ 2040,  6791,  2492,  8610, 22209, 17083, 10199,  1999,  1996,  5532,\n",
      "              4419,     0],\n",
      "            [ 2054,  2001,  1996,  2171,  1997, 17484,  2006, 12054,  2483,  1055,\n",
      "             12187,     0],\n",
      "            [ 2054,  1055,  1996,  2087, 10059, 18767,  2266,  1997,  1996, 20949,\n",
      "              2155,     0],\n",
      "            [ 2006,  2054,  3927,  2003,  1996,  2434,  7842,  5705,  2533,  3573,\n",
      "              2284,     0],\n",
      "            [ 2054,  4708,  2515,  1996,  8945,  2226, 14356,  8843,  1997,  3899,\n",
      "              4685,     0],\n",
      "            [ 2129,  2146,  2323,  2017,  5438,  2115, 17022, 16405, 11796, 17022,\n",
      "             20209,     0],\n",
      "            [ 2054,  2020,  1996,  3415,  1997,  1996,  2093,  3719,  2109,  2011,\n",
      "              8912,     0],\n",
      "            [ 2054,  2003,  1996, 10014,  2369,  1996, 11173,  1999,  1996,  3239,\n",
      "              2170,     0],\n",
      "            [ 2054,  3609, 10029,  7541,  2000,  1996,  3095,  2006,  5706,  1055,\n",
      "              5210,     0],\n",
      "            [ 2054,  2350,  8582,  2038,  1996,  2190,  3808,  2501,  1999,  1996,\n",
      "              2088,     0],\n",
      "            [ 2054,  3573,  4447,  2000,  2022,  1996,  2088,  1055,  2922,  2533,\n",
      "              3573,     0],\n",
      "            [ 1999,  2054,  2406,  2003,  1037,  5881,  2041,  4416,  1037,  5379,\n",
      "             14806,     0],\n",
      "            [ 2054,  8316,  2001,  8826,  2011,  1039,  1039, 17454,  2063,  1999,\n",
      "              4437,     0],\n",
      "            [ 2054,  1055,  1996, 22498,  2005, 13012,  3490, 13181,  3406,  7630,\n",
      "              8625,     0],\n",
      "            [ 2054,  2299,  2106, 22732,  3931,  2275,  2111,  5613,  2000,  1999,\n",
      "              3925,     0],\n",
      "            [ 2054,  2024,  1996,  5640, 16371, 28990,  2015,  2013,  1015,  2000,\n",
      "              2184,     0],\n",
      "            [ 2054,  4153,  2001, 11556,  4540, 10686,  3909,  2058,  2043,  2016,\n",
      "              5419,     0],\n",
      "            [ 2054,  2024,  1996,  2034,  1998,  2197,  4144,  1997,  1996,  3306,\n",
      "             12440,     0],\n",
      "            [ 2054,  2003,  1996, 12066,  2433,  1997,  1996,  2120,  4879,  1997,\n",
      "              4812,     0],\n",
      "            [ 2043,  3752,  6219, 14997,  2054,  2515, 25212, 29405,  2060,  3233,\n",
      "              2005,     0],\n",
      "            [ 1996,  8956,  2015,  3390,  2037,  2886,  2006, 13085,  2006,  2054,\n",
      "              2154,     0]], device='cuda:0'), tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [5],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [5],\n",
      "            [5],\n",
      "            [4]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1737'], ['3330'], ['761'], ['4474'], ['4491'], ['328'], ['688'], ['4113'], ['4188'], ['4639'], ['2255'], ['3721'], ['5164'], ['1168'], ['977'], ['832'], ['5255'], ['4231'], ['1248'], ['2640'], ['3921'], ['4929'], ['1955'], ['3775'], ['652'], ['3278'], ['2968'], ['968'], ['3709'], ['3081'], ['4414'], ['830']],\n",
      "    text: (tensor([[ 1999,  2054,  2110,  2001,  2045,  2019,  2340,  2454, 25234,  3514,\n",
      "             14437],\n",
      "            [ 2054,  2024,  1996,  2327,  2702,  2035,  2051,  2769,  2437,  5088,\n",
      "              2780],\n",
      "            [ 2339,  2001,  1996,  1048,  1037,  2436,  1997, 16994,  1998, 14913,\n",
      "              2701],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  6084,  2090,  4701,  1998,\n",
      "              6435],\n",
      "            [ 2054,  2020,  8817,  1997,  4268,  4147,  2006,  2037,  4641,  1999,\n",
      "              3982],\n",
      "            [ 2029, 13426,  2221,  6319, 23277, 25508,  2015, 22156,  2007,  1037,\n",
      "              3274],\n",
      "            [ 1999,  2054,  4386,  2399,  2106, 14942, 16571,  2638,  6895,  2468,\n",
      "              2759],\n",
      "            [ 2054,  2001,  1996, 14429,  8658,  1997,  2762,  1055,  1057,  1016,\n",
      "              6982],\n",
      "            [ 2054,  7433,  9560,  3463,  2043,  1037,  2447,  2038,  2053,  3423,\n",
      "              2693],\n",
      "            [ 2129,  2106,  3565,  2343,  5114,  2010,  4204,  2006,  1996,  6579,\n",
      "              2186],\n",
      "            [ 2054,  2003,  1996, 11749,  1997,  1037,  2899, 12281,  4939,  1055,\n",
      "              5470],\n",
      "            [ 2054,  2001,  1996,  8320,  2075,  5390,  1997,  1996,  2220,  2137,\n",
      "             24517],\n",
      "            [ 2054,  1055,  1996,  4489,  2090,  1056,  6199,  1998,  7037, 13594,\n",
      "              4653],\n",
      "            [ 2054,  3042,  2193,  2064,  1045,  2655,  2000,  2031,  1037,  3392,\n",
      "              8461],\n",
      "            [ 2054,  2515,  2643,  3443,  1999,  1996,  2034,  6251,  1997,  1996,\n",
      "              6331],\n",
      "            [ 2054,  2024,  2070, 10247,  2005,  2311,  1037,  2543,  1999,  1037,\n",
      "             13788],\n",
      "            [ 2054,  2020,  1996,  2197,  3415,  1997, 20067,  2015, 12220,  1998,\n",
      "             12085],\n",
      "            [ 2054,  2450,  8070,  2038,  4930,  2041,  6945,  3766,  1998,  9180,\n",
      "              7158],\n",
      "            [ 2054,  2406,  1998,  2530,  3220,  2003,  2124,  2004,  1996,  3165,\n",
      "              4419],\n",
      "            [ 2054,  2024,  1996,  9530,  9103, 12540,  2015,  1997,  5256,  1998,\n",
      "              8271],\n",
      "            [ 2054,  2003, 10173,  2000,  2327, 10814,  2058,  2090,  2230,  1998,\n",
      "             12609],\n",
      "            [ 2054,  2064,  1045,  2079,  2000,  2131,  2046,  2019,  7768,  2223,\n",
      "              2082],\n",
      "            [ 2129,  2064,  1045,  4089,  6366,  2417,  4511, 27094,  2013,  1056,\n",
      "             11344],\n",
      "            [ 2129,  2515,  2833,  3609,  7461,  2129,  2017,  2228,  2009,  2097,\n",
      "              5510],\n",
      "            [ 2054,  2003,  1996,  5583,  1997,  2659,  3778,  2105,  1996, 26640,\n",
      "              2170],\n",
      "            [ 2171,  1996,  2413,  3439,  2558,  2076,  1996,  5853,  1997,  8891,\n",
      "              3523],\n",
      "            [ 2054,  2003,  1996,  2986,  2005,  2383,  1037,  3899,  2006,  1037,\n",
      "              3509],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1037,  5439,  2607,  1999, 21381,\n",
      "              3509],\n",
      "            [ 2129,  2515,  9388,  2140,  2433,  1998,  2054,  9754,  2515,  2009,\n",
      "              5383],\n",
      "            [ 2040,  1055,  3336,  2001,  4086, 26034,  2006,  1996,  4831,  6672,\n",
      "              9476],\n",
      "            [ 2054,  1055,  1996,  2248,  2557,  3642,  2773,  2005,  1996,  3661,\n",
      "              1042],\n",
      "            [ 2054,  2047,  2690,  2082,  2001,  2328,  1999,  4407,  3552,  2197,\n",
      "              2095]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5287'], ['3705'], ['2754'], ['969'], ['3816'], ['4200'], ['3407'], ['3192'], ['2287'], ['103'], ['2783'], ['3099'], ['5108'], ['3905'], ['2394'], ['4651'], ['5123'], ['4627'], ['2350'], ['1564'], ['1140'], ['3794'], ['4730'], ['4299'], ['1236'], ['2161'], ['3387'], ['3122'], ['4844'], ['1724'], ['424'], ['3630']],\n",
      "    text: (tensor([[ 2054,  2079,  1037,  6323,  1998, 15116,  1997,  5317,  2031,  1999,\n",
      "              2691],\n",
      "            [ 2054,  3754,  2038,  1996,  6953, 22769,  5820,  2439,  2083,  4968,\n",
      "              3370],\n",
      "            [ 2054,  1055,  1996,  2197,  2240,  1997, 19675,  1055,  1037,  4234,\n",
      "              8594],\n",
      "            [ 2054,  2024,  2070,  1997,  1996,  3278,  3439,  2824,  1997,  1996,\n",
      "              4134],\n",
      "            [ 2054,  2003, 12101, 11113,  9759,  2290,  1055, 18906, 29469,  2389,\n",
      "             11749],\n",
      "            [ 2054,  2001,  1996,  1058,  1022, 10869, 14558,  1996,  5510,  8569,\n",
      "              2094],\n",
      "            [ 2054,  2097,  1996,  2662,  3806,  4171,  2022,  1999,  1996,  2095,\n",
      "              2456],\n",
      "            [ 2054,  2001,  3157, 22701,  2015,  1996,  2547,  2265,  2013,  3326,\n",
      "              2055],\n",
      "            [16994,  1998, 14913,  2701,  2037,  3050,  3349,  2436,  2005,  2054,\n",
      "              3114],\n",
      "            [ 2054,  2785,  1997,  4176,  2020,  1999,  1996,  5122, 18153, 19419,\n",
      "              3690],\n",
      "            [ 2054,  2177,  2356,  1996,  3315,  3160,  2079,  2017,  2903,  1999,\n",
      "              3894],\n",
      "            [ 2054,  1057,  1055,  2110,  2038, 10878, 18623,  2004,  2049,  2110,\n",
      "              6546],\n",
      "            [ 2054,  2123, 17602,  2299, 20342,  7666,  1996,  2154,  8937,  9079,\n",
      "              2351],\n",
      "            [ 2054,  2079,  4500,  5344,  1997,  1037,  3280,  2467,  5587,  2039,\n",
      "              2000],\n",
      "            [ 2054,  2001,  1996, 14392,  1999,  1996,  3979,  1997, 15860,  8945,\n",
      "             18246],\n",
      "            [ 2171,  1997,  1996,  3203,  1996,  2307, 11721,  3215,  3762, 17527,\n",
      "              2005],\n",
      "            [ 2029,  5396,  2003, 10654,  3468,  2078,  1996,  2034,  4823, 11762,\n",
      "              1999],\n",
      "            [ 2054,  2450,  2001,  2051,  1055,  2158,  1997,  1996,  2095,  2005,\n",
      "              3999],\n",
      "            [ 2054,  3867,  1997,  2088,  1055,  4840,  2300,  2003,  2179,  1999,\n",
      "              2710],\n",
      "            [ 2054,  2003,  1996,  3382,  1997,  9530,  3401, 14966, 17718, 21531,\n",
      "             13461],\n",
      "            [ 2054,  2001, 21127,  1055,  6226,  5790,  2044,  2184,  2086,  1999,\n",
      "              2373],\n",
      "            [ 2054,  2003,  1996,  3091,  1997,  3675,  2090,  1996,  5924,  1998,\n",
      "              3607],\n",
      "            [ 2129,  2079,  1045,  2113,  2129,  2172,  2769,  2000,  3828,  2005,\n",
      "              5075],\n",
      "            [ 2054,  2024,  2111,  2725,  2000,  2393,  4652,  1996, 14446,  1997,\n",
      "              5055],\n",
      "            [ 2054,  2024,  1996,  2350,  5966,  1999,  1996,  3234,  1998,  8938,\n",
      "             11822],\n",
      "            [ 1999,  1996,  4679,  5507,  2063,  2694,  3293,  2040,  2003,  1996,\n",
      "              6492],\n",
      "            [ 2054,  2003,  1996,  2364,  4646,  1997, 13365, 18479, 23722,  8873,\n",
      "              2618],\n",
      "            [ 1996,  7012,  4525,  2013,  2088,  2162,  2462,  2024,  2124,  2004,\n",
      "              2054],\n",
      "            [ 2054,  2171,  2106,  2374,  1055,  2047,  2259, 13785, 11092,  1999,\n",
      "              3699],\n",
      "            [ 2054,  2931,  5276,  2550, 10968,  2015,  1997,  3541,  2047,  2563,\n",
      "              2166],\n",
      "            [ 2054,  2024,  2070,  5875,  8866,  1998,  2592,  2055,  6077,  3709,\n",
      "              4667],\n",
      "            [ 2981,  3165, 21405,  1055,  4070,  2005,  2054,  7017,  1997,  3165,\n",
      "              2537]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2588'], ['2728'], ['5337'], ['2892'], ['1894'], ['4202'], ['870'], ['3211'], ['3075'], ['613'], ['639'], ['1550'], ['4615'], ['1612'], ['3235'], ['542'], ['5008'], ['3919'], ['2781'], ['1005'], ['3009'], ['1139'], ['3271'], ['4105'], ['3899'], ['2099'], ['2280'], ['1642'], ['5435'], ['3328'], ['4421'], ['5269']],\n",
      "    text: (tensor([[ 2054,  5021,  6167,  2823,  2838,  1037,  5653,  2386,  2315, 26892,\n",
      "              8002],\n",
      "            [ 2054,  2003,  1996,  2299, 21952,  2000,  6014,  2011,  2419, 22116,\n",
      "              2055],\n",
      "            [ 2054,  1055,  1996,  2690,  2171,  1997,  3185,  3135,  3312,  1041,\n",
      "             17780],\n",
      "            [ 2054,  2024,  1996,  2087,  4042,  2853,  2011,  2028,  3063,  2030,\n",
      "              2316],\n",
      "            [ 2054,  2161,  4269,  2007,  1996,  2310, 12789,  2140,  1041, 12519,\n",
      "             11636],\n",
      "            [ 2054,  3661,  2515,  2175, 28483, 16179,  1055,  2690,  2171,  2707,\n",
      "              2007],\n",
      "            [ 2029,  6359, 13156,  2351,  2012,  2712,  2088,  1997,  1037, 28079,\n",
      "              8985],\n",
      "            [ 2054,  2020,  1996,  5103,  7443,  2066,  2076,  1996,  3870,  2937,\n",
      "              2335],\n",
      "            [ 2054,  2024,  1996,  3901,  1997,  1996,  2479,  1997,  4649, 15853,\n",
      "              2170],\n",
      "            [ 2054,  3696,  2003,  1996,  2300,  6839,  1996, 28501,  2389,  6454,\n",
      "              2005],\n",
      "            [ 2054,  2154,  1997,  1996,  2733,  5927,  1996,  2087, 10611,  2482,\n",
      "             13436],\n",
      "            [ 2054,  2024,  1996,  5751,  1997,  1037,  2406,  2183,  2046,  1037,\n",
      "             19396],\n",
      "            [ 2171,  1996,  2273,  1055, 10918,  2008,  2003,  3378,  2007,  1996,\n",
      "              2712],\n",
      "            [ 2054,  2785,  1997,  1037,  2998,  2136,  2003,  1996,  5273, 24186,\n",
      "              2015],\n",
      "            [ 2054,  2311,  2328,  1999,  2324,  3397, 28469,  2661,  1997,  2338,\n",
      "             15475],\n",
      "            [ 2054,  2024,  1996,  5664,  3558,  3494, 14606,  1997,  1996, 13771,\n",
      "              3586],\n",
      "            [ 2043,  2001,  1996,  2034,  3144,  2540, 22291,  2005,  1037,  2529,\n",
      "                 0],\n",
      "            [ 2073,  2064,  1045,  2424,  1996,  3570,  1997,  2026,  4171,  2709,\n",
      "                 0],\n",
      "            [ 3005, 22590,  2075,  2001, 12061,  1996,  4126,  1997,  1996,  2301,\n",
      "                 0],\n",
      "            [ 2054,  3297,  4823, 11762,  8617,  1996,  2662,  7048,  3598,  2136,\n",
      "                 0],\n",
      "            [ 2040,  2580,  1996,  6071,  1999,  2984, 15828,  1055,  3117, 22478,\n",
      "                 0],\n",
      "            [ 2054,  2406,  2001,  1996,  4292,  1997,  2017,  2069,  2444,  3807,\n",
      "                 0],\n",
      "            [ 2054,  2003,  1996,  8917,  2378,  1997,  1060, 11636, 11636, 11636,\n",
      "                 0],\n",
      "            [ 2073,  2064,  1045,  2424,  2489,  3682,  7644,  2005,  2759,  2189,\n",
      "                 0],\n",
      "            [ 2054,  5983, 21183,  6132, 12146,  2024,  2109,  2005, 26920,  4268,\n",
      "                 0],\n",
      "            [ 2054,  1055,  1996,  2248, 10168,  5093,  4119,  5384,  2788,  2170,\n",
      "                 0],\n",
      "            [ 2054,  2003,  1037, 19130,  2606,  8248,  2941,  2081,  2041,  1997,\n",
      "                 0],\n",
      "            [ 2054,  1055,  1996,  4489,  2090,  1046,  1040,  1998,  2222,  1049,\n",
      "                 0],\n",
      "            [ 2054,  2111,  2191,  2039,  2431,  1996,  3354,  2586,  1055,  2313,\n",
      "                 0],\n",
      "            [ 2054,  2024,  1996,  5918,  2005,  3352,  1037,  6926,  1997,  2660,\n",
      "                 0],\n",
      "            [ 1999,  7813,  8925,  2064,  2017,  2171, 18906,  3351,  1055,  3899,\n",
      "                 0],\n",
      "            [ 2054,  2081,  1996,  2460,  2973,  2732, 12505,  6167,  2061,  4310,\n",
      "                 0]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10,\n",
      "            10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1413'], ['1976'], ['3573'], ['268'], ['3337'], ['1566'], ['2295'], ['2715'], ['1100'], ['2466'], ['4845'], ['3385'], ['3539'], ['611'], ['616'], ['4353'], ['1840'], ['3040'], ['1493'], ['2645'], ['1557'], ['2285'], ['4836'], ['2195'], ['2633'], ['3913'], ['4662'], ['5176'], ['4415'], ['4841'], ['3543'], ['5099']],\n",
      "    text: (tensor([[ 2054,  3699,  3312,  1048,  2158, 28563,  2143,  3465,  2654,  2454],\n",
      "            [ 2054,  2003,  6334,  2076,  1996,  2733,  1997,  2337,  2538,  2676],\n",
      "            [ 2029,  1057,  1055,  2343,  2003,  3950,  1999,  2899,  1040,  1039],\n",
      "            [ 2000,  2054,  2515,  7513,  1055,  3645,  1017, 12533,  2049,  3112],\n",
      "            [ 2029, 13297,  2106,  6904,  4213,  2480,  2017,  8977,  7632, 17364],\n",
      "            [ 2054,  3032,  2031,  1996,  2922,  4273,  2749,  1999,  1996,  2088],\n",
      "            [ 2054, 27701,  6743,  2003,  1999,  3002,  2848,  1055,  5040, 13546],\n",
      "            [ 2054,  2001,  2632,  6178,  5643,  2633,  8580,  2005,  1999,  4739],\n",
      "            [ 2054,  2003,  1996,  4654,  8586, 16161,  2099,  1999,  1037,  2097],\n",
      "            [ 2054,  4153, 11197,  5296,  1998,  7569,  1999,  4291,  4290,  6496],\n",
      "            [ 2054,  2931,  8343,  1999,  1996,  2208,  1997,  9789,  2003,  2309],\n",
      "            [ 2054,  3827,  2003,  2179,  1999,  9808, 11493,  2075,  2047,  2259],\n",
      "            [ 1999,  4748, 25897,  2054,  4066,  1997, 12035, 10069,  2020,  2045],\n",
      "            [ 2040,  2351,  1015,  2519,  2013,  2073,  2198,  1042,  5817,  2106],\n",
      "            [ 2043,  2003,  1996,  2609,  7479,  3980,  4012,  2183,  2000,  2330],\n",
      "            [ 2054,  2003,  2921,  1999,  3481, 11994,  2008,  2003,  2061,  7070],\n",
      "            [ 2054, 15607,  2414,  4735,  2457,  2001,  2320,  1037, 16708,  3317],\n",
      "            [ 2054,  2003,  2009,  2066,  2000,  3325,  1037,  2379,  2331,  2792],\n",
      "            [ 2054,  2003,  4097,  8226,  4917,  1055,  7203,  2158,  7203,  2007],\n",
      "            [ 2054,  2024,  2198,  1039, 22982,  1998,  2888,  5726,  2124,  2004],\n",
      "            [ 2054,  2003,  1996,  2394,  5449,  2005,  1996,  2773, 10250, 25099],\n",
      "            [ 2054,  2079,  1045,  2342,  2000,  4553,  2000,  2640,  4773,  5530],\n",
      "            [ 2054,  2003,  1996,  6149,  2126,  2000,  2224,  2089,  5443,  2453],\n",
      "            [ 2054,  4435,  1997,  2317, 19379,  2003,  2145,  2081,  1999,  7394],\n",
      "            [ 2054,  2154,  2003,  2124,  2004,  1996,  2120,  2154,  1997,  7083],\n",
      "            [ 2054,  2106,  1996,  3418,  2015,  2655,  1996,  2176,  2307,  3787],\n",
      "            [ 2129,  2106,  1996,  2706,  1997,  1996,  2095,  2131,  2045,  2171],\n",
      "            [ 2073,  2106,  1996,  2943,  2005,  1996,  2502,  9748,  2272,  2013],\n",
      "            [ 2054,  2024,  1996,  2654,  9049,  2015,  1999,  1996,  2394,  2653],\n",
      "            [ 2054,  2003,  5003,  9496, 12426, 21877,  6216, 24860,  1055,  2287],\n",
      "            [ 2073,  2003,  1996,  7778, 10061,  1997,  1996,  2142,  2163,  3784],\n",
      "            [ 2054,  2003,  1037, 11375,  1997, 19021, 28173, 16940,  3401,  4570]],\n",
      "           device='cuda:0'), tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "            10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3],\n",
      "            [2]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2011'], ['3418'], ['4021'], ['2125'], ['1727'], ['3091'], ['4586'], ['4610'], ['9'], ['1968'], ['512'], ['3005'], ['3118'], ['1356'], ['1286'], ['3658'], ['3045'], ['3111'], ['2216'], ['2332'], ['1709'], ['3232'], ['1394'], ['1759'], ['1554'], ['614'], ['1416'], ['1543'], ['5297'], ['820'], ['3051'], ['4339']],\n",
      "    text: (tensor([[ 2054,  2024,  7861, 28522, 15975,  2094,  2006,  1996, 22193,  5074],\n",
      "            [ 2054,  2003,  1996,  4489,  2090,  1037,  2267,  1998,  1037,  2118],\n",
      "            [ 2054,  2282,  2106,  1059,  1039,  4249,  2562,  2010,  3075,  1999],\n",
      "            [ 2054,  2592,  2064,  2017,  2425,  2033,  2055,  3364,  2508, 16759],\n",
      "            [ 2054,  2323,  2017, 14315,  2000, 16889,  1037, 10095,  1999,  6921],\n",
      "            [ 2054, 20121,  2003,  4202, 16589,  1055,  2307,  7006,  1997,  2643],\n",
      "            [ 2054,  2024,  2047,  3274,  2399,  2005,  3645,  5345,  2030,  5818],\n",
      "            [ 2054,  1055,  8200,  2055,  1037,  5340, 15457,  2094,  1055,  2519],\n",
      "            [ 2171,  1996, 11228,  4320, 17284,  4477,  1997,  1996,  2214,  2225],\n",
      "            [ 2054,  2001,  1996,  9560,  1997,  1996,  3386,  8038, 24458,  3034],\n",
      "            [ 2054,  2001,  1996,  2958,  1997,  2624,  6446, 12569,  2081,  1997],\n",
      "            [ 2054,  2081,  1996,  4344,  6597,  1999,  2530,  2047,  2259,  2110],\n",
      "            [ 2054,  2024,  2070,  5072,  5144,  1997,  2273,  9247,  6777,  5007],\n",
      "            [ 2054,  2515,  2019, 11209,  2618,  2482,  3954,  2655,  3707, 15772],\n",
      "            [ 2054,  1055,  1996,  2053,  1015,  6359,  1999,  3919,  3550,  3032],\n",
      "            [ 2054, 11938,  2030, 27885,  8043, 26711,  2024,  6334,  1999,  3304],\n",
      "            [ 2054,  4883,  3447,  8315,  4841,  2000,  8849,  1996,  2047,  8880],\n",
      "            [ 2054,  2003,  1996, 18937,  2005,  2111,  2040,  2113,  1996,  4489],\n",
      "            [ 2073,  2515,  1996,  1057,  1055,  2131,  2087,  1997,  2049,  2943],\n",
      "            [ 2129,  2980,  2515,  1996,  2503,  1997,  2019,  3161, 12779,  2131],\n",
      "            [ 2054,  2828,  1997,  9256,  2003, 17869,  5162, 26046,  6820, 22083],\n",
      "            [ 2073,  2064,  2017,  2424,  1996, 11691,  4875,  6494,  2361,     0],\n",
      "            [ 2054,  2515,  2169,  1997,  1996, 16548,  3465,  1999, 15404,     0],\n",
      "            [ 1037,  2522, 10623,  2072,  2003,  1037,  2785,  1997,  2054,     0],\n",
      "            [ 2054,  2524,  1997,  4994,  3063,  4993,  3103, 14156,  2015,     0],\n",
      "            [ 2054,  4176,  2079,  2017,  2424,  1999,  1996,  4518,  3006,     0],\n",
      "            [ 2073,  2106,  1996,  2645,  1997,  1996, 23708,  2202,  2173,     0],\n",
      "            [ 2054,  2097,  4148,  2043, 13365,  2003,  2404,  1999,  2300,     0],\n",
      "            [ 2129,  2116,  2020,  1999,  5270,  2012,  1996,  2197, 15264,     0],\n",
      "            [ 2129,  2116,  2706,  2515,  1037,  3671,  2529, 10032,  2197,     0],\n",
      "            [ 2129,  2079,  2017,  5466,  1037,  2160,  9028,  6562,  2283,     0],\n",
      "            [ 2054,  2479,  2003,  2188,  2000, 11342,  2170, 28566,  2015,     0]],\n",
      "           device='cuda:0'), tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "            10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4920'], ['1972'], ['4077'], ['2730'], ['1576'], ['1608'], ['1330'], ['3716'], ['5294'], ['1548'], ['2660'], ['3311'], ['27'], ['3393'], ['4071'], ['4695'], ['2139'], ['5070'], ['2916'], ['624'], ['5046'], ['1448'], ['1375'], ['4208'], ['1877'], ['5408'], ['439'], ['487'], ['4447'], ['278'], ['3352'], ['1084']],\n",
      "    text: (tensor([[ 2054,  5907,  2003,  2025,  3039,  2000,  3789,  1999, 13085],\n",
      "            [ 2054,  5320,  2064,  5484, 14699,  2015,  1999,  1996,  2677],\n",
      "            [ 2054,  2003,  1996,  2381,  1997,  1996,  2606, 21190,  2121],\n",
      "            [ 2054,  2024,  3724,  1998, 11211,  1999, 14910,  2361,  4210],\n",
      "            [ 2054,  2001,  1996,  8297,  2000,  1996,  4231,  1055, 13212],\n",
      "            [ 2054,  1055,  1996,  2117,  5221,  4855,  2932,  1999,  2637],\n",
      "            [ 2054,  2942,  2162,  2001,  4061,  2090,  4266,  1998,  3912],\n",
      "            [ 2171,  1996,  3435,  2833,  4677,  2007,  1996,  3585, 13540],\n",
      "            [ 2054,  2001,  1996,  3466,  1997,  1996,  8038, 24458,  3034],\n",
      "            [ 2054,  2024,  1996,  9646,  1997,  2019,  3256,  3873,  3125],\n",
      "            [ 2054,  2842,  2038,  1996, 25430, 14083,  7556,  2768,  2005],\n",
      "            [ 1999,  2054,  3971,  2106,  7332,  4921,  2490,  2845,  4935],\n",
      "            [ 2054,  2003,  1996,  3284, 14297,  1999,  1996,  2142,  2163],\n",
      "            [ 2054,  2003,  1996,  6493,  2314,  1999,  1996,  2142,  2163],\n",
      "            [ 2129,  2116, 16300,  2024,  2109,  1999,  8301, 26328,  2015],\n",
      "            [ 2054,  2003,  1996,  4587,  2311,  1999,  1996,  2142,  2163],\n",
      "            [ 2054,  2001,  2170,  1996,  2088,  1055,  2922,  2533,  3573],\n",
      "            [ 2129,  2079,  2017,  2424,  1996,  2181,  1997,  1037,  4418],\n",
      "            [ 1999,  2148,  4420,  2129,  2116,  2137,  3548,  2024,  2045],\n",
      "            [ 2054,  2003,  3021,  6733,  1997,  7513,  1041,  5653,  4769],\n",
      "            [ 2054,  2003,  1996,  2190,  2126,  2000,  3604,  1999,  2900],\n",
      "            [ 2004, 19362, 15464,  2063,  2003,  2036,  2124,  2004,  2054],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  1996,  3010,  2120, 11971],\n",
      "            [ 2054,  2003,  1996,  2088,  2501,  2005,  1996,  6493,  2606],\n",
      "            [ 2054,  2003,  1996,  2190,  3292,  2495,  2118,  2030,  2267],\n",
      "            [ 2054,  2442,  2022, 14872,  2000,  3965,  1037, 12728,  8797],\n",
      "            [ 2054,  3853,  2515,  1037,  2451,  1055,  2300,  3578,  3710],\n",
      "            [ 2054, 12991,  7751,  2003,  3621,  3805,  1997,  2049,  2051],\n",
      "            [ 2054,  2003,  4583,  2335,  4086,  2121,  2084, 11942,  5699],\n",
      "            [ 2054,  2003,  1996,  7290,  2504,  1997,  1996,  2137, 14814],\n",
      "            [ 2054,  2024,  1996,  6747,  2005, 15967,  6853,  1999,  5374],\n",
      "            [ 2054,  2003,  3725,  1055,  6664,  2006,  1996,  2822,  8240]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [4],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3367'], ['2076'], ['3589'], ['3642'], ['848'], ['4072'], ['3668'], ['1004'], ['775'], ['3399'], ['83'], ['709'], ['3855'], ['860'], ['2769'], ['4424'], ['5199'], ['1423'], ['2807'], ['4047'], ['3481'], ['3886'], ['2374'], ['3464'], ['413'], ['3326'], ['2145'], ['970'], ['211'], ['5424'], ['2677'], ['4507']],\n",
      "    text: (tensor([[ 2054,  2003,  1037, 10675,  2005,  2004, 19362, 15464,  2063],\n",
      "            [ 2054,  2457,  2515,  3960, 19133,  6235,  1999,  1996, 17937],\n",
      "            [ 2054,  5761,  2106,  7207,  2202,  2000,  4468,  1996,  4433],\n",
      "            [ 2054,  2158,  2081, 21938,  2003,  1015,  6146,  2661,  2146],\n",
      "            [ 2054,  2003,  1996,  2440,  2171,  1997,  1996, 20228,  2080],\n",
      "            [ 2054, 15644,  2024,  2045,  2005,  3633, 24260,  3436,  2668],\n",
      "            [ 2054,  2394,  3035,  2018,  2416,  3093,  2006,  2028,  2192],\n",
      "            [ 2054,  2001,  1996, 10200,  4823,  2177,  2005,  6060,  7369],\n",
      "            [ 2054,  3439,  2724,  3047,  1999,  3899,  4665,  1999,  6166],\n",
      "            [ 2054,  2576,  2283,  2003, 26403, 27132,  1037,  2112,  1997],\n",
      "            [ 2054,  2003,  1996,  8367,  2005,  1996,  2110,  1997,  5900],\n",
      "            [ 2129,  2521,  2064,  1037,  2158,  3604,  1999,  6058,  2686],\n",
      "            [ 2073,  2106,  1996,  2744,  2543, 24759, 15916,  2272,  2013],\n",
      "            [ 2054,  1057,  1055, 12295,  2056,  2562,  1996,  4752,  3336],\n",
      "            [ 2054,  2691, 11468,  2031,  1996,  4602,  3528,  1997, 15910],\n",
      "            [ 2339,  2106, 13481,  2034,  2272,  2000,  2660,  1998, 20526],\n",
      "            [ 2073,  1999,  1037,  3392,  2515,  7760,  6038, 25078,  5258],\n",
      "            [ 2054,  2024,  2070,  2590,  2824,  1997,  1996,  9500,  1055],\n",
      "            [ 2129,  2079,  2017,  2224,  8736,  2004,  4941,  2000,  2582],\n",
      "            [ 2054,  2003,  1996,  3185,  5655, 27656,  2712, 24848,  2140],\n",
      "            [ 2054,  1055,  1996,  3284,  2825,  7226,  1999,  3206,  2958],\n",
      "            [ 2054,  2003,  1996,  3274,  2005,  1996,  2717,  1997,  2149],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  5522,  4518,  3863],\n",
      "            [ 2054,  2323,  2017,  2079,  2005,  2019, 10792, 11867, 21166],\n",
      "            [ 2073,  2001,  1996,  5622, 27390,  2937,  3072, 14112, 15376],\n",
      "            [ 2054,  6759,  2024,  2218,  1999,  2047,  2259,  2023,  2733],\n",
      "            [ 2054,  6433,  2043,  7407,  9326,  1037,  2303,  1997,  2300],\n",
      "            [ 2171,  1996,  2069, 12905, 11544,  1997,  4556,  3306,  3248],\n",
      "            [ 2054,  2001,  1996,  2495,  2291,  1999,  1996,  3624,  1055],\n",
      "            [ 2054,  5404,  1055,  2171,  2003,  5421,  2004,  7006, 24702],\n",
      "            [ 2054,  2003,  1996,  2440,  5579,  1997,  1037,  3203, 11829],\n",
      "            [ 2054,  1055,  1996,  2087,  2691,  2395,  2171,  1999,  2637]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5195'], ['926'], ['3911'], ['91'], ['4023'], ['2241'], ['2479'], ['2325'], ['3363'], ['4577'], ['2966'], ['3971'], ['4144'], ['4852'], ['4712'], ['2234'], ['4998'], ['4366'], ['3726'], ['1698'], ['1832'], ['1669'], ['3030'], ['2509'], ['438'], ['2349'], ['2088'], ['1222'], ['4943'], ['4792'], ['1242'], ['2647']],\n",
      "    text: (tensor([[ 2054,  3573,  2515,  9246,  5954,  4748, 16874,  5562,  2005],\n",
      "            [ 2029,  2003,  1996,  2922,  5119,  6705,  7968,  1999,  2885],\n",
      "            [ 8042,  2234,  2000,  2373,  1999,  2762,  1999,  2054,  2095],\n",
      "            [ 2054,  5320,  1996,  2303,  2000, 13277,  1999,  3147,  7715],\n",
      "            [ 2054,  8942,  2839,  5906,  2105,  2006,  1037,  7151, 23490],\n",
      "            [ 2054,  2001,  2703, 21122,  7054,  1055, 23060,  1055,  2171],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  7437, 22962,  1055,  2316],\n",
      "            [ 2073,  2064,  1045,  4553,  2055,  5212,  2175,  8737,  2545],\n",
      "            [ 2054,  2003,  5622,  1048, 11113,  3678,  1055,  2197,  2171],\n",
      "            [ 2054,  2024,  1996,  2274,  2087,  2759,  2224,  7159,  2967],\n",
      "            [ 2054,  1055,  1996,  2087,  2691,  2171,  1999, 13640, 24468],\n",
      "            [ 2054,  2785,  1997,  6552,  2515,  1996, 22015,  2444,  1999],\n",
      "            [ 2073,  2003,  1996,  2880,  5717,  1997,  1996,  2712,  2504],\n",
      "            [ 2054,  2106, 19065,  5503,  2360,  2008,  2288,  2032,  4727],\n",
      "            [ 2073,  2003,  2028,  1055, 13931,  2655,  2891,  2819,  2179],\n",
      "            [ 2073,  2106,  9678,  4653,  2010, 13568,  2274,  2122,  2015],\n",
      "            [ 2054,  2003,  1996,  8674,  1997,  1037,  8254,  2063,  4400],\n",
      "            [ 2054,  2001,  2198, 14233, 12750,  1055,  8932,  7452, 20430],\n",
      "            [ 2054,  2003,  1996,  2166,  5987, 11656,  1997,  2019, 10777],\n",
      "            [ 2054,  2001,  1996,  2449,  1997,  1996,  6579,  3712, 12505],\n",
      "            [ 2054,  3226,  2764,  1996,  2801,  1997,  8962, 20051,  2818],\n",
      "            [ 2054,  2785,  1997,  3899,  2003,  8040,  9541,  3762, 20160],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1037,  3309,  1999,  9506],\n",
      "            [ 2054,  1055,  2047,  1999,  1996, 10690,  2088,  1999,  2639],\n",
      "            [ 2054,  2079, 12170, 27108, 12556,  4176,  2031,  2048,  1997],\n",
      "            [ 2054,  2210,  2879,  1998,  3899,  2444,  1999,  1037, 10818],\n",
      "            [ 2129,  2079,  2017,  5468,  1996,  3684,  1997,  1996,  3103],\n",
      "            [ 2054,  2024,  1996,  2034,  2702, 27950, 13665,  2015,  2979],\n",
      "            [ 2054,  2003, 11318,  2175, 28483, 16179,  1055,  2690,  3988],\n",
      "            [ 2054,  2001,  2198,  1042,  5817,  1055,  3624,  3049,  2299],\n",
      "            [ 2054,  2024,  1996,  2922, 18710,  3111,  1999,  1996,  2088],\n",
      "            [ 2054,  2024,  2070,  2204, 11110,  2005,  4268,  2000,  2079]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4199'], ['4432'], ['5447'], ['1023'], ['3940'], ['3830'], ['5062'], ['4910'], ['3750'], ['1750'], ['3562'], ['1602'], ['69'], ['983'], ['4638'], ['4498'], ['2987'], ['196'], ['3624'], ['5218'], ['3022'], ['921'], ['3292'], ['2935'], ['2422'], ['442'], ['4478'], ['4612'], ['4471'], ['3295'], ['4906'], ['2957']],\n",
      "    text: (tensor([[ 2054,  2106,  4658,  2192,  5355,  2175,  2000,  7173,  2005],\n",
      "            [ 2054,  2001, 14957,  2232, 12436,  4063,  1055,  2365,  2315],\n",
      "            [ 2054,  1055,  1996,  4338,  1997,  1037, 19130,  1055,  8560],\n",
      "            [ 2054,  2003,  5610,  2100,  1996,  4562,  1055,  2690,  2171],\n",
      "            [ 2054,  2003,  2178,  2171,  2005,  2379, 25807,  2098,  2791],\n",
      "            [ 2054,  2329,  2694,  2186,  4427,  2035,  1999,  1996,  2155],\n",
      "            [ 2029,  1997,  1996,  2698, 28984,  3310,  2034, 12440, 15004],\n",
      "            [ 2054,  2003,  1996,  5499, 13637,  2000,  1996,  2417,  2892],\n",
      "            [ 2054,  2001,  3533, 15125,  8988,  1055,  2034,  3206,  4276],\n",
      "            [ 2029,  4901,  3465,  3678,  3185,  7336,  1996, 16615,  6505],\n",
      "            [ 2054,  2828,  1997,  5593,  2106, 11044,  2310, 12119,  2031],\n",
      "            [ 2054,  2079, 19130,  2015,  3573,  1999,  2037, 14910,  4523],\n",
      "            [ 2054,  2024, 12731,  4095,  2386,  1998, 16045,  2124,  2005],\n",
      "            [ 2054,  2003,  2304,  4564,  2148,  7734,  2087,  3297,  2005],\n",
      "            [ 2040,  2001,  2641,  2000,  2022,  1996,  2269,  1997,  6825],\n",
      "            [ 2054,  2020,  1996,  2274,  3098,  2616,  2006,  3841,  9036],\n",
      "            [ 2054, 15300,  5836,  1037,  4477,  2007,  2252,  1998,  6099],\n",
      "            [ 2054, 24369,  2363,  2019,  5756,  3014,  2013,  7855,  2118],\n",
      "            [ 2054,  2003,  1996,  1058, 13626,  2140,  3231,  1997,  2668],\n",
      "            [ 2054,  2194,  1055, 11749,  2001,  2010,  3040,  1055,  2376],\n",
      "            [ 2054,  2106,  1996,  2698, 28984,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2001,  2137,  5154,  5394,  2198, 11526,  1055,  8367],\n",
      "            [ 2054,  2301,  2106,  2396,  1055,  6298,  2558,  4088,  1999],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  2773, 18565,     0],\n",
      "            [ 2054,  1057,  1055,  2118, 21979,  1996,  2922,  3075,     0],\n",
      "            [ 2129,  2172,  4586, 19635,  2019,  4960,  1997,  4542,     0],\n",
      "            [ 2029,  3348,  2003,  6380,  6830,  2916,  1999, 13085,     0],\n",
      "            [ 2054,  2003,  1996,  2034,  2154,  1997,  1996,  2733,     0],\n",
      "            [16933,  5209,  2109,  2000,  2022,  2081,  2011,  3183,     0],\n",
      "            [ 1999,  2054,  2095,  2001,  1996,  4068,  2813,  7019,     0],\n",
      "            [ 2054,  2024,  1996,  6666,  1997,  1037, 12037,  3698,     0],\n",
      "            [ 2054,  4082,  2291,  2079,  9980, 11892,  6681,  2224,     0]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3708'], ['1752'], ['4162'], ['556'], ['220'], ['197'], ['1335'], ['4444'], ['2685'], ['2415'], ['4100'], ['1884'], ['4307'], ['4948'], ['2351'], ['1937'], ['5103'], ['352'], ['3954'], ['3902'], ['3572'], ['593'], ['4568'], ['865'], ['1827'], ['5147'], ['3116'], ['2101'], ['5224'], ['2369'], ['2866'], ['707']],\n",
      "    text: (tensor([[ 2054,  2003,  1996,  3552,  2110,  3318,  4171,  3446],\n",
      "            [ 2129,  2515,  1037,  4045, 10250, 19879,  4263,  2147],\n",
      "            [ 2054,  2024,  1996,  2184, 11629,  2015,  1997,  5279],\n",
      "            [ 2054,  2003,  1996,  2190,  2267,  1999,  1996,  2406],\n",
      "            [ 2054,  2003,  1996,  2640,  1997,  1996,  2911, 20753],\n",
      "            [ 2043,  2001,  1996,  2034,  2813,  2395,  3485,  2405],\n",
      "            [ 2043,  2001,  1996,  9546,  3797, 21547,  3367,  2543],\n",
      "            [ 2054,  3257,  2079,  2087,  3598, 23232,  6510,  2646],\n",
      "            [ 1996,  2143, 16113,  2001,  2081,  1999,  2054,  2095],\n",
      "            [ 2054,  2003,  5980,  5215,  1055,  3058,  1997,  4182],\n",
      "            [ 2054,  2003,  1996,  2313,  1997,  1996,  2142,  2163],\n",
      "            [ 2054,  2024,  1996,  2698, 16278,  1997,  1996,  2088],\n",
      "            [ 2054,  2557,  2276,  2106,  2703,  7702,  2147,  2005],\n",
      "            [ 2054,  2003,  1996,  2088,  2313,  2004,  1997,  2651],\n",
      "            [13229,  1055,  2034,  3743,  4158,  2006,  2054,  3058],\n",
      "            [ 2054,  2079,  1996,  2413,  2655,  2474,  2158,  5403],\n",
      "            [ 2054,  2024, 19399,  1999,  1996,  3011,  1055, 19116],\n",
      "            [ 2054,  2024,  1996, 13908,  5711,  1997,  1037, 13361],\n",
      "            [ 2054,  2003,  1996, 28501,  3696,  2005,  2257,  2403],\n",
      "            [ 2054,  2515,  6746,  1055, 11320, 10196,  4330, 14970],\n",
      "            [ 2054, 13930,  2106, 19781,  2618,  2595,  2177,  2681],\n",
      "            [ 2054,  1055,  8455,  2043,  1037, 14199, 15701,  3514],\n",
      "            [ 2054,  1057,  1055,  2231,  4034, 18687, 11749,  2015],\n",
      "            [ 2339,  2020,  2111,  8733,  2005,  1996,  5148,  2162],\n",
      "            [ 2054,  1055,  1996,  2088,  1055,  6493,  8636,  2958],\n",
      "            [ 2054,  2003,  1996,  1055,  1052,  3156,  2109,  2005],\n",
      "            [ 2029, 16696,  2001,  2823,  2170, 26219,  2099,  2509],\n",
      "            [ 2054,  2003,  1037,  2470,  5590,  1999,  3137,  8218],\n",
      "            [ 2054,  2003,  1996,  2922,  2688,  1999,  1996,  2088],\n",
      "            [ 2054,  2079,  2087,  9045,  3942,  1999, 24964,  5244],\n",
      "            [ 2054,  2003,  3214,  2011,  2668,  7367,  2094,  3446],\n",
      "            [ 2054,  2001,  3035,  3848,  1055,  2516,  4953,  2634]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [3],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1890'], ['4620'], ['4497'], ['933'], ['3935'], ['4018'], ['37'], ['2690'], ['2893'], ['866'], ['4402'], ['4502'], ['5275'], ['4774'], ['267'], ['53'], ['879'], ['5174'], ['2805'], ['2606'], ['4675'], ['4780'], ['1338'], ['955'], ['1678'], ['348'], ['2169'], ['3178'], ['314'], ['1316'], ['1625'], ['3788']],\n",
      "    text: (tensor([[ 2054,  2003,  1037, 11265, 10976, 26210,  3351,  2239],\n",
      "            [ 2054, 15607,  2813,  6753,  1996,  2919, 21682, 14493],\n",
      "            [ 2054,  2024,  1996,  2783,  7521,  4277,  1999,  2149],\n",
      "            [ 2054,  2001,  7905,  2100,  1998,  2033, 23935,  8671],\n",
      "            [ 2054,  2515,  1037,  2521, 16252,  2404,  6007,  2006],\n",
      "            [ 2054,  2515,  2009,  2202,  2000,  2468,  1037,  5160],\n",
      "            [ 1999,  2054,  4676,  2001, 18301,  1996,  3267,  7804],\n",
      "            [ 2054,  2001,  1996,  2905,  2911,  1997,  1996,  4386],\n",
      "            [ 1996,  2117,  2087,  2759,  4368,  4969,  2003,  2054],\n",
      "            [ 2054,  2283,  2001, 10180, 10888,  1037,  2266,  1997],\n",
      "            [ 2054,  2001,  1996,  3025,  2171,  2005,  1996,  5663],\n",
      "            [ 2054,  2515,  6554,  2332,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2248,  3029,  2001,  2631,  2011, 10254, 12975],\n",
      "            [ 2054,  2003,  1996, 21877,  4135, 26029, 20281,  2223],\n",
      "            [ 2054,  2003,  1996,  4438,  6210,  1997, 13800,  5394],\n",
      "            [ 2073,  2106,  1996,  2744,  6564,  2098,  2272,  2013],\n",
      "            [ 2054,  2001,  1996,  6139,  1997, 18193,  5785,  9082],\n",
      "            [ 2054,  2003,  1996,  2088,  1055,  2190,  4855, 17387],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  9925,  3780],\n",
      "            [ 2054,  2003,  1996,  5072,  5512,  1997,  1037, 22635],\n",
      "            [ 2054,  2003,  1996,  4633,  2066,  2006,  1996,  4231],\n",
      "            [ 2054,  2001,  5261, 22959,  2618,  1055,  4323,  2299],\n",
      "            [ 2054,  2003,  1996,  2431,  2166,  1997,  1052,  3590],\n",
      "            [ 2054,  2003,  1996,  7982,  4418,  1999, 13941,  2170],\n",
      "            [ 2054,  2024,  1996,  2922,  8860,  1999,  1996,  2149],\n",
      "            [ 2054,  2024,  1996,  2367,  8107,  1997,  3001,  4106],\n",
      "            [ 1996,  4589,  4605,  2003,  2284,  1999,  2054,  2103],\n",
      "            [ 2054,  2406,  2097,  2718,  1996,  2095,  1016,  2034],\n",
      "            [ 2054,  2154,  2001,  7247,  6496,  4457,  1999,  3758],\n",
      "            [ 2054,  2785,  1997,  2671,  2003,  2522, 25855,  6483],\n",
      "            [ 2054,  2024,  1037,  3598,  2136,  1055,  2543,  3549],\n",
      "            [ 2054,  2003, 11280,  6097, 15987,  2063,  2124,  2004]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5376'], ['4514'], ['3021'], ['2898'], ['102'], ['1870'], ['3482'], ['299'], ['4889'], ['305'], ['2828'], ['3910'], ['3003'], ['4865'], ['2086'], ['1668'], ['466'], ['2474'], ['1644'], ['258'], ['4648'], ['5166'], ['692'], ['4607'], ['1918'], ['3673'], ['5377'], ['3987'], ['4318'], ['5000'], ['3291'], ['703']],\n",
      "    text: (tensor([[ 2054,  2003,  1996, 13805,  8316,  1997,  8744,  7893],\n",
      "            [ 6972,  8997,  2003,  2190,  2124,  2005,  2054,  6344],\n",
      "            [ 2054,  3466,  2515, 15012,  2031,  2006, 18870,  4367],\n",
      "            [ 2054,  1055,  1996,  3284,  2192,  1999,  3442, 11662],\n",
      "            [ 2054,  2106, 23006,  2079,  2000, 18375,  1055,  2606],\n",
      "            [ 2054,  1055,  2178,  2773,  2008,  2965,  4282,  2035],\n",
      "            [ 2054,  2003,  1996,  2966,  4650,  1997, 23760, 29048],\n",
      "            [ 2054,  2003,  3763,  2005,  4297, 25377, 12870,  3372],\n",
      "            [ 2054,  2003,  1996,  4489,  2090,  2606,  1998,  6519],\n",
      "            [ 2054,  2024,  1996,  1021,  4790,  1997,  1996,  4552],\n",
      "            [ 2054,  2515, 10250, 25099, 17637,  2000,  1999,  2394],\n",
      "            [ 2054,  2003,  1996, 22498,  2005,  2434,  3941,  7751],\n",
      "            [ 2054,  4796,  2441,  2006,  2264,  1998,  2225,  4068],\n",
      "            [ 2054,  2003,  1996,  3793,  1997,  1996,  3587,  7450],\n",
      "            [ 2040,  2003,  1996,  3306,  2643,  1997,  1996,  2712],\n",
      "            [ 2054,  2001,  2637,  1055, 28290,  2098, 11307,  9907],\n",
      "            [ 2054,  2003,  1996, 26849,  2732,  5710,  2013,  3011],\n",
      "            [ 2054,  2003,  4012,  4502,  4160,  1055,  3260,  4861],\n",
      "            [ 2054,  2001,  1996,  2535,  1997,  1996,  5781,  9054],\n",
      "            [ 2054,  2003,  1996, 13314,  2005, 10289,  8214,  2118],\n",
      "            [ 2054,  2020,  1996,  2034,  4230,  4716,  2011, 12076],\n",
      "            [ 2054,  2003,  1996,  2394,  3574,  1997, 10250, 25099],\n",
      "            [ 2054,  2515,  1037,  9152, 19466,  2923,  2903,  1999],\n",
      "            [ 2054,  2515,  6141,  7980,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  3335,  2634,  2807],\n",
      "            [ 2054,  3599,  4919,  2515,  3637,  2079,  2005,  2017],\n",
      "            [16933,  3194,  3765,  2020,  2081,  2011,  2054,  2194],\n",
      "            [ 2054,  2516,  2515,  9971,  2888,  2402,  2386,  4366],\n",
      "            [ 2054,  2465,  2003, 20427,  2004,  1996, 22846,  2666],\n",
      "            [ 2054,  2003,  1037,  2711,  1055, 17522, 23035,  2597],\n",
      "            [ 2339,  2003,  1996,  2773, 22498,  2061,  2146,     0],\n",
      "            [ 2073,  2024,  1996,  5133,  4542,  3224, 20611,     0]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2268'], ['4241'], ['276'], ['2047'], ['1941'], ['1037'], ['2669'], ['1694'], ['5050'], ['5121'], ['132'], ['2961'], ['1420'], ['3394'], ['3934'], ['4701'], ['3847'], ['2870'], ['3290'], ['130'], ['4052'], ['4323'], ['884'], ['3033'], ['1347'], ['5246'], ['1606'], ['5325'], ['1363'], ['1110'], ['774'], ['1978']],\n",
      "    text: (tensor([[ 2054,  2515, 28619,  4859, 21716,  2594,  2812],\n",
      "            [ 2040,  2001,  1996,  2034,  2450,  1999,  2686],\n",
      "            [ 2054,  2003,  9587,  2135,  2497,  4181,  2819],\n",
      "            [ 2054,  2024,  1996, 12971,  1997,  2047,  2563],\n",
      "            [ 2054,  2003,  1037,  3571,  1997,  2108,  6530],\n",
      "            [ 2129,  2079,  1045,  2424,  2041,  2055,  5841],\n",
      "            [ 2073,  2003,  1996,  2529,  3096,  2560,  7591],\n",
      "            [ 2054,  2003,  1996,  2922,  3528,  1997, 23265],\n",
      "            [ 2043,  2001,  1996,  2112, 10222,  2239,  2328],\n",
      "            [ 2054,  6087,  2003, 17454, 12380,  2081,  1997],\n",
      "            [ 2054,  2003,  1037,  2143,  4626, 12582,  2375],\n",
      "            [ 2054, 15607,  2314,  6223,  2083,  4524, 14697],\n",
      "            [ 2054,  2003,  1996, 13747,  2311,  1999,  2900],\n",
      "            [ 2054,  2515,  1996,  3149, 10978,  3233,  2005],\n",
      "            [ 2054,  3047,  2000, 13433,  8737,  7416,  2072],\n",
      "            [ 2054,  2003,  2343, 11296,  1055,  4182, 13701],\n",
      "            [ 2054,  6139,  2038,  1996,  3284,  8179,  3446],\n",
      "            [ 2073,  2003,  2115, 13931,  2655,  2891,  2819],\n",
      "            [ 2054,  2003,  1996,  2190,  3784,  2399,  2609],\n",
      "            [ 2054,  3117,  4427,  1996,  3185,  6085, 23195],\n",
      "            [ 2054,  2679,  2003,  1015, 14989,  2661,  2146],\n",
      "            [ 2054,  2003,  6970, 20051,  2050,  4274,  2326],\n",
      "            [ 2054,  2024,  1996,  2542,  3785,  1999,  7394],\n",
      "            [ 2007,  3183,  2106,  5747, 12826, 24111, 16543],\n",
      "            [ 2054,  2003,  3021,  7977,  1055, 10373,  4769],\n",
      "            [ 2054,  2024,  1996,  2274,  3937,  5742, 13692],\n",
      "            [ 2054,  2003,  4141,  2641,  1996,  3587,  3168],\n",
      "            [ 2054,  2003,  1996,  2087,  4235, 13237,  3269],\n",
      "            [ 2054,  2311,  2024,  2329, 19799, 10249,  1999],\n",
      "            [ 2054,  2024,  7538, 13051,  1999, 24964,  5244],\n",
      "            [ 2054,  2001,  6117,  1055,  2034,  4552,  2170],\n",
      "            [ 2054,  3032,  2031,  1996,  2190,  8785,  2493]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['519'], ['2920'], ['271'], ['4518'], ['4333'], ['4386'], ['47'], ['5150'], ['1908'], ['2074'], ['4789'], ['1492'], ['4840'], ['416'], ['5143'], ['669'], ['845'], ['1359'], ['3028'], ['4779'], ['1007'], ['2063'], ['3718'], ['104'], ['2133'], ['1327'], ['4828'], ['453'], ['3114'], ['3478'], ['4761'], ['1213']],\n",
      "    text: (tensor([[ 2054,  2003, 29153,  1055,  2364, 19502,  9167],\n",
      "            [ 2054,  2515,  1037,  2002, 12798, 10727,  2817],\n",
      "            [ 2054,  2106, 22953, 13663, 22244,  2229,  4521],\n",
      "            [ 2054,  4774,  2106, 27832,  2293,  3363,  7523],\n",
      "            [ 2054,  2024,  1996,  2176,  7111,  1999, 15404],\n",
      "            [ 2054,  2003,  1037, 13045,  1999,  3274,  3408],\n",
      "            [ 2054,  2003,  4523,  4839,  1999,  1996,  7139],\n",
      "            [ 2054,  2024,  1996, 12760,  1997, 16787, 15270],\n",
      "            [ 2054,  2003,  1996,  5072,  6454,  2005, 14114],\n",
      "            [ 2054,  2003,  3565, 15239,  1055,  3595,  4767],\n",
      "            [ 2054,  2003,  1996,  7268, 15156,  2005, 28519],\n",
      "            [ 2129,  3435,  2079, 18178, 12928,  7898,  2448],\n",
      "            [ 2054,  2515,  1037, 21877, 26173,  3334,  5468],\n",
      "            [ 2054, 26572, 20281,  2111, 21490,  2047,  3414],\n",
      "            [ 2054,  2003,  1996,  2087,  2759,  2197,  2171],\n",
      "            [ 2129,  3435,  2515,  1996,  7915,  2482,  2175],\n",
      "            [ 2054,  2003,  1040,  1038,  6201,  2124,  2005],\n",
      "            [ 2171,  2019,  2396,  3916,  1999,  2047,  2259],\n",
      "            [ 2073,  2106,  1996,  2744,  6353,  2272,  2013],\n",
      "            [ 2129,  2515,  2236,  6341,  9922, 15138, 10735],\n",
      "            [ 2073,  2106,  1996,  2744,  6564,  2272,  2013],\n",
      "            [ 2054,  1055,  1996,  9350, 13821,  1999,  9780],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  8362,  2154],\n",
      "            [ 2029,  1997,  1996,  2206,  2001, 10588,  6288],\n",
      "            [ 2054,  2400,  2003,  1996,  7436,  1997,  6475],\n",
      "            [ 2040,  2764,  1996,  2034, 14955,  3695, 17404],\n",
      "            [ 2054,  2024,  2492,  3466,  9099, 20483,  2869],\n",
      "            [ 2054,  1055,  3267,  1055,  3800,  2005, 22668],\n",
      "            [ 2073,  2003,  1996, 12065,  3455,  2136,  2241],\n",
      "            [ 2054,  2064,  2028,  2156,  1999, 24964,  5244],\n",
      "            [ 2054,  2020, 11561,  7920,  1055,  3017,  3415],\n",
      "            [ 2054,  2106,  1996,  3806,  2160,  6080,  2377]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2956'], ['2262'], ['4128'], ['2599'], ['888'], ['5390'], ['914'], ['5320'], ['4183'], ['2951'], ['657'], ['5279'], ['1645'], ['2318'], ['4506'], ['4659'], ['2906'], ['2012'], ['965'], ['4882'], ['2410'], ['4'], ['4625'], ['4827'], ['2846'], ['502'], ['1093'], ['4139'], ['4555'], ['2424'], ['3389'], ['4523']],\n",
      "    text: (tensor([[ 2040,  2001, 10861,  5753,  2389, 16531,  2140],\n",
      "            [ 2040,  2001,  1059, 16584, 18274, 18414, 25112],\n",
      "            [ 2054,  2079,  2394,  3549, 17042,  3209,  1999],\n",
      "            [ 2054,  2003,  1996, 17974,  2005,  6763, 12122],\n",
      "            [ 2054, 19264,  2628,  8912,  2000,  1996, 10925],\n",
      "            [ 2054,  2515,  1996,  2314, 16470,  4064,  2046],\n",
      "            [ 2054,  1055,  1996,  6730,  2314,  1997,  2634],\n",
      "            [ 2054,  1055,  1037, 10231,  2015,  2447,  2170],\n",
      "            [ 2054,  2024, 13433,  4168, 17643, 12556,  2015],\n",
      "            [ 2054,  2003,  1996,  3284,  3142, 16371, 28990],\n",
      "            [ 2129,  2003, 10957,  4465,  1055,  3058,  4340],\n",
      "            [ 2054,  4774,  2435,  2978,  2232,  2000, 10646],\n",
      "            [10021,  2404,  3723,  2001,  8826,  2011,  3183],\n",
      "            [ 2054,  2020,  1996, 10106,  1997,  2957, 11296],\n",
      "            [ 2054,  2001, 18379,  1996,  2744, 19117,  8975],\n",
      "            [ 2054,  2785,  1997,  2194,  2003,  1021,  5408],\n",
      "            [ 2054,  2106,  1996,  3519,  1997,  6004,  5323],\n",
      "            [ 1996,  4589,  4605,  2003,  1999,  2054,  2103],\n",
      "            [ 2054,  4127,  1997,  2300, 10796,  2024,  2045],\n",
      "            [ 2073,  2024, 29145,  2015,  2087,  3497,  2179],\n",
      "            [ 2054,  2515,  6275, 22610,  5354, 23777,  5020],\n",
      "            [ 2054,  2003,  1996,  2440,  2433,  1997,  4012],\n",
      "            [ 2040,  2020,  2198,  1042,  5817,  1055,  6077],\n",
      "            [ 2054,  2003,  2224,  7159,  2005,  1996,  4274],\n",
      "            [ 2054, 12652,  3092, 21442,  7373, 16106, 13941],\n",
      "            [ 2054,  2001,  2124,  2004,  1996, 17688,  2479],\n",
      "            [ 2054,  2003, 15333,  3363,  1051,  2081,  2013],\n",
      "            [ 6972,  8997,  2003,  2087,  3297,  2005,  2054],\n",
      "            [ 2054,  1055,  1996,  2110, 12652,  1997,  2662],\n",
      "            [ 2054,  2079,  2887,  2082, 11408,  2298,  2066],\n",
      "            [ 2054,  2024,  1996,  6177,  1997, 26572, 20367],\n",
      "            [ 2054,  2106, 29554,  2015,  3046,  2000,  2203]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [5],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['959'], ['4285'], ['2448'], ['3465'], ['28'], ['19'], ['4551'], ['2447'], ['2069'], ['1845'], ['2036'], ['2788'], ['5180'], ['5076'], ['4702'], ['1221'], ['2546'], ['3735'], ['3879'], ['3294'], ['4142'], ['4516'], ['216'], ['4377'], ['5091'], ['2140'], ['4673'], ['687'], ['4580'], ['4578'], ['2362'], ['1186']],\n",
      "    text: (tensor([[ 2054,  2003,  1996,  6614,  5139,  2278,  6708],\n",
      "            [ 2054,  9843,  2051,  2079,  2057,  2444,  1999],\n",
      "            [ 2054,  2003,  1996,  7117,  1997,  2035,  4763],\n",
      "            [ 2054,  3333,  1015, 22997,  2519,  1999,  3150],\n",
      "            [ 2171,  1037,  5439,  2607,  1999, 21381,  3509],\n",
      "            [ 2054,  2003,  2019,  5754, 17287,  3064, 24751],\n",
      "            [ 2040,  2001,  1996,  2034,  4111,  2046,  2686],\n",
      "            [ 2029,  2003,  1996,  2087,  2109,  3274,  2565],\n",
      "            [ 2054,  2003,  1996,  5675,  2000, 18422, 14255],\n",
      "            [ 2054,  2003,  2745,  4027,  1055,  2690,  2171],\n",
      "            [ 2054,  1055,  1996,  2880,  2653,  1997, 11337],\n",
      "            [ 2054,  2515,  1996, 13445,  2832,  4372, 14162],\n",
      "            [ 2054,  1055,  1996,  1057,  1055,  3212, 14825],\n",
      "            [ 2054,  2001,  1996,  2757,  2158,  1055,  2192],\n",
      "            [ 2054,  2003,  1996,  2307,  2137,  2155, 20943],\n",
      "            [ 8362,  2154,  2003,  6334,  2006,  2054,  3058],\n",
      "            [ 2054,  2515, 10250, 25099,  2812,  1999,  2394],\n",
      "            [ 2054,  2515,  1996,  2171, 19347,  2812,     0],\n",
      "            [ 2040,  2003,  1996,  3954,  1997, 13229,     0],\n",
      "            [ 2054,  2003,  1037,  9850,  1997,  7815,     0],\n",
      "            [ 2054,  2515,  6413,  2015,  2769,  2812,     0],\n",
      "            [ 2040,  6791, 14916, 19513,  1999, 24592,     0],\n",
      "            [ 2054,  2003,  1055,  3630, 21131,  2015,     0],\n",
      "            [ 2054,  2003,  1037,  3571,  1997, 10394,     0],\n",
      "            [ 2054,  2515, 23969,  2290,  3233,  2005,     0],\n",
      "            [ 2054,  2712, 20626,  1996, 26164,  3470,     0],\n",
      "            [ 2054,  2003,  2197,  3382,  2005,  4176,     0],\n",
      "            [ 2054,  2003,  1037,  3571,  1997, 23996,     0],\n",
      "            [ 2054,  2515,  1996,  2171,  9606,  2812,     0],\n",
      "            [ 2054,  2024,  1996,  2698,  9252, 15516,     0],\n",
      "            [ 2040,  2003,  1996, 12168,  1997, 15761,     0],\n",
      "            [12582,  2375,  6051,  1999,  2029,  2143,     0]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4132'], ['4439'], ['1001'], ['4024'], ['3179'], ['949'], ['1342'], ['4476'], ['3252'], ['4559'], ['4601'], ['1145'], ['683'], ['837'], ['224'], ['3476'], ['4831'], ['4069'], ['2808'], ['2992'], ['2520'], ['3891'], ['1456'], ['214'], ['1743'], ['1853'], ['1429'], ['3431'], ['3570'], ['5252'], ['2425'], ['1843']],\n",
      "    text: (tensor([[ 2040,  8826,  1996,  9587,  8649, 13564],\n",
      "            [ 2129,  4206,  2003,  1996,  3043,  9769],\n",
      "            [ 2043,  2106,  8956,  3629, 18445, 13085],\n",
      "            [ 2054,  2024,  1996,  2364,  2668,  6470],\n",
      "            [ 2054,  6087,  2191,  2039,  1037, 10098],\n",
      "            [ 2054,  2001,  1996,  9610, 21827,  9288],\n",
      "            [ 2054,  2079,  3017,  6529,  2903,  1999],\n",
      "            [ 2054,  2097,  1996,  4633,  2022,  2651],\n",
      "            [ 2054,  2110,  2515,  2798, 26211,  5050],\n",
      "            [ 1996,  3644, 12440,  2003,  2170,  2054],\n",
      "            [ 2054,  1055,  1996, 13048,  1997, 18740],\n",
      "            [ 2054,  2003,  6554,  2332,  1055,  3105],\n",
      "            [ 2054,  2003,  1996,  4678,  3367,  9226],\n",
      "            [ 2054,  2003,  2281,  1055, 18250,  5524],\n",
      "            [ 2054,  2003,  1996,  1021,  3371,  9907],\n",
      "            [ 2054,  2515,  5000,  9436,  4063, 10172],\n",
      "            [ 2054,  2003,  2110,  3392,  1997,  8506],\n",
      "            [ 2054,  2003,  6141,  7980,  1055,  9518],\n",
      "            [ 2054,  2001,  1996,  6585,  2000, 17550],\n",
      "            [ 2054,  2081,  4869,  2204,  8095,  3297],\n",
      "            [ 2043,  2079,  2017,  3269,  3467, 10500],\n",
      "            [ 2054,  2515,  1996, 26385,  2194,  9922],\n",
      "            [ 2054,  2003,  1996,  1039,  4730,  2653],\n",
      "            [ 2054,  2003, 22396,  5811,  3297,  2005],\n",
      "            [ 2054,  2003,  1037, 16475,  2080,  6045],\n",
      "            [ 5455,  4097,  2798,  3248,  2054,  6602],\n",
      "            [ 2054,  2614,  2515, 17096,  2899, 27590],\n",
      "            [ 2054,  2024,  2070,  2336,  1055,  2916],\n",
      "            [ 2054,  2024,  1996,  2732,  5233, 14549],\n",
      "            [ 2040,  2081,  1996, 16933,  3194,  9935],\n",
      "            [ 2171,  1037,  5474,  2697,  2103,  3780],\n",
      "            [ 2073,  2106,  2002,  2131,  1996,  2516]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4039'], ['3087'], ['3752'], ['3605'], ['3578'], ['4284'], ['366'], ['843'], ['261'], ['159'], ['4872'], ['1149'], ['5214'], ['4171'], ['2105'], ['2299'], ['3303'], ['5095'], ['361'], ['4698'], ['2548'], ['92'], ['1720'], ['176'], ['3945'], ['4032'], ['4049'], ['4248'], ['3016'], ['1537'], ['1508'], ['851']],\n",
      "    text: (tensor([[ 2054,  2024,  3565,  7395,  2081,  1997],\n",
      "            [ 2054,  2024,  1996,  3340,  2081,  1997],\n",
      "            [ 2073,  2001, 24494,  9790,  2100,  8826],\n",
      "            [ 2040,  2003,  2198, 17719, 21502, 10700],\n",
      "            [ 2073,  2106,  5939, 17176,  4982,  2039],\n",
      "            [ 2171,  2176,  5021, 12970,  2055,  8221],\n",
      "            [ 2129,  3144,  2003, 12098,  8462, 20900],\n",
      "            [ 2054,  2003,  1996,  6493,  2394,  2773],\n",
      "            [13229,  2003,  1996, 22498,  2005,  2054],\n",
      "            [ 2054,  2003,  1037, 11394,  7117,  5033],\n",
      "            [ 2054,  2003,  1996,  2087,  2691,  2171],\n",
      "            [ 2054,  2003,  1996,  3949,  2005,  6245],\n",
      "            [ 2054,  2003,  1996,  8367,  1997,  3552],\n",
      "            [ 2054,  2003,  8223,  1999,  1996,  3274],\n",
      "            [ 2054,  2003,  2686,  7384,  2209,  2006],\n",
      "            [ 2054,  2003,  5980,  5215,  1055,  5798],\n",
      "            [ 2054,  2003,  2258,  1055, 20296,  5524],\n",
      "            [ 6972,  8997,  2003,  3297,  2005,  2054],\n",
      "            [ 9375,  1996,  6887, 10242,  7646,  2252],\n",
      "            [ 2054,  2024,  8026, 20936,  2389, 21374],\n",
      "            [ 2054,  2003,  1996,  3260,  1997, 18368],\n",
      "            [ 2054,  2024,  4562,  1998,  7087,  6089],\n",
      "            [ 2054,  2003,  1996,  2976,  6263, 11897],\n",
      "            [ 2073,  2106,  2796, 29593,  2272,  2013],\n",
      "            [ 2054,  2024,  1996, 16324,  1999,  4274],\n",
      "            [ 2054, 12779, 23442,  6683,  2006, 12071],\n",
      "            [ 2054,  2003,  1996,  3635,  1997,  2250],\n",
      "            [ 2054,  4676,  2038,  1996,  2087,  2372],\n",
      "            [ 2043,  2003,  1037,  2450,  2087, 14946],\n",
      "            [ 2073,  2106, 10189, 11012,  2121,  3627],\n",
      "            [ 2054,  2003,  1996, 12440,  2005,  3763],\n",
      "            [ 2054,  2287,  2628,  1996,  4421,  2287]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3165'], ['2329'], ['3441'], ['110'], ['3177'], ['4993'], ['601'], ['3729'], ['5128'], ['5313'], ['2215'], ['4699'], ['1143'], ['1453'], ['566'], ['2988'], ['5135'], ['1123'], ['2111'], ['4342'], ['787'], ['4757'], ['2482'], ['35'], ['170'], ['2593'], ['1089'], ['1943'], ['5436'], ['960'], ['3694'], ['3761']],\n",
      "    text: (tensor([[ 2054,  1055,  1037,  3287,  6965,  2170],\n",
      "            [ 2054,  2079, 18931,  2015,  6775,  2007],\n",
      "            [ 2129,  2898,  2003,  1996,  4448,  4153],\n",
      "            [ 2073,  2079, 28480,  2015,  2272,  2013],\n",
      "            [ 2054,  2106,  9822,  2272,  2067,  2004],\n",
      "            [ 2054,  2003,  1996,  2087,  2691,  4456],\n",
      "            [ 2054,  2003,  1996,  4562,  1997, 18007],\n",
      "            [ 2171,  1997,  2332,  4300,  1055,  4690],\n",
      "            [ 2054,  6459,  9002,  2000,  2049,  4454],\n",
      "            [ 2054,  3047,  2006,  2254,  2321,  3440],\n",
      "            [ 2073,  2515,  8945, 20534,  2272,  2013],\n",
      "            [ 2054,  2001,  1996,  2542,  2282,  2162],\n",
      "            [ 2054,  2003,  1037, 27291,  7473,     0],\n",
      "            [ 2054,  2024,  1996,  2698, 11915,     0],\n",
      "            [ 2054,  2003,  1037,  2665, 22132,     0],\n",
      "            [ 2040,  2764,  8962, 20051,  2818,     0],\n",
      "            [ 2054,  2003, 11917,  1999,  2833,     0],\n",
      "            [ 2073,  2106,  7102, 14695, 21754,     0],\n",
      "            [ 2054,  2024, 21243,  2081,  1997,     0],\n",
      "            [ 2054,  2001,  1996,  5409,  7064,     0],\n",
      "            [ 2043,  2001,  1996,  2307,  6245,     0],\n",
      "            [ 2054,  2024,  7280,  3156,  3316,     0],\n",
      "            [ 2054, 10585,  8826,  1996,  7905,     0],\n",
      "            [ 2054,  2079, 15111,  2015,  2903,     0],\n",
      "            [ 2073,  2024,  1996,  4749,  4084,     0],\n",
      "            [ 2054,  1055,  1037,  2460, 10228,     0],\n",
      "            [ 2054,  4245,  2572,  1045,  1999,     0],\n",
      "            [ 2054,  1055,  1996,  2417,  4774,     0],\n",
      "            [ 2054,  2769,  2001,  2109,  2182,     0],\n",
      "            [ 2043,  2024,  8351, 26822,  6826,     0],\n",
      "            [ 2054,  2003,  1996,  7915,  3274,     0],\n",
      "            [ 2054,  2024,  2070, 11327, 11744,     0]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "            5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['18'], ['4185'], ['4148'], ['4325'], ['559'], ['1444'], ['292'], ['5038'], ['1702'], ['3755'], ['2742'], ['291'], ['891'], ['3219'], ['4765'], ['2531'], ['2179'], ['1070'], ['373'], ['2550'], ['2710'], ['3382'], ['1162'], ['3277'], ['3842'], ['553'], ['148'], ['338'], ['2035'], ['2328'], ['4191'], ['1705']],\n",
      "    text: (tensor([[ 2054,  2003,  3157,  4960, 10063],\n",
      "            [ 2054,  2515,  5863,  3766,  2079],\n",
      "            [ 2054,  2003,  1037,  6270,  4231],\n",
      "            [ 2054,  2003,  1996,  2959,  9812],\n",
      "            [ 2054,  2024,  1996, 13649,  3741],\n",
      "            [ 2029,  1997,  2122,  2024,  6048],\n",
      "            [ 2054,  2079, 16773,  2655,  7701],\n",
      "            [ 2054,  2003,  2976,  3318,  4171],\n",
      "            [ 2054, 10662,  2001,  4027, 25218],\n",
      "            [ 2073,  2515, 24903,  2272,  2013],\n",
      "            [ 2054,  2515,  1037, 20466,  3067],\n",
      "            [ 2073,  2001,  5696,  8912,  2141],\n",
      "            [ 2054,  2024,  1996,  2698, 21560],\n",
      "            [ 2054,  2003,  1996,  3795,  4610],\n",
      "            [ 2054,  2024,  1996, 22162, 14243],\n",
      "            [ 2054,  2515,  1037,  2450,  2215],\n",
      "            [ 2073,  2003,  1999, 24163,  2241],\n",
      "            [ 2073,  2106, 16204,  2272,  2013],\n",
      "            [ 2073,  2515,  7967,  2272,  2013],\n",
      "            [ 2129,  2521,  2064,  2017,  2156],\n",
      "            [ 2054,  2515,  2019,  3750,  2079],\n",
      "            [ 2054,  2003,  1996, 16708,  2291],\n",
      "            [ 2054,  2024,  1996, 24471,  9777],\n",
      "            [ 2171,  1037,  2413, 14870,  2283],\n",
      "            [ 2054,  2003,  1037,  3269, 12448],\n",
      "            [ 2073,  2079,  5749,  2272,  2013],\n",
      "            [ 2040,  7137, 11867, 19042,  2618],\n",
      "            [ 2054,  2024,  1996,  2176,  3787],\n",
      "            [ 2054,  2003,  2757, 29346, 11339],\n",
      "            [ 2054,  2003,  3306,  6770,  2050],\n",
      "            [ 2073,  2079,  3737,  8974,  4088],\n",
      "            [ 2043,  2001,  3035,  3848,  2141]], device='cuda:0'), tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "            5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1605'], ['636'], ['2519'], ['2902'], ['2786'], ['323'], ['2266'], ['5449'], ['947'], ['726'], ['846'], ['4630'], ['2686'], ['5231'], ['4337'], ['5395'], ['22'], ['1949'], ['653'], ['3579'], ['1091'], ['4205'], ['4448'], ['4663'], ['8'], ['1187'], ['429'], ['2189'], ['94'], ['791'], ['1452'], ['1888']],\n",
      "    text: (tensor([[ 2054,  2024,  3819,  9049,  2015],\n",
      "            [ 2054,  2079,  4257,  7529,  4521],\n",
      "            [ 2171,  1037,  2942,  2162, 11686],\n",
      "            [ 2171,  1037,  2931,  3275, 18815],\n",
      "            [ 2054,  2003, 15680,  4357,  6028],\n",
      "            [ 2054,  2024, 14414,  1055,  6087],\n",
      "            [ 2054,  4762,  2079, 24042,  2224],\n",
      "            [ 2054,  2003,  1996,  4860,  2651],\n",
      "            [ 2054,  2003,  2660,  2154,     0],\n",
      "            [ 2054,  2003, 11831,  9457,     0],\n",
      "            [ 2040,  2003,  6972,  8997,     0],\n",
      "            [ 2040,  2881,  2414,  2958,     0],\n",
      "            [ 2129,  2515,  7407,  3604,     0],\n",
      "            [ 2073,  2106,  5789, 21754,     0],\n",
      "            [ 2054,  2003,  1037, 21477,     0],\n",
      "            [ 6235,  1996,  2146,  2233,     0],\n",
      "            [ 2171,  2340,  3297, 18945,     0],\n",
      "            [ 2054,  2003, 18303,  7720,     0],\n",
      "            [ 2054,  2024,  5008,  3340,     0],\n",
      "            [ 2054,  2003,  1037, 15246,     0],\n",
      "            [ 2040,  2003,  6203,  9460,     0],\n",
      "            [ 2171,  1037,  3909, 25476,     0],\n",
      "            [ 2073,  2024, 11719, 21846,     0],\n",
      "            [ 2054,  4094,  5761, 17932,     0],\n",
      "            [ 2054,  2024, 11290, 16285,     0],\n",
      "            [ 2054,  5320,  6634,  4491,     0],\n",
      "            [ 2054,  2730,  3960, 20326,     0],\n",
      "            [ 2054,  5329,  2024, 10432,     0],\n",
      "            [ 2054,  2003, 24903,  2391,     0],\n",
      "            [ 2054,  2003,  4810, 23187,     0],\n",
      "            [ 3005, 25337,  2001,  6436,     0],\n",
      "            [ 2054, 17367,  2019,  4639,     0]], device='cuda:0'), tensor([5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "            4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['60'], ['1721'], ['4564'], ['4641'], ['5338'], ['3280'], ['1427'], ['2963']],\n",
      "    text: (tensor([[ 2073,  2003,  1996,  7077],\n",
      "            [ 5900,  2003,  9919,  2054],\n",
      "            [ 2040,  8826,  3455,     0],\n",
      "            [ 2054,  2024,  5300,     0],\n",
      "            [ 9375, 26403, 27132,     0],\n",
      "            [ 2054,  2003,  2051,     0],\n",
      "            [ 2054,  2003,  2643,     0],\n",
      "            [ 2054,  2003,  9262,     0]], device='cuda:0'), tensor([4, 4, 3, 3, 3, 3, 3, 3], device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2]], device='cuda:0')\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "enc = []\n",
    "grads = []\n",
    "labels = []\n",
    "enc_layers = {i: [] for i in range(num_layers)}\n",
    "\n",
    "\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=False,\n",
    "    indices=indices,\n",
    ")\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch in train_iter:\n",
    "\n",
    "        print(batch)\n",
    "        inputs, _ = batch.text\n",
    "        labels.append(batch.label)\n",
    "        inputs.requires_grad = False\n",
    "\n",
    "    #     embedded_tokens = clf.bert.embeddings(inputs)\n",
    "    #     embedded_tokens = torch.autograd.Variable(\n",
    "    #         embedded_tokens, requires_grad=True\n",
    "    #     )\n",
    "        encoded_all = clf(\n",
    "            inputs,\n",
    "            output_hidden_states=True,\n",
    "            # head_mask=head_mask,\n",
    "            # attention_mask=attention_mask,\n",
    "        )\n",
    "        # Skip the embedding layer [1:]\n",
    "        for i, enc_layer in enumerate(encoded_all[1][1:]):\n",
    "            enc_layers[i].append(enc_layer[:, 0].cpu())\n",
    "\n",
    "\n",
    "        encoded = encoded_all[0][:, 0]\n",
    "        enc.append(encoded.cpu())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    y = torch.cat(labels)\n",
    "    for k, v in enc_layers.items():\n",
    "        X = torch.cat(v)\n",
    "        enc_layers[k] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45480170",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enc_layers[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27410ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['929'], ['3557'], ['2485'], ['4861'], ['4268'], ['4895'], ['4261'], ['3601'], ['2526'], ['4800'], ['5375'], ['515'], ['1395'], ['253'], ['2173'], ['3307'], ['2827'], ['1692'], ['2269'], ['3664'], ['1148'], ['3327'], ['3923'], ['4443'], ['3472'], ['1296'], ['2737'], ['2024'], ['580'], ['1773'], ['1002'], ['4585']],\n",
      "    text: (tensor([[ 2171,  1996,  4802,  ...,  4895, 15464,  2098],\n",
      "            [ 2054,  2003,  1996,  ...,     0,     0,     0],\n",
      "            [ 2054,  2280,  2548,  ...,     0,     0,     0],\n",
      "            ...,\n",
      "            [ 2129,  2064,  1045,  ...,     0,     0,     0],\n",
      "            [ 2054,  2001,  2928,  ...,     0,     0,     0],\n",
      "            [ 2054, 17727,  8625,  ...,     0,     0,     0]], device='cuda:0'), tensor([32, 29, 26, 24, 24, 23, 23, 23, 23, 23, 22, 22, 21, 21, 21, 21, 21, 21,\n",
      "            20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2889323/28447427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0membedded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[0;32m---> 26\u001b[0;31m     encoded_all = clf(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0membedded_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         output_hidden_states=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/transformers/adapters/context.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     }\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;31m# append output attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "enc = []\n",
    "grads = []\n",
    "labels = []\n",
    "enc_layers = {i: [] for i in range(num_layers)}\n",
    "\n",
    "\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=False,\n",
    "    indices=indices,\n",
    ")\n",
    "\n",
    "for batch in train_iter:\n",
    "\n",
    "    print(batch)\n",
    "    inputs, _ = batch.text\n",
    "    labels.append(batch.label)\n",
    "    inputs.requires_grad = False\n",
    "\n",
    "    embedded_tokens = clf.embeddings(inputs)\n",
    "    embedded_tokens = torch.autograd.Variable(\n",
    "        embedded_tokens, requires_grad=True\n",
    "    )\n",
    "    encoded_all = clf(\n",
    "        embedded_tokens,\n",
    "        output_hidden_states=True,\n",
    "        # head_mask=head_mask,\n",
    "        # attention_mask=attention_mask,\n",
    "    )\n",
    "    # Skip the embedding layer [1:]\n",
    "    for i, enc_layer in enumerate(encoded_all[1][1:]):\n",
    "        enc_layers[i].append(enc_layer[:, 0].cpu())\n",
    "\n",
    "    encoded = encoded_all[0][:, 0]\n",
    "    enc.append(encoded.cpu())\n",
    "\n",
    "    mean = encoded.mean()\n",
    "    mean.backward()\n",
    "    enc_grad = embedded_tokens.grad.data\n",
    "    grads.append(enc_grad.norm(p=2, dim=(1, 2)))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "y = torch.cat(labels)\n",
    "for k, v in enc_layers.items():\n",
    "    X = torch.cat(v)\n",
    "    enc_layers[k] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3126b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.encoder.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ab4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = enc_layers[-1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1748e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Sample 2\n",
      "Sample 3\n",
      "Sample 4\n",
      "Sample 5\n",
      "Sample 6\n",
      "Sample 7\n",
      "Sample 8\n",
      "Sample 9\n",
      "Sample 10\n",
      "Sample 11\n",
      "Sample 12\n",
      "Sample 13\n",
      "Sample 14\n",
      "Sample 15\n",
      "Sample 16\n",
      "Sample 17\n",
      "Sample 18\n"
     ]
    }
   ],
   "source": [
    "from cka import *\n",
    "\n",
    "n = 18\n",
    "\n",
    "lin_vals = np.empty((n, n))\n",
    "rbf_vals = np.empty((n, n))\n",
    "for i in range(100, 1000, 50):\n",
    "    A = X[i:i+50]\n",
    "    print(f\"Sample {i//50 - 1}\")\n",
    "    for j in range(i, 1000, 50):\n",
    "        B = X[j:j+50]\n",
    "        lin = linear_CKA(A, B)\n",
    "        rbf = kernel_CKA(A, B)\n",
    "        i_mod = i // 50 - 2\n",
    "        j_mod = j // 50 - 2\n",
    "        lin_vals[i_mod, j_mod] = lin_vals[j_mod, i_mod] = lin\n",
    "        rbf_vals[i_mod, j_mod] = rbf_vals[j_mod, i_mod] = rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a95f274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(np.flip(rbf_vals, 1), xticklabels=range(1, 18+1), yticklabels=range(18, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c3d2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98248242 0.96114412 0.95121319 0.90460212 0.71041576\n",
      "  0.47315452 0.38221755 0.31722107 0.27903575 0.25892686 0.24506719]\n",
      " [0.98248242 1.         0.99294096 0.98335407 0.95183908 0.75358897\n",
      "  0.50744447 0.41371993 0.34471121 0.30324662 0.28150918 0.26641857]\n",
      " [0.96114412 0.99294096 1.         0.99445655 0.96767089 0.76605118\n",
      "  0.51650029 0.42217762 0.3524165  0.31063183 0.28872567 0.27348558]\n",
      " [0.95121319 0.98335407 0.99445655 1.         0.97601547 0.78270474\n",
      "  0.53881083 0.44590866 0.37730722 0.33579883 0.31386207 0.29857912]\n",
      " [0.90460212 0.95183908 0.96767089 0.97601547 1.         0.86372819\n",
      "  0.64402416 0.55500195 0.48563069 0.44082381 0.41642609 0.39986809]\n",
      " [0.71041576 0.75358897 0.76605118 0.78270474 0.86372819 1.\n",
      "  0.91641715 0.85514805 0.80074403 0.7619774  0.73903904 0.72382307]\n",
      " [0.47315452 0.50744447 0.51650029 0.53881083 0.64402416 0.91641715\n",
      "  1.         0.98668085 0.96352048 0.94102505 0.92561751 0.91487866]\n",
      " [0.38221755 0.41371993 0.42217762 0.44590866 0.55500195 0.85514805\n",
      "  0.98668085 1.         0.99073546 0.97514698 0.96322383 0.95479626]\n",
      " [0.31722107 0.34471121 0.3524165  0.37730722 0.48563069 0.80074403\n",
      "  0.96352048 0.99073546 1.         0.99368034 0.98627515 0.980397  ]\n",
      " [0.27903575 0.30324662 0.31063183 0.33579883 0.44082381 0.7619774\n",
      "  0.94102505 0.97514698 0.99368034 1.         0.99771465 0.99458776]\n",
      " [0.25892686 0.28150918 0.28872567 0.31386207 0.41642609 0.73903904\n",
      "  0.92561751 0.96322383 0.98627515 0.99771465 1.         0.99915245]\n",
      " [0.24506719 0.26641857 0.27348558 0.29857912 0.39986809 0.72382307\n",
      "  0.91487866 0.95479626 0.980397   0.99458776 0.99915245 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(lin_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e25b09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98822128 0.96864577 0.94506764 0.84834738 0.58058964\n",
      "  0.38203942 0.30834932 0.27336096 0.25623951 0.2498741  0.24393084]\n",
      " [0.98822128 1.         0.98886123 0.96045117 0.87905716 0.61475402\n",
      "  0.41201909 0.33673577 0.30072946 0.28261005 0.27595218 0.26954692]\n",
      " [0.96864577 0.98886123 1.         0.9828193  0.90749149 0.63409695\n",
      "  0.42791082 0.35237271 0.31687092 0.29899749 0.29216579 0.28537392]\n",
      " [0.94506764 0.96045117 0.9828193  1.         0.93184827 0.66351566\n",
      "  0.46338771 0.3904026  0.3567184  0.33894004 0.33143854 0.32377679]\n",
      " [0.84834738 0.87905716 0.90749149 0.93184827 1.         0.83521269\n",
      "  0.66546147 0.5968039  0.55941694 0.53621035 0.52402475 0.51286493]\n",
      " [0.58058964 0.61475402 0.63409695 0.66351566 0.83521269 1.\n",
      "  0.94082216 0.89526446 0.86034934 0.83374846 0.81842072 0.80571088]\n",
      " [0.38203942 0.41201909 0.42791082 0.46338771 0.66546147 0.94082216\n",
      "  1.         0.9877828  0.96883966 0.94919752 0.9360177  0.92503854]\n",
      " [0.30834932 0.33673577 0.35237271 0.3904026  0.5968039  0.89526446\n",
      "  0.9877828  1.         0.99094239 0.97567427 0.96464111 0.95507823]\n",
      " [0.27336096 0.30072946 0.31687092 0.3567184  0.55941694 0.86034934\n",
      "  0.96883966 0.99094239 1.         0.99297577 0.98468996 0.97586278]\n",
      " [0.25623951 0.28261005 0.29899749 0.33894004 0.53621035 0.83374846\n",
      "  0.94919752 0.97567427 0.99297577 1.         0.99728635 0.99119932]\n",
      " [0.2498741  0.27595218 0.29216579 0.33143854 0.52402475 0.81842072\n",
      "  0.9360177  0.96464111 0.98468996 0.99728635 1.         0.99753495]\n",
      " [0.24393084 0.26954692 0.28537392 0.32377679 0.51286493 0.80571088\n",
      "  0.92503854 0.95507823 0.97586278 0.99119932 0.99753495 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(lin_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b913a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fda8257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Core set\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "617026dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entropy\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc285785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 1000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"long-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"f1_micro\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=95,\n",
    "    linewidth=3,\n",
    ")\n",
    "g.set_ylim(0.89, 0.98)\n",
    "g.set_xlim(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d25a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `acuraccy` for parameter `y`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1434047/548833310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g = sns.lineplot(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ada-besov\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"labeled\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"acuraccy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sampler\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[0;34m(x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LinePlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m     p = _LinePlotter(\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    365\u001b[0m         )\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `acuraccy` for parameter `y`"
     ]
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"ada-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"f1_micro\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=95,\n",
    "    linewidth=3,\n",
    ")\n",
    "# g.set_ylim(0.82, 0.92)\n",
    "# g.set_xlim(500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44e34a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoAdapterModel, AdapterConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "d = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "\n",
    "def save_dataset(hfd, name):\n",
    "    hfd[\"train\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        5_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/train.csv\", header=False)\n",
    "    hfd[\"test\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        2_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/test.csv\", header=False)\n",
    "    hfd[\"validation\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        1_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/validation.csv\", header=False)\n",
    "\n",
    "\n",
    "save_dataset(d, \"QQP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe182e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoAdapterModel.from_pretrained(\"bert-base-uncased\")\n",
    "a = model.load_adapter(\"adapters/TREC-2-BERT-pfeiffer\")\n",
    "model.add_classification_head(\"head\", num_labels=2)\n",
    "model.add_adapter(\"head\")\n",
    "model.train_adapter(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f14e35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jjukic/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c15a5dfd90473ba1783414b42d727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "d = load_dataset(\"glue\", \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5243de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'the kittens yawned awake and played.', 'label': -1, 'idx': 3}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"test\"][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fee3a0d468748c44cd2b5f7c2d15d26ebb787aed261e84470feedc3724e7bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
