{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcdfea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from dataloaders import *\n",
    "from util import Config\n",
    "from viz_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b644810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC-6-BERT\n",
      "Loading TREC-6 -- ada -- BERT\n",
      "Loading TREC-6 -- ada-besov -- BERT\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"MRPC\", \"TREC-2\", \"SUBJ\", \"AGN-2\", \"TREC-6\", \"AGN-4\", \"SST\"]\n",
    "dataset_map = {\n",
    "    \"TREC-2\": \"TREC-2\",\n",
    "    \"SUBJ\": \"SUBJ\",\n",
    "    \"AGN-2\": \"AGN-2\",\n",
    "    \"TREC-6\": \"TREC-full\",\n",
    "    \"SST\": \"SST\",\n",
    "    \"COLA\": \"COLA\",\n",
    "    \"AGN-4\": \"ag_news-full\",\n",
    "}\n",
    "models = [\"BERT\", \"ELECTRA\"]\n",
    "load_anti = False\n",
    "n = 0  # AL step at which evaluation (AUC) starts\n",
    "model = \"BERT\"\n",
    "mode = \"ada\"\n",
    "dataset = \"TREC-6\"\n",
    "\n",
    "aucs = []\n",
    "trs = []\n",
    "try:\n",
    "    experiments, meta = load_results(\n",
    "        base_dir=f\"results/\",\n",
    "        dataset=dataset,\n",
    "        model=model,\n",
    "    )\n",
    "except:\n",
    "    print(f\"No experiments for {dataset}-{model}-{mode}\")\n",
    "for load_mode in [\"last\", \"best\"]:\n",
    "    if mode == \"short\" and load_mode == \"best\":\n",
    "        continue\n",
    "    mode_print = mode if load_mode == \"last\" else f\"{mode}-besov\"\n",
    "    print(f\"Loading {dataset} -- {mode_print} -- {model}\")\n",
    "    df_tr_i = results_to_df(experiments, mode=load_mode)\n",
    "\n",
    "    df_tr_i[\"model\"] = model\n",
    "    df_tr_i[\"mode\"] = mode_print\n",
    "    df_tr_i[\"dataset\"] = dataset\n",
    "    df_tr_i = df_tr_i.reset_index().set_index(\n",
    "        [\"dataset\", \"model\", \"mode\", \"sampler\", \"experiment\", \"al_iter\"]\n",
    "    )\n",
    "    trs.append(df_tr_i)\n",
    "\n",
    "    df_auc_i = al_auc(df_tr_i)\n",
    "    df_auc_i[\"mode\"] = mode_print\n",
    "    df_auc_i = df_auc_i.reset_index().set_index([\"mode\", \"sampler\"])\n",
    "    aucs.append(df_auc_i)\n",
    "\n",
    "\n",
    "# plot_besov_index(df_tr, ci=0)\n",
    "# plot_al_accuracy(df_tr, metric=\"f1_micro\", ci=0)\n",
    "df_tr = pd.concat(trs)\n",
    "df_auc = pd.concat(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2b3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"ada-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"test_accuracy\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=90,\n",
    "    linewidth=3,\n",
    ")\n",
    "# plt.legend(loc='lower right')\n",
    "# g.set_ylim(0.89, 0.98)\n",
    "# g.set_xlim(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5628051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>labeled</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>sampler</th>\n",
       "      <th>experiment</th>\n",
       "      <th>al_iter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">TREC-2</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">ada-besov</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">random</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.657703</td>\n",
       "      <td>0.674897</td>\n",
       "      <td>0.674897</td>\n",
       "      <td>0.673964</td>\n",
       "      <td>[1549, 1546, 1179, 111, 561, 1832, 619, 56, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.662511</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.701160</td>\n",
       "      <td>[364, 841, 941, 922, 152, 1904, 903, 450, 447,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.651112</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.691073</td>\n",
       "      <td>[142, 543, 930, 872, 865, 1646, 95, 589, 513, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>0.633320</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>[1630, 1187, 1237, 1552, 682, 1424, 357, 178, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.642351</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>[499, 1225, 1423, 438, 1077, 1637, 566, 1410, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>14</th>\n",
       "      <td>800</td>\n",
       "      <td>0.658221</td>\n",
       "      <td>0.775720</td>\n",
       "      <td>0.775720</td>\n",
       "      <td>0.771635</td>\n",
       "      <td>[1416, 1090, 83, 524, 1923, 1278, 1293, 882, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>850</td>\n",
       "      <td>0.649009</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.806466</td>\n",
       "      <td>[1763, 240, 1153, 246, 1013, 1552, 1818, 1850,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>900</td>\n",
       "      <td>0.659438</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>[168, 1248, 1598, 714, 784, 1841, 1253, 1873, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>950</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.818820</td>\n",
       "      <td>[1455, 1577, 1788, 1880, 1023, 1458, 1126, 791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.648496</td>\n",
       "      <td>0.816872</td>\n",
       "      <td>0.816872</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>[1606, 456, 1572, 1407, 57, 1461, 463, 294, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    labeled  train_loss  \\\n",
       "dataset model mode      sampler experiment al_iter                        \n",
       "TREC-2  BERT  ada-besov random  0          0            100    0.657703   \n",
       "                                           1            150    0.662511   \n",
       "                                           2            200    0.651112   \n",
       "                                           3            250    0.633320   \n",
       "                                           4            300    0.642351   \n",
       "...                                                     ...         ...   \n",
       "                        entropy 4          14           800    0.658221   \n",
       "                                           15           850    0.649009   \n",
       "                                           16           900    0.659438   \n",
       "                                           17           950    0.656500   \n",
       "                                           18          1000    0.648496   \n",
       "\n",
       "                                                    test_accuracy  f1_micro  \\\n",
       "dataset model mode      sampler experiment al_iter                            \n",
       "TREC-2  BERT  ada-besov random  0          0             0.674897  0.674897   \n",
       "                                           1             0.709877  0.709877   \n",
       "                                           2             0.695473  0.695473   \n",
       "                                           3             0.738683  0.738683   \n",
       "                                           4             0.732510  0.732510   \n",
       "...                                                           ...       ...   \n",
       "                        entropy 4          14            0.775720  0.775720   \n",
       "                                           15            0.806584  0.806584   \n",
       "                                           16            0.800412  0.800412   \n",
       "                                           17            0.818930  0.818930   \n",
       "                                           18            0.816872  0.816872   \n",
       "\n",
       "                                                    f1_macro  \\\n",
       "dataset model mode      sampler experiment al_iter             \n",
       "TREC-2  BERT  ada-besov random  0          0        0.673964   \n",
       "                                           1        0.701160   \n",
       "                                           2        0.691073   \n",
       "                                           3        0.738194   \n",
       "                                           4        0.732143   \n",
       "...                                                      ...   \n",
       "                        entropy 4          14       0.771635   \n",
       "                                           15       0.806466   \n",
       "                                           16       0.799964   \n",
       "                                           17       0.818820   \n",
       "                                           18       0.816853   \n",
       "\n",
       "                                                                                             selected  \n",
       "dataset model mode      sampler experiment al_iter                                                     \n",
       "TREC-2  BERT  ada-besov random  0          0        [1549, 1546, 1179, 111, 561, 1832, 619, 56, 51...  \n",
       "                                           1        [364, 841, 941, 922, 152, 1904, 903, 450, 447,...  \n",
       "                                           2        [142, 543, 930, 872, 865, 1646, 95, 589, 513, ...  \n",
       "                                           3        [1630, 1187, 1237, 1552, 682, 1424, 357, 178, ...  \n",
       "                                           4        [499, 1225, 1423, 438, 1077, 1637, 566, 1410, ...  \n",
       "...                                                                                               ...  \n",
       "                        entropy 4          14       [1416, 1090, 83, 524, 1923, 1278, 1293, 882, 1...  \n",
       "                                           15       [1763, 240, 1153, 246, 1013, 1552, 1818, 1850,...  \n",
       "                                           16       [168, 1248, 1598, 714, 784, 1841, 1253, 1873, ...  \n",
       "                                           17       [1455, 1577, 1788, 1880, 1023, 1458, 1126, 791...  \n",
       "                                           18       [1606, 456, 1572, 1407, 57, 1461, 463, 294, 12...  \n",
       "\n",
       "[475 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf138bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>labeled</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>model</th>\n",
       "      <th>sampler</th>\n",
       "      <th>experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"25\" valign=\"top\">TREC-2</th>\n",
       "      <th rowspan=\"25\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"25\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">core_set</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6469762802124024, 0.636...</td>\n",
       "      <td>[0.6748971193415638, 0.551440329218107, 0.5452...</td>\n",
       "      <td>[0.6748971193415638, 0.551440329218107, 0.5452...</td>\n",
       "      <td>[0.6739639945652174, 0.45776695054045197, 0.44...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6821997761726379, 0.616...</td>\n",
       "      <td>[0.6748971193415638, 0.49588477366255146, 0.56...</td>\n",
       "      <td>[0.6748971193415638, 0.49588477366255146, 0.56...</td>\n",
       "      <td>[0.6708333333333334, 0.3350830657545721, 0.486...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6754907011985779, 0.601...</td>\n",
       "      <td>[0.6152263374485597, 0.5061728395061729, 0.5, ...</td>\n",
       "      <td>[0.6152263374485597, 0.5061728395061729, 0.5, ...</td>\n",
       "      <td>[0.6121904696881121, 0.36681649403947625, 0.34...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6158845901489258, 0.592...</td>\n",
       "      <td>[0.5555555555555556, 0.49794238683127573, 0.49...</td>\n",
       "      <td>[0.5555555555555556, 0.49794238683127573, 0.49...</td>\n",
       "      <td>[0.4830601953986763, 0.33955622883621456, 0.33...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6353173375129699, 0.6251...</td>\n",
       "      <td>[0.49176954732510286, 0.49382716049382713, 0.4...</td>\n",
       "      <td>[0.49176954732510286, 0.49382716049382713, 0.4...</td>\n",
       "      <td>[0.3296551724137931, 0.3305785123966942, 0.339...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dal</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6642346858978272, 0.663...</td>\n",
       "      <td>[0.6748971193415638, 0.6604938271604939, 0.666...</td>\n",
       "      <td>[0.6748971193415638, 0.6604938271604939, 0.666...</td>\n",
       "      <td>[0.6739639945652174, 0.6492540251151437, 0.648...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6488877415657044, 0.636...</td>\n",
       "      <td>[0.6748971193415638, 0.6893004115226338, 0.703...</td>\n",
       "      <td>[0.6748971193415638, 0.6893004115226338, 0.703...</td>\n",
       "      <td>[0.6708333333333334, 0.6868489888925396, 0.699...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.651800012588501, 0.6412...</td>\n",
       "      <td>[0.6152263374485597, 0.7078189300411523, 0.713...</td>\n",
       "      <td>[0.6152263374485597, 0.7078189300411522, 0.713...</td>\n",
       "      <td>[0.6121904696881121, 0.7060216739367502, 0.706...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6310327291488648, 0.683...</td>\n",
       "      <td>[0.5555555555555556, 0.6851851851851852, 0.716...</td>\n",
       "      <td>[0.5555555555555556, 0.6851851851851852, 0.716...</td>\n",
       "      <td>[0.4830601953986763, 0.6752514510571208, 0.715...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6481092929840088, 0.6514...</td>\n",
       "      <td>[0.49176954732510286, 0.654320987654321, 0.703...</td>\n",
       "      <td>[0.49176954732510286, 0.654320987654321, 0.703...</td>\n",
       "      <td>[0.3296551724137931, 0.6377318306859525, 0.703...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6654908657073975, 0.656...</td>\n",
       "      <td>[0.6748971193415638, 0.6728395061728395, 0.699...</td>\n",
       "      <td>[0.6748971193415638, 0.6728395061728395, 0.699...</td>\n",
       "      <td>[0.6739639945652174, 0.6620084242018659, 0.698...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6613013267517089, 0.672...</td>\n",
       "      <td>[0.6748971193415638, 0.6008230452674898, 0.707...</td>\n",
       "      <td>[0.6748971193415638, 0.6008230452674898, 0.707...</td>\n",
       "      <td>[0.6708333333333334, 0.5784343533704148, 0.697...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6476762533187866, 0.629...</td>\n",
       "      <td>[0.6152263374485597, 0.7119341563786008, 0.563...</td>\n",
       "      <td>[0.6152263374485597, 0.7119341563786008, 0.563...</td>\n",
       "      <td>[0.6121904696881121, 0.6991989248262569, 0.490...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6380608439445495, 0.643...</td>\n",
       "      <td>[0.5555555555555556, 0.7016460905349794, 0.646...</td>\n",
       "      <td>[0.5555555555555556, 0.7016460905349794, 0.646...</td>\n",
       "      <td>[0.4830601953986763, 0.6958658996059679, 0.637...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.642036247253418, 0.67306...</td>\n",
       "      <td>[0.49176954732510286, 0.7160493827160493, 0.68...</td>\n",
       "      <td>[0.49176954732510286, 0.7160493827160493, 0.68...</td>\n",
       "      <td>[0.3296551724137931, 0.7139127764127764, 0.689...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">entropy_dropout</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6431065201759338, 0.632...</td>\n",
       "      <td>[0.6748971193415638, 0.5267489711934157, 0.707...</td>\n",
       "      <td>[0.6748971193415638, 0.5267489711934157, 0.707...</td>\n",
       "      <td>[0.6739639945652174, 0.425531914893617, 0.7068...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6572281002998352, 0.609...</td>\n",
       "      <td>[0.6748971193415638, 0.6954732510288066, 0.520...</td>\n",
       "      <td>[0.6748971193415638, 0.6954732510288066, 0.520...</td>\n",
       "      <td>[0.6708333333333334, 0.6904352017628426, 0.392...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6576382756233216, 0.652...</td>\n",
       "      <td>[0.6152263374485597, 0.7222222222222222, 0.722...</td>\n",
       "      <td>[0.6152263374485597, 0.7222222222222222, 0.722...</td>\n",
       "      <td>[0.6121904696881121, 0.7212296318327633, 0.712...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6216179490089416, 0.625...</td>\n",
       "      <td>[0.5555555555555556, 0.6213991769547325, 0.724...</td>\n",
       "      <td>[0.5555555555555556, 0.6213991769547325, 0.724...</td>\n",
       "      <td>[0.4830601953986763, 0.5993548387096774, 0.722...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6512132883071899, 0.6700...</td>\n",
       "      <td>[0.49176954732510286, 0.6625514403292181, 0.62...</td>\n",
       "      <td>[0.49176954732510286, 0.6625514403292181, 0.62...</td>\n",
       "      <td>[0.3296551724137931, 0.6558133107629591, 0.598...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">random</th>\n",
       "      <th>0</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6577029973268509, 0.6625113010406494, 0.651...</td>\n",
       "      <td>[0.6748971193415638, 0.7098765432098766, 0.695...</td>\n",
       "      <td>[0.6748971193415638, 0.7098765432098766, 0.695...</td>\n",
       "      <td>[0.6739639945652174, 0.7011604530171343, 0.691...</td>\n",
       "      <td>[[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6459900438785553, 0.6732913494110108, 0.649...</td>\n",
       "      <td>[0.6748971193415638, 0.5987654320987654, 0.730...</td>\n",
       "      <td>[0.6748971193415638, 0.5987654320987654, 0.730...</td>\n",
       "      <td>[0.6708333333333334, 0.5652173913043478, 0.730...</td>\n",
       "      <td>[[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6794537752866745, 0.6374668717384339, 0.640...</td>\n",
       "      <td>[0.6152263374485597, 0.5534979423868313, 0.547...</td>\n",
       "      <td>[0.6152263374485597, 0.5534979423868313, 0.547...</td>\n",
       "      <td>[0.6121904696881121, 0.48521723850107634, 0.46...</td>\n",
       "      <td>[[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.6245803534984589, 0.6433198928833008, 0.631...</td>\n",
       "      <td>[0.5555555555555556, 0.6090534979423868, 0.730...</td>\n",
       "      <td>[0.5555555555555556, 0.6090534979423868, 0.730...</td>\n",
       "      <td>[0.4830601953986763, 0.589527027027027, 0.7304...</td>\n",
       "      <td>[[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100, 150, 200, 250, 300, 350, 400, 450, 500, ...</td>\n",
       "      <td>[0.650259718298912, 0.6340792775154114, 0.6493...</td>\n",
       "      <td>[0.49176954732510286, 0.588477366255144, 0.722...</td>\n",
       "      <td>[0.49176954732510286, 0.588477366255144, 0.722...</td>\n",
       "      <td>[0.3296551724137931, 0.5326293924182102, 0.721...</td>\n",
       "      <td>[[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          labeled  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    dal             0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    entropy         0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    entropy_dropout 0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                    random          0           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    1           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    2           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    3           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "                                    4           [100, 150, 200, 250, 300, 350, 400, 450, 500, ...   \n",
       "\n",
       "                                                                                       train_loss  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6577029973268509, 0.6469762802124024, 0.636...   \n",
       "                                    1           [0.6459900438785553, 0.6821997761726379, 0.616...   \n",
       "                                    2           [0.6794537752866745, 0.6754907011985779, 0.601...   \n",
       "                                    3           [0.6245803534984589, 0.6158845901489258, 0.592...   \n",
       "                                    4           [0.650259718298912, 0.6353173375129699, 0.6251...   \n",
       "                    dal             0           [0.6577029973268509, 0.6642346858978272, 0.663...   \n",
       "                                    1           [0.6459900438785553, 0.6488877415657044, 0.636...   \n",
       "                                    2           [0.6794537752866745, 0.651800012588501, 0.6412...   \n",
       "                                    3           [0.6245803534984589, 0.6310327291488648, 0.683...   \n",
       "                                    4           [0.650259718298912, 0.6481092929840088, 0.6514...   \n",
       "                    entropy         0           [0.6577029973268509, 0.6654908657073975, 0.656...   \n",
       "                                    1           [0.6459900438785553, 0.6613013267517089, 0.672...   \n",
       "                                    2           [0.6794537752866745, 0.6476762533187866, 0.629...   \n",
       "                                    3           [0.6245803534984589, 0.6380608439445495, 0.643...   \n",
       "                                    4           [0.650259718298912, 0.642036247253418, 0.67306...   \n",
       "                    entropy_dropout 0           [0.6577029973268509, 0.6431065201759338, 0.632...   \n",
       "                                    1           [0.6459900438785553, 0.6572281002998352, 0.609...   \n",
       "                                    2           [0.6794537752866745, 0.6576382756233216, 0.652...   \n",
       "                                    3           [0.6245803534984589, 0.6216179490089416, 0.625...   \n",
       "                                    4           [0.650259718298912, 0.6512132883071899, 0.6700...   \n",
       "                    random          0           [0.6577029973268509, 0.6625113010406494, 0.651...   \n",
       "                                    1           [0.6459900438785553, 0.6732913494110108, 0.649...   \n",
       "                                    2           [0.6794537752866745, 0.6374668717384339, 0.640...   \n",
       "                                    3           [0.6245803534984589, 0.6433198928833008, 0.631...   \n",
       "                                    4           [0.650259718298912, 0.6340792775154114, 0.6493...   \n",
       "\n",
       "                                                                                    test_accuracy  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6748971193415638, 0.551440329218107, 0.5452...   \n",
       "                                    1           [0.6748971193415638, 0.49588477366255146, 0.56...   \n",
       "                                    2           [0.6152263374485597, 0.5061728395061729, 0.5, ...   \n",
       "                                    3           [0.5555555555555556, 0.49794238683127573, 0.49...   \n",
       "                                    4           [0.49176954732510286, 0.49382716049382713, 0.4...   \n",
       "                    dal             0           [0.6748971193415638, 0.6604938271604939, 0.666...   \n",
       "                                    1           [0.6748971193415638, 0.6893004115226338, 0.703...   \n",
       "                                    2           [0.6152263374485597, 0.7078189300411523, 0.713...   \n",
       "                                    3           [0.5555555555555556, 0.6851851851851852, 0.716...   \n",
       "                                    4           [0.49176954732510286, 0.654320987654321, 0.703...   \n",
       "                    entropy         0           [0.6748971193415638, 0.6728395061728395, 0.699...   \n",
       "                                    1           [0.6748971193415638, 0.6008230452674898, 0.707...   \n",
       "                                    2           [0.6152263374485597, 0.7119341563786008, 0.563...   \n",
       "                                    3           [0.5555555555555556, 0.7016460905349794, 0.646...   \n",
       "                                    4           [0.49176954732510286, 0.7160493827160493, 0.68...   \n",
       "                    entropy_dropout 0           [0.6748971193415638, 0.5267489711934157, 0.707...   \n",
       "                                    1           [0.6748971193415638, 0.6954732510288066, 0.520...   \n",
       "                                    2           [0.6152263374485597, 0.7222222222222222, 0.722...   \n",
       "                                    3           [0.5555555555555556, 0.6213991769547325, 0.724...   \n",
       "                                    4           [0.49176954732510286, 0.6625514403292181, 0.62...   \n",
       "                    random          0           [0.6748971193415638, 0.7098765432098766, 0.695...   \n",
       "                                    1           [0.6748971193415638, 0.5987654320987654, 0.730...   \n",
       "                                    2           [0.6152263374485597, 0.5534979423868313, 0.547...   \n",
       "                                    3           [0.5555555555555556, 0.6090534979423868, 0.730...   \n",
       "                                    4           [0.49176954732510286, 0.588477366255144, 0.722...   \n",
       "\n",
       "                                                                                         f1_micro  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6748971193415638, 0.551440329218107, 0.5452...   \n",
       "                                    1           [0.6748971193415638, 0.49588477366255146, 0.56...   \n",
       "                                    2           [0.6152263374485597, 0.5061728395061729, 0.5, ...   \n",
       "                                    3           [0.5555555555555556, 0.49794238683127573, 0.49...   \n",
       "                                    4           [0.49176954732510286, 0.49382716049382713, 0.4...   \n",
       "                    dal             0           [0.6748971193415638, 0.6604938271604939, 0.666...   \n",
       "                                    1           [0.6748971193415638, 0.6893004115226338, 0.703...   \n",
       "                                    2           [0.6152263374485597, 0.7078189300411522, 0.713...   \n",
       "                                    3           [0.5555555555555556, 0.6851851851851852, 0.716...   \n",
       "                                    4           [0.49176954732510286, 0.654320987654321, 0.703...   \n",
       "                    entropy         0           [0.6748971193415638, 0.6728395061728395, 0.699...   \n",
       "                                    1           [0.6748971193415638, 0.6008230452674898, 0.707...   \n",
       "                                    2           [0.6152263374485597, 0.7119341563786008, 0.563...   \n",
       "                                    3           [0.5555555555555556, 0.7016460905349794, 0.646...   \n",
       "                                    4           [0.49176954732510286, 0.7160493827160493, 0.68...   \n",
       "                    entropy_dropout 0           [0.6748971193415638, 0.5267489711934157, 0.707...   \n",
       "                                    1           [0.6748971193415638, 0.6954732510288066, 0.520...   \n",
       "                                    2           [0.6152263374485597, 0.7222222222222222, 0.722...   \n",
       "                                    3           [0.5555555555555556, 0.6213991769547325, 0.724...   \n",
       "                                    4           [0.49176954732510286, 0.6625514403292181, 0.62...   \n",
       "                    random          0           [0.6748971193415638, 0.7098765432098766, 0.695...   \n",
       "                                    1           [0.6748971193415638, 0.5987654320987654, 0.730...   \n",
       "                                    2           [0.6152263374485597, 0.5534979423868313, 0.547...   \n",
       "                                    3           [0.5555555555555556, 0.6090534979423868, 0.730...   \n",
       "                                    4           [0.49176954732510286, 0.588477366255144, 0.722...   \n",
       "\n",
       "                                                                                         f1_macro  \\\n",
       "dataset model model sampler         experiment                                                      \n",
       "TREC-2  BERT  BERT  core_set        0           [0.6739639945652174, 0.45776695054045197, 0.44...   \n",
       "                                    1           [0.6708333333333334, 0.3350830657545721, 0.486...   \n",
       "                                    2           [0.6121904696881121, 0.36681649403947625, 0.34...   \n",
       "                                    3           [0.4830601953986763, 0.33955622883621456, 0.33...   \n",
       "                                    4           [0.3296551724137931, 0.3305785123966942, 0.339...   \n",
       "                    dal             0           [0.6739639945652174, 0.6492540251151437, 0.648...   \n",
       "                                    1           [0.6708333333333334, 0.6868489888925396, 0.699...   \n",
       "                                    2           [0.6121904696881121, 0.7060216739367502, 0.706...   \n",
       "                                    3           [0.4830601953986763, 0.6752514510571208, 0.715...   \n",
       "                                    4           [0.3296551724137931, 0.6377318306859525, 0.703...   \n",
       "                    entropy         0           [0.6739639945652174, 0.6620084242018659, 0.698...   \n",
       "                                    1           [0.6708333333333334, 0.5784343533704148, 0.697...   \n",
       "                                    2           [0.6121904696881121, 0.6991989248262569, 0.490...   \n",
       "                                    3           [0.4830601953986763, 0.6958658996059679, 0.637...   \n",
       "                                    4           [0.3296551724137931, 0.7139127764127764, 0.689...   \n",
       "                    entropy_dropout 0           [0.6739639945652174, 0.425531914893617, 0.7068...   \n",
       "                                    1           [0.6708333333333334, 0.6904352017628426, 0.392...   \n",
       "                                    2           [0.6121904696881121, 0.7212296318327633, 0.712...   \n",
       "                                    3           [0.4830601953986763, 0.5993548387096774, 0.722...   \n",
       "                                    4           [0.3296551724137931, 0.6558133107629591, 0.598...   \n",
       "                    random          0           [0.6739639945652174, 0.7011604530171343, 0.691...   \n",
       "                                    1           [0.6708333333333334, 0.5652173913043478, 0.730...   \n",
       "                                    2           [0.6121904696881121, 0.48521723850107634, 0.46...   \n",
       "                                    3           [0.4830601953986763, 0.589527027027027, 0.7304...   \n",
       "                                    4           [0.3296551724137931, 0.5326293924182102, 0.721...   \n",
       "\n",
       "                                                                                         selected  \n",
       "dataset model model sampler         experiment                                                     \n",
       "TREC-2  BERT  BERT  core_set        0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    dal             0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    entropy         0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    entropy_dropout 0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  \n",
       "                    random          0           [[1549, 1546, 1179, 111, 561, 1832, 619, 56, 5...  \n",
       "                                    1           [[998, 1179, 1018, 232, 1471, 696, 1089, 891, ...  \n",
       "                                    2           [[454, 565, 154, 1536, 1952, 959, 1490, 816, 1...  \n",
       "                                    3           [[1736, 11, 1693, 1079, 1304, 1144, 1330, 1452...  \n",
       "                                    4           [[1268, 33, 599, 432, 1073, 156, 1319, 589, 81...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.groupby([\"dataset\", \"model\", \"model\", \"sampler\", \"experiment\"]).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa2b72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr.groupby([\"dataset\", \"model\", \"model\", \"sampler\", \"experiment\"]).agg(list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f7c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from podium import Vocab, Field, LabelField, Iterator  # , BucketIterator\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.datasets.hf import HFDatasetConverter\n",
    "from podium.vectorizers import GloVe\n",
    "from podium.utils.general_utils import repr_type_and_attrs\n",
    "\n",
    "from typing import Iterator as PythonIterator\n",
    "from typing import NamedTuple, Tuple\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from util import Config\n",
    "\n",
    "\n",
    "class BucketIterator(Iterator):\n",
    "    \"\"\"\n",
    "    Creates a bucket iterator which uses a look-ahead heuristic to batch\n",
    "    examples in a way that minimizes the amount of necessary padding.\n",
    "\n",
    "    Uses a bucket of size N x batch_size, and sorts instances within the bucket\n",
    "    before splitting into batches, minimizing necessary padding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset=None,\n",
    "        batch_size=32,\n",
    "        sort_key=None,\n",
    "        shuffle=True,\n",
    "        seed=1,\n",
    "        matrix_class=np.array,\n",
    "        internal_random_state=None,\n",
    "        look_ahead_multiplier=100,\n",
    "        bucket_sort_key=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates a BucketIterator with the given bucket sort key and look-ahead\n",
    "        multiplier (how many batch_sizes to look ahead when sorting examples for\n",
    "        batches).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        look_ahead_multiplier : int\n",
    "            Multiplier of ``batch_size`` which determines the size of the\n",
    "            look-ahead bucket.\n",
    "            If ``look_ahead_multiplier == 1``, then the BucketIterator behaves\n",
    "            like a normal Iterator.\n",
    "            If ``look_ahead_multiplier >= (num_examples / batch_size)``, then\n",
    "            the BucketIterator behaves like a normal iterator that sorts the\n",
    "            whole dataset.\n",
    "            Default is ``100``.\n",
    "            The callable object used to sort examples in the bucket.\n",
    "            If ``bucket_sort_key=None``, then the ``sort_key`` must not be ``None``,\n",
    "            otherwise a ``ValueError`` is raised.\n",
    "            Default is ``None``.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If sort_key and bucket_sort_key are both None.\n",
    "        \"\"\"\n",
    "\n",
    "        if sort_key is None and bucket_sort_key is None:\n",
    "            raise ValueError(\n",
    "                \"For BucketIterator to work, either sort_key or \"\n",
    "                \"bucket_sort_key must be != None.\"\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            sort_key=sort_key,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            matrix_class=matrix_class,\n",
    "            internal_random_state=internal_random_state,\n",
    "        )\n",
    "\n",
    "        self.bucket_sort_key = bucket_sort_key\n",
    "        self.look_ahead_multiplier = look_ahead_multiplier\n",
    "\n",
    "    def __iter__(self) -> PythonIterator[Tuple[NamedTuple, NamedTuple]]:\n",
    "        step = self.batch_size * self.look_ahead_multiplier\n",
    "        dataset = self._dataset\n",
    "\n",
    "        # Fix: Shuffle dataset if the shuffle is turned on, only IF sort key is not none\n",
    "        if self._shuffle and self._sort_key is None:\n",
    "            indices = list(range(len(dataset)))\n",
    "            # Cache state prior to shuffle so we can use it when unpickling\n",
    "            self._shuffler_state = self.get_internal_random_state()\n",
    "            self._shuffler.shuffle(indices)\n",
    "            # dataset.shuffle_examples(random_state=self._shuffler_state)\n",
    "            dataset = dataset[indices]\n",
    "\n",
    "        # Determine the step where iteration was stopped for lookahead & within bucket\n",
    "        lookahead_start = (\n",
    "            self.iterations // self.look_ahead_multiplier * self.look_ahead_multiplier\n",
    "        )\n",
    "        batch_start = self.iterations % self.look_ahead_multiplier\n",
    "\n",
    "        if self._sort_key is not None:\n",
    "            dataset = dataset.sorted(key=self._sort_key)\n",
    "        for i in range(lookahead_start, len(dataset), step):\n",
    "            bucket = dataset[i : i + step]\n",
    "\n",
    "            if self.bucket_sort_key is not None:\n",
    "                bucket = bucket.sorted(key=self.bucket_sort_key)\n",
    "\n",
    "            for j in range(batch_start, len(bucket), self.batch_size):\n",
    "                batch_dataset = bucket[j : j + self.batch_size]\n",
    "                batch = self._create_batch(batch_dataset)\n",
    "\n",
    "                yield batch\n",
    "                self._iterations += 1\n",
    "\n",
    "        # prepare for new epoch\n",
    "        self._iterations = 0\n",
    "        self._epoch += 1\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        attrs = {\n",
    "            \"batch_size\": self._batch_size,\n",
    "            \"epoch\": self._epoch,\n",
    "            \"iteration\": self._iterations,\n",
    "            \"shuffle\": self._shuffle,\n",
    "            \"look_ahead_multiplier\": self.look_ahead_multiplier,\n",
    "        }\n",
    "        return repr_type_and_attrs(self, attrs, with_newlines=True)\n",
    "\n",
    "\n",
    "class TokenizerVocabWrapper:\n",
    "    def __init__(self, tokenizer):\n",
    "        # wrap BertTokenizer so the method signatures align with podium\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def get_padding_index(self):\n",
    "        return self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenizer)\n",
    "\n",
    "    def numericalize(self, instance):\n",
    "        # Equivalent to .encode, but I want to delineate the steps\n",
    "        return self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(instance))\n",
    "\n",
    "\n",
    "def load_embeddings(vocab, name=\"glove\"):\n",
    "    if name == \"glove\":\n",
    "        glove = GloVe()\n",
    "        embeddings = glove.load_vocab(vocab)\n",
    "        return embeddings\n",
    "    else:\n",
    "        raise ValueError(f\"Wrong embedding key provided {name}\")\n",
    "\n",
    "\n",
    "def make_iterable(dataset, device, batch_size=32, train=False, indices=None):\n",
    "    \"\"\"\n",
    "    Construct a DataLoader from a podium Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def instance_length(instance):\n",
    "        raw, tokenized = instance.text\n",
    "        return -len(tokenized)\n",
    "\n",
    "    def cast_to_device(data):\n",
    "        return torch.tensor(np.array(data), device=device)\n",
    "\n",
    "    # Selects examples at given indices to support subset iteration.\n",
    "    if indices is not None:\n",
    "        dataset = dataset[indices]\n",
    "\n",
    "    # iterator = BucketIterator(\n",
    "    #     dataset,\n",
    "    #     batch_size=batch_size,\n",
    "    #     sort_key=instance_length,\n",
    "    #     shuffle=train,\n",
    "    #     matrix_class=cast_to_device,\n",
    "    #     look_ahead_multiplier=20,\n",
    "    # )\n",
    "\n",
    "    iterator = Iterator(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=train,\n",
    "        matrix_class=cast_to_device,\n",
    "    )\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "class Instance:\n",
    "    def __init__(self, index, text, label, extras=None):\n",
    "        self.index = index\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.extras = extras\n",
    "        self.length = len(text)  # text is already tokenized & filtered\n",
    "\n",
    "    def set_mask(self, masked_text, masked_labels):\n",
    "        # Set the masking as an attribute\n",
    "        self.masked_text = masked_text\n",
    "        self.masked_labels = masked_labels\n",
    "\n",
    "    def set_numericalized(self, indices, target):\n",
    "        self.numericalized_text = indices\n",
    "        self.numericalized_label = target\n",
    "        self.length = len(indices)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.index}: {self.length}, {self.label}\"\n",
    "\n",
    "\n",
    "def generate_eraser_rationale_mask(tokens, evidences):\n",
    "    mask = torch.zeros(len(tokens))  # zeros for where you can attend to\n",
    "\n",
    "    any_evidence_left = False\n",
    "    for ev in evidences:\n",
    "        if ev.start_token > len(tokens) or ev.end_token > len(tokens):\n",
    "            continue  # evidence out of span\n",
    "\n",
    "        if not any_evidence_left:\n",
    "            any_evidence_left = True\n",
    "        # 1. Validate\n",
    "\n",
    "        assert ev.text == \" \".join(\n",
    "            tokens[ev.start_token : ev.end_token]\n",
    "        ), \"Texts dont match; did you filter some tokens?\"\n",
    "\n",
    "        mask[ev.start_token : ev.end_token] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def load_tse(\n",
    "    train_path=\"data/TSE/train.csv\", test_path=\"data/TSE/test.csv\", max_size=20000\n",
    "):\n",
    "\n",
    "    vocab = Vocab(max_size=max_size)\n",
    "    fields = [\n",
    "        Field(\"id\", numericalizer=None),\n",
    "        Field(\"text\", numericalizer=vocab, include_lengths=True),\n",
    "        Field(\"rationale\", numericalizer=vocab),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "    train_dataset = TabularDataset(\n",
    "        train_path, format=\"csv\", fields=fields, skip_header=True\n",
    "    )\n",
    "    test_dataset = TabularDataset(\n",
    "        test_path, format=\"csv\", fields=fields, skip_header=True\n",
    "    )\n",
    "    train_dataset.finalize_fields()\n",
    "    return (train_dataset, test_dataset), vocab\n",
    "\n",
    "\n",
    "class MaxLenHook:\n",
    "    def __init__(self, max_len):\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, raw, tokenized):\n",
    "        return raw, tokenized[: self.max_len]\n",
    "\n",
    "\n",
    "def lowercase_hook(raw, tokenized):\n",
    "    return raw, [tok.lower() for tok in tokenized]\n",
    "\n",
    "\n",
    "def isalnum(token):\n",
    "    return any(c.isalnum() for c in token)\n",
    "\n",
    "\n",
    "def remove_nonalnum(raw, tokenized):\n",
    "    # Remove non alphanumeric tokens\n",
    "    return raw, [tok for tok in tokenized if isalnum(tok)]\n",
    "\n",
    "\n",
    "def load_imdb(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/IMDB\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_isear(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/ISEAR\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_agn2(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/AGN-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_agn4(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/AGN-4\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_mnli(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/MNLI\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_mrpc(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/MRPC\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_qqp(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_sequence_pair_dataset(\n",
    "        \"data/GLUE/QQP\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def test_load_cola(meta, tok):\n",
    "    splits, vocab = load_cola(meta, tok)\n",
    "    print(vocab)\n",
    "    train, valid, test = splits\n",
    "    print(len(train), len(valid), len(test))\n",
    "\n",
    "    print(train)\n",
    "    print(train[0])\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_iter = make_iterable(test, device, batch_size=2)\n",
    "    batch = next(iter(train_iter))\n",
    "\n",
    "    print(batch)\n",
    "    text, length = batch.text\n",
    "    print(length[0])\n",
    "    print(vocab.get_padding_index())\n",
    "\n",
    "\n",
    "def load_sequence_pair_dataset(\n",
    "    data_dir, meta, tokenizer=None, max_vocab_size=20_000, max_seq_len=200\n",
    "):\n",
    "\n",
    "    # Use BERT subword tokenization\n",
    "    vocab = TokenizerVocabWrapper(tokenizer)\n",
    "    print(vocab.get_padding_index())\n",
    "    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    fields = [\n",
    "        Field(\"id\", disable_batch_matrix=True),\n",
    "        Field(\n",
    "            \"sequence1\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "        Field(\n",
    "            \"sequence2\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "\n",
    "    train = TabularDataset(\n",
    "        os.path.join(data_dir, \"train.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    val = TabularDataset(\n",
    "        os.path.join(data_dir, \"validation.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    test = TabularDataset(\n",
    "        os.path.join(data_dir, \"test.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "\n",
    "    train.finalize_fields()\n",
    "\n",
    "    meta.vocab = vocab\n",
    "    meta.num_tokens = len(vocab)\n",
    "    meta.padding_idx = vocab.get_padding_index()\n",
    "    meta.num_labels = len(train.field(\"label\").vocab)\n",
    "\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    data_dir, meta, tokenizer=None, max_vocab_size=20_000, max_seq_len=200\n",
    "):\n",
    "\n",
    "    # Use BERT subword tokenization\n",
    "    vocab = TokenizerVocabWrapper(tokenizer)\n",
    "    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    fields = [\n",
    "        Field(\"id\", disable_batch_matrix=True),\n",
    "        Field(\n",
    "            \"text\",\n",
    "            tokenizer=tokenizer.tokenize,\n",
    "            padding_token=pad_index,\n",
    "            numericalizer=tokenizer.convert_tokens_to_ids,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[\n",
    "                remove_nonalnum,\n",
    "                MaxLenHook(max_seq_len),\n",
    "                lowercase_hook,\n",
    "            ],\n",
    "        ),\n",
    "#         LabelField(\"label\"),\n",
    "    ]\n",
    "\n",
    "    train = TabularDataset(\n",
    "        os.path.join(data_dir, \"train.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    val = TabularDataset(\n",
    "        os.path.join(data_dir, \"validation.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "    test = TabularDataset(\n",
    "        os.path.join(data_dir, \"test.csv\"), format=\"csv\", fields=fields\n",
    "    )\n",
    "\n",
    "    train.finalize_fields()\n",
    "\n",
    "    meta.vocab = vocab\n",
    "    meta.num_tokens = len(vocab)\n",
    "    meta.padding_idx = vocab.get_padding_index()\n",
    "    meta.num_labels = len(train.field(\"label\").vocab)\n",
    "\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def load_sst(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "    return load_dataset(\n",
    "        \"data/GLUE/SST-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def test_load_sst(max_vocab_size=20_000, max_seq_len=200):\n",
    "    splits, vocab = load_sst()\n",
    "    print(vocab)\n",
    "    train, valid, test = splits\n",
    "    print(len(train), len(valid), len(test))\n",
    "\n",
    "    print(train)\n",
    "    print(train[0])\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_iter = make_iterable(train, device, batch_size=2)\n",
    "    batch = next(iter(train_iter))\n",
    "\n",
    "    print(batch)\n",
    "    text, length = batch.text\n",
    "    print(vocab.reverse_numericalize(text[0]))\n",
    "    print(length[0])\n",
    "    print(vocab.get_padding_index())\n",
    "\n",
    "\n",
    "def load_trec2(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/TREC-2\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_trec6(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/TREC-6\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_cola(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/GLUE/COLA\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_polarity(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/POL\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_subj(\n",
    "    meta,\n",
    "    tokenizer=None,\n",
    "    max_vocab_size=20_000,\n",
    "    max_seq_len=200,\n",
    "):\n",
    "\n",
    "    return load_dataset(\n",
    "        \"data/SUBJ\",\n",
    "        meta=meta,\n",
    "        tokenizer=tokenizer,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_trec_hf(label=\"label-coarse\", max_vocab_size=20_000, max_seq_len=200):\n",
    "    vocab = Vocab(max_size=max_vocab_size)\n",
    "    fields = [\n",
    "        Field(\n",
    "            \"text\",\n",
    "            numericalizer=vocab,\n",
    "            include_lengths=True,\n",
    "            posttokenize_hooks=[MaxLenHook(max_seq_len)],\n",
    "            keep_raw=True,\n",
    "        ),\n",
    "        LabelField(\"label\"),\n",
    "    ]\n",
    "    hf_dataset = load_dataset(\"trec\")\n",
    "    hf_dataset = hf_dataset.rename_column(label, \"label\")\n",
    "    print(hf_dataset)\n",
    "    hf_train_val, hf_test = (\n",
    "        hf_dataset[\"train\"],\n",
    "        hf_dataset[\"test\"],\n",
    "    )\n",
    "    train_val_conv = HFDatasetConverter(hf_train_val, fields=fields)\n",
    "    test_conv = HFDatasetConverter(hf_test, fields=fields)\n",
    "    train_val, test = (\n",
    "        train_val_conv.as_dataset(),\n",
    "        test_conv.as_dataset(),\n",
    "    )\n",
    "    train, val = train_val.split(split_ratio=0.8, random_state=0)\n",
    "    train.finalize_fields()\n",
    "    print(train)\n",
    "    return (train, val, test), vocab\n",
    "\n",
    "\n",
    "def add_ids_to_files(root_folder):\n",
    "    split_ins = [\"train_old.csv\", \"dev_old.csv\", \"test_old.csv\"]\n",
    "    split_outs = [\"train.csv\", \"dev.csv\", \"test.csv\"]\n",
    "\n",
    "    for split_in, split_out in zip(split_ins, split_outs):\n",
    "        with open(os.path.join(root_folder, split_in), \"r\") as infile:\n",
    "            with open(os.path.join(root_folder, split_out), \"w\") as outfile:\n",
    "                for idx, line in enumerate(infile):\n",
    "                    parts = line.strip().split(\",\")\n",
    "                    if idx == 0:\n",
    "                        continue\n",
    "                    outfile.write(f\"{idx-1},{parts[0]},{parts[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f7155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from args import *\n",
    "\n",
    "args = Config()\n",
    "args.lr = 2e-5\n",
    "args.l2 = 0\n",
    "args.model = \"BERT\"\n",
    "args.data = \"TREC-6\"\n",
    "args.adapter = \"unipelt\"\n",
    "args.batch_size = 32\n",
    "args.epochs = 10\n",
    "args.clip = 1\n",
    "\n",
    "meta = Config()\n",
    "\n",
    "dataloader = dataset_loaders[args.data]\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMERS[args.model])\n",
    "(train, val, test), vocab = dataloader(meta=meta, tokenizer=tokenizer)\n",
    "\n",
    "if args.data in pair_sequence_datasets:\n",
    "    meta.pair_sequence = True\n",
    "else:\n",
    "    meta.pair_sequence = False\n",
    "\n",
    "if meta.num_labels == 2:\n",
    "    # Binary classification\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    meta.num_targets = 1\n",
    "else:\n",
    "    # Multiclass classification\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    meta.num_targets = meta.num_labels\n",
    "    \n",
    "model = Transformer(args, meta, args.model, adapter=args.adapter)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_iterable(dataset, device, batch_size=32, train=False, indices=None):\n",
    "    \"\"\"\n",
    "    Construct a DataLoader from a podium Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def instance_length(instance):\n",
    "        raw, tokenized = instance.text\n",
    "        return -len(tokenized)\n",
    "\n",
    "    def cast_to_device(data):\n",
    "        return torch.tensor(np.array(data), device=device)\n",
    "\n",
    "    # Selects examples at given indices to support subset iteration.\n",
    "    if indices is not None:\n",
    "        dataset = dataset[indices]\n",
    "\n",
    "    iterator = BucketIterator(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=instance_length,\n",
    "        shuffle=train,\n",
    "        matrix_class=cast_to_device,\n",
    "        look_ahead_multiplier=20,\n",
    "    )\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=True,\n",
    "#     indices=indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1a6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from al.experiment import Experiment\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_iter):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    accuracy, confusion_matrix = 0, np.zeros(\n",
    "        (meta.num_labels, meta.num_labels), dtype=int\n",
    "    )\n",
    "\n",
    "    logit_list = []\n",
    "    y_true_list = []\n",
    "    ids = []\n",
    "    for batch_num, batch in enumerate(train_iter, 1):\n",
    "        t = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids.extend([int(id[0]) for id in batch.id])\n",
    "\n",
    "        # Unpack batch & cast to device\n",
    "        if meta.pair_sequence:\n",
    "            (x_sequence1, sequence1_lengths) = batch.sequence1\n",
    "            (x_sequence2, sequence2_lengths) = batch.sequence2\n",
    "        else:\n",
    "            (x, lengths) = batch.text\n",
    "\n",
    "        y = batch.label\n",
    "        y_true_list.append(y.squeeze(0) if y.numel() == 1 else y.squeeze())\n",
    "\n",
    "        if meta.pair_sequence:\n",
    "            # PSQ\n",
    "            lengths = (sequence1_lengths, sequence2_lengths)\n",
    "            logits, return_dict = model(x_sequence1, x_sequence2, lengths)\n",
    "        else:\n",
    "            # SSQ\n",
    "            logits, return_dict = model(x, lengths)\n",
    "        logit_list.append(logits)\n",
    "\n",
    "        # Bookkeeping and cast label to float\n",
    "        accuracy, confusion_matrix = Experiment.update_stats(\n",
    "            accuracy, confusion_matrix, logits, y\n",
    "        )\n",
    "        if logits.shape[-1] == 1:\n",
    "            # binary cross entropy, cast labels to float\n",
    "            y = y.type(torch.float)\n",
    "\n",
    "        loss = criterion(logits.view(-1, meta.num_targets).squeeze(), y.squeeze())\n",
    "\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Batch]: {}/{} in {:.5f} seconds\".format(\n",
    "                batch_num, len(train_iter), time.time() - t\n",
    "            ),\n",
    "            end=\"\\r\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    loss = total_loss / len(train_iter)\n",
    "    result_dict = {\"loss\": loss}\n",
    "    logit_tensor = torch.cat(logit_list)\n",
    "    y_true = torch.cat(y_true_list)\n",
    "    return result_dict, logit_tensor, y_true, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022001ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/10\n",
      "{'loss': 1.5692268680123722}seconds\n",
      "Training epoch: 2/10\n",
      "{'loss': 1.233461660107756} seconds\n",
      "Training epoch: 3/10\n",
      "{'loss': 0.8343249787302578}seconds\n",
      "Training epoch: 4/10\n",
      "{'loss': 0.5697764279016482}seconds\n",
      "Training epoch: 5/10\n",
      "{'loss': 0.4263514495558209}seconds\n",
      "Training epoch: 6/10\n",
      "{'loss': 0.349474528207888} seconds\n",
      "Training epoch: 7/10\n",
      "{'loss': 0.30121782519458945}econds\n",
      "Training epoch: 8/10\n",
      "{'loss': 0.25657056335335465}econds\n",
      "Training epoch: 9/10\n",
      "{'loss': 0.22974231799005293}econds\n",
      "Training epoch: 10/10\n",
      "{'loss': 0.2082190094820035}seconds\n"
     ]
    }
   ],
   "source": [
    "train_results = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(f\"Training epoch: {epoch}/{args.epochs}\")\n",
    "    # a) Train for one epoch\n",
    "    result_dict_train, logits, y_true, ids = train_model(\n",
    "        model, optimizer, criterion, train_iter\n",
    "    )\n",
    "    print(result_dict_train)\n",
    "    train_results.append(result_dict_train)\n",
    "\n",
    "    # b) Evaluate model (test set)\n",
    "#     eval_result_dict = self._evaluate_model(model)\n",
    "#     acc.append(eval_result_dict[\"accuracy\"])\n",
    "#     loss.append(result_dict_train[\"loss\"])\n",
    "#     eval_results.append(eval_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57b1c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "name = model.get_classifier_name()\n",
    "clf = model.classifier #getattr(model.classifier, name)\n",
    "config = model.classifier.config\n",
    "num_layers = config.num_hidden_layers\n",
    "\n",
    "print(num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b69027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.3900,  4.1626, -0.7429, -1.9608, -1.0143, -2.7310],\n",
       "        [ 5.2413, -1.1506,  1.8984, -2.0992, -2.6798, -1.6891],\n",
       "        [ 1.3242,  0.6738, -1.9786,  4.5847, -2.2803, -2.1135],\n",
       "        [ 4.9922, -0.5433,  0.5287, -1.2219, -2.0188, -2.5741],\n",
       "        [ 4.2137, -2.3493,  2.1044, -1.1609, -1.4063, -1.8276],\n",
       "        [-1.3099, -1.3617, -0.6319,  5.9067, -0.7854, -1.7350],\n",
       "        [ 4.2988, -0.2366,  1.2845, -2.0587, -1.3539, -2.1875],\n",
       "        [ 2.4077,  0.5523,  1.4256, -1.0230, -1.4068, -2.6421],\n",
       "        [ 4.7827, -0.8779,  1.7367, -1.8129, -2.4295, -2.4101],\n",
       "        [-0.0487,  0.8461, -0.9498,  0.4986,  1.3494, -2.3525],\n",
       "        [ 3.9158,  1.9345, -0.3427, -2.2640, -1.8074, -2.4878],\n",
       "        [ 3.3428, -1.2677,  2.7778, -1.1901, -1.8196, -2.5822],\n",
       "        [ 0.2694,  6.6043, -1.8484, -2.0286, -1.0732, -2.7626],\n",
       "        [ 1.1058,  3.6770, -1.5612, -0.3926, -0.4904, -2.9746],\n",
       "        [ 1.4879,  0.1173,  0.7719, -1.5803,  0.6612, -1.8502],\n",
       "        [ 3.0174,  1.3685,  1.8667, -2.6324, -2.1333, -2.4993],\n",
       "        [ 2.3652,  0.1952,  0.8562, -1.5894, -0.4130, -2.1312],\n",
       "        [ 4.5141,  2.1809, -0.6321, -1.9391, -2.3707, -2.8040],\n",
       "        [ 4.3300,  0.0322,  0.3474, -2.2454, -2.4219, -0.9529],\n",
       "        [-0.4264, -2.3082,  0.1749,  5.6889, -0.9003, -1.9197],\n",
       "        [ 3.7701,  0.5494, -0.5658, -0.4464, -0.8054, -3.1860],\n",
       "        [ 2.0797,  1.9312, -0.7664, -1.6480, -0.0572, -2.2358],\n",
       "        [-1.1809,  1.7517, -0.9914, -2.1966,  4.0061, -2.4559],\n",
       "        [ 5.1302,  1.1403, -0.5296, -1.6445, -2.5823, -2.5666],\n",
       "        [-0.0652,  5.6830, -1.4196, -1.9067, -0.7593, -2.3454],\n",
       "        [ 1.5925,  4.0513, -0.4621, -2.0958, -0.8604, -3.3495],\n",
       "        [ 6.2674,  0.2471, -0.5005, -1.3074, -3.1454, -2.0666],\n",
       "        [ 4.6570, -1.3299,  2.3918, -2.0621, -2.4432, -1.7714],\n",
       "        [-1.3338, -1.4758, -0.7488,  5.4782, -0.0182, -1.7354],\n",
       "        [-0.8941, -2.3177,  4.7722, -0.3214, -0.0271, -0.9140],\n",
       "        [ 2.9613, -0.2610,  2.7579, -1.9908, -2.2702, -2.0449],\n",
       "        [ 2.8808,  0.6748, -0.4252,  1.4215, -2.5883, -2.0736]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89806f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tr[\n",
    "    (df_tr.index.get_level_values(\"sampler\") == \"entropy\")\n",
    "    & (df_tr.index.get_level_values(\"mode\") == \"ada-besov\")\n",
    "    & (df_tr.index.get_level_values(\"experiment\") == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "411273be",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df.selected.agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc11b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [s for ss in selected for s in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de75de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b640940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['929'], ['3557'], ['2485'], ['4861'], ['4268'], ['4895'], ['4261'], ['3601'], ['2526'], ['4800'], ['5375'], ['515'], ['1395'], ['253'], ['2173'], ['3307'], ['2827'], ['1692'], ['2269'], ['3664'], ['1148'], ['3327'], ['3923'], ['4443'], ['3472'], ['1296'], ['2737'], ['2024'], ['580'], ['1773'], ['1002'], ['4585']],\n",
      "    text: (tensor([[ 2171,  1996,  4802,  ...,  4895, 15464,  2098],\n",
      "            [ 2054,  2003,  1996,  ...,     0,     0,     0],\n",
      "            [ 2054,  2280,  2548,  ...,     0,     0,     0],\n",
      "            ...,\n",
      "            [ 2129,  2064,  1045,  ...,     0,     0,     0],\n",
      "            [ 2054,  2001,  2928,  ...,     0,     0,     0],\n",
      "            [ 2054, 17727,  8625,  ...,     0,     0,     0]], device='cuda:0'), tensor([32, 29, 26, 24, 24, 23, 23, 23, 23, 23, 22, 22, 21, 21, 21, 21, 21, 21,\n",
      "            20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2175'], ['2037'], ['2386'], ['4238'], ['819'], ['3143'], ['2980'], ['3867'], ['1114'], ['2018'], ['2288'], ['2095'], ['3069'], ['4674'], ['4628'], ['5420'], ['994'], ['1153'], ['2261'], ['588'], ['1033'], ['4314'], ['3510'], ['5340'], ['1305'], ['2607'], ['2066'], ['4928'], ['1181'], ['1646'], ['1988'], ['417']],\n",
      "    text: (tensor([[ 2054, 15138,  2100,  3507,  2288,  1996, 14101,  3642,  5585,  2581,\n",
      "              2487,  2013,  1996,  1057,  1055, 10690,  2326,  1999,  3699],\n",
      "            [ 2054,  2165,  2034,  3396,  1999, 18168,  3490,  2932,  1055,  5049,\n",
      "              2000,  2424,  1996,  7209, 14477,  3619, 13777,  3085,  3160],\n",
      "            [ 2029,  1997,  1996,  2206,  2106,  2025,  4374,  1037,  3172,  5151,\n",
      "              2388,  2400,  2013,  1996,  2120,  2388,  1055,  2154,  2837],\n",
      "            [ 2054, 26529,  3555,  1996,  2206,  2065,  2643,  2106,  2025,  4839,\n",
      "              2009,  2052,  2022,  4072,  2000,  1999, 15338,  2032,     0],\n",
      "            [ 2054,  2106,  4907,  1037, 15922, 13238,  2094,  1998,  2198, 19337,\n",
      "             20668,  2072,  8046,  5095,  2305,  2444,  2000,  2468,     0],\n",
      "            [ 2073,  2064,  2019,  3265,  2131,  1037,  3967, 10014,  7718,  2008,\n",
      "              5296,  1996,  2972,  3302,  1997,  3239,  2043,  2047,     0],\n",
      "            [ 2054,  2001,  2761,  4225,  2004,  2028,  1015,  2454,  2705,  1997,\n",
      "              1996,  3292,  2013,  1996, 26640,  2000,  1996,  6536,     0],\n",
      "            [ 2040,  2106, 15467,  2154,  2812,  2043,  2016,  2056,  1045,  2655,\n",
      "              2032, 14637,  2138,  2002,  1055,  5121,  2053,  2600,     0],\n",
      "            [ 2054,  9469,  1996,  2522,  4405,  1997,  1996,  4372,  6030,  5637,\n",
      "              2000,  4607,  2069,  2026,  2643,  1999,  2010,  8833,     0],\n",
      "            [ 2054,  2764,  1037,  8579,  1999, 10150,  2096,  9565,  2075,  1996,\n",
      "              2331,  1997,  1057,  1055,  2708,  3425,  2198,  5832,     0],\n",
      "            [ 2054,  2848,  1038, 20051,  3723,  3117, 23412,  1996, 22812,  1997,\n",
      "             16964,  6097, 27276,  1055,  6664,  2011,  1996,  6548,     0],\n",
      "            [ 2054,  2665,  3016, 15285,  2873,  6316, 19137, 21850,  5422,  2045,\n",
      "              1055,  2498,  2008, 18716,  1996,  2543,  2066,  5223,     0],\n",
      "            [ 2054,  2003,  1996,  7835,  1997,  9413,  2571,  6156, 11764,  1055,\n",
      "              1996,  2553,  1997,  1996, 10215,  5939, 18136,  2102,     0],\n",
      "            [ 2054,  2647,  2406,  4704, 22981, 12133,  1999,  4927,  2138,  8021,\n",
      "              2068,  3465,  2062,  2084,  2037,  2227,  3643,     0,     0],\n",
      "            [ 2054, 14731,  7461,  1996,  2181,  1997,  1996, 25552,  3470,  1998,\n",
      "              2030, 26993,  3470,  1999,  1996,  2167,  2712,     0,     0],\n",
      "            [ 2054,  2106,  1996,  2830,  3241,  4079,  3428, 18112,  1997,  3190,\n",
      "             19274,  2046,  4524,  9050,  2000, 12992,  2449,     0,     0],\n",
      "            [ 2054,  2001,  4114,  2004,  1037,  8055,  8244,  2591,  2252,  1999,\n",
      "             16405,  8523,  3211,  1999,  5298,  1999,  7647,     0,     0],\n",
      "            [ 2054, 15550,  2098,  9476,  3494,  2079,  8936,  3619,  2113,  2004,\n",
      "              1058,  2721,  3900, 11721,  3900,  1998, 10164,     0,     0],\n",
      "            [ 2054, 15607,  5093,  2977,  1055,  2273,  1055,  3895,  2516,  2001,\n",
      "              5965,  6890,  1996,  2197, 25244,  2000,  2663,     0,     0],\n",
      "            [ 2054,  2079,  2017,  2131,  2011,  5815, 18749,  3406,  3676,  6895,\n",
      "             20159, 20934, 27887,  7277,  2271,  2000,  6501,     0,     0],\n",
      "            [ 2054,  2515,  1996, 15068, 24847, 21194,  3319,  1997,  7695,  5051,\n",
      "              4817,  2655,  2019,  1999, 25918,  8082,  4861,     0,     0],\n",
      "            [ 2043,  2170,  2588,  2000,  7806,  2054,  2137,  2236,  3880,  2909,\n",
      "              1045,  2031,  2025,  2664,  5625,  2000,  2954,     0,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  4268,  2265,  2013,  3010,\n",
      "              2270,  2694,  2007,  1996,  4823,  7222, 23804,     0,     0],\n",
      "            [ 2054,  2003,  1999,  3336,  9898,  1998,  3336,  2843,  3258,  2008,\n",
      "              3084,  2009,  5437,  1996,  2126,  2009,  2515,     0,     0],\n",
      "            [ 2054,  8316,  2106,  8101,  2224,  1999,  3015,  2000,  2022,  2030,\n",
      "              2025,  2000,  2022,  2008,  2003,  1996,  3160,     0,     0],\n",
      "            [ 2129,  2116,  1997,  2296,  2184,  2372,  1997,  1996, 18936, 11666,\n",
      "              2523,  2031,  2196,  2499,  1037,  8086,     0,     0,     0],\n",
      "            [ 2054,  5043,  3303,  1996, 24549,  1997,  1037,  6465,  3034,  2090,\n",
      "             16551,  1998,  1047,  8093, 20668, 16179,     0,     0,     0],\n",
      "            [ 2054,  2003,  1996,  2922,  1998,  2087,  6450, 10846,  2810,  2622,\n",
      "              1999,  1996,  1057,  1055,  2157,  2085,     0,     0,     0],\n",
      "            [ 2054,  4706,  4438,  6401,  2006,  1996,  3945,  2005,  1037,  8813,\n",
      "              1999,  2751,  4276,  1021,  1014,  7038,     0,     0,     0],\n",
      "            [ 2054,  2323,  1996, 17428,  2022,  2275,  2012,  2005, 21522, 18237,\n",
      "              2100,  1051,  4017, 14163, 15379,  2015,     0,     0,     0],\n",
      "            [ 2054,  1055,  1996,  7098,  4366,  2000,  4476,  1997,  1996,  2402,\n",
      "              2308,  2040,  2719, 16000,  6541, 23963,     0,     0,     0],\n",
      "            [ 2054,  3185,  2778,  1997,  1996,  3142,  3400,  2838,  1996,  4748,\n",
      "              8202, 22753,  5216,  2092,  1998,  2444,     0,     0,     0]],\n",
      "           device='cuda:0'), tensor([19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17,\n",
      "            17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2515'], ['1734'], ['680'], ['2581'], ['5112'], ['2583'], ['1172'], ['990'], ['1614'], ['3347'], ['2859'], ['2174'], ['558'], ['3608'], ['634'], ['3770'], ['2274'], ['1944'], ['1183'], ['4886'], ['3812'], ['388'], ['2102'], ['456'], ['2442'], ['4588'], ['1938'], ['2965'], ['3690'], ['1920'], ['1405'], ['5004']],\n",
      "    text: (tensor([[ 2054,  2003,  8965, 10556, 24316,  2050,  1055,  2460,  2466,  1037,\n",
      "              2406,  3460,  2667,  2000,  2425,  2149],\n",
      "            [ 2054,  2106,  1037,  5767,  2301, 25245,  8258,  2131,  2005,  5128,\n",
      "              1037,  8903,  3608,  2083,  1037,  3614],\n",
      "            [ 2054,  2079,  2867,  3046,  2000,  2079,  2043,  1996,  2189,  6762,\n",
      "              1999,  1037,  2208,  1997,  3315,  8397],\n",
      "            [ 2029,  2217,  1997,  1996,  2227,  2079,  2087,  3324,  7166,  2000,\n",
      "              2265,  2062,  1997,  1999,  2969,  9668],\n",
      "            [ 2054,  2001,  1996,  2030,  3540,  1055,  2171,  2008,  2351,  1997,\n",
      "              1037, 28079,  8985,  2012,  2712,  2088],\n",
      "            [ 2054,  9575,  2052,  2017,  5987,  2000,  3191,  2055,  1999,  1996,\n",
      "              7058,  4772,  1996,  2502, 13064,  2739],\n",
      "            [ 2054,  9983,  1055,  2171,  3544,  2006,  1996,  3356,  2187,  3420,\n",
      "              1997,  1037, 13007, 19845,  8043,  3830],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  3379,  2008,  2003,  2284,\n",
      "              2379,  1996,  3007,  2103,  1997, 15786],\n",
      "            [ 2054,  2079,  8594,  2140,  6243, 19971, 24865, 16391,  9579,  1998,\n",
      "             12120, 17017,  2035,  2031,  1999,  2691],\n",
      "            [ 2054,  2024,  1996, 10818, 10826,  1997,  1051, 11030,  5207,  1998,\n",
      "             14163, 20389,  5092,  1996,  6452,  2867],\n",
      "            [ 2129,  2515,  1996,  3177,  1996, 16853, 23371,  1999,  1037, 13103,\n",
      "              7461,  1996,  6434,  1997,  1996, 13103],\n",
      "            [ 2054,  2003,  1996,  2197,  2171,  1997,  7004,  1998, 11409,  2271,\n",
      "              2013,  1996, 21443,  1055,  5021,  6167],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996, 13130,  2008, 26442, 21613,\n",
      "              5652,  1999,  2007,  4116,  4907,  4143],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  1996,  3729, 12495, 25832,  1055,\n",
      "              2030, 11754, 22824,  2026,  2171,  2003],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  3185,  2008,  5652, 10666,\n",
      "              2962,  1998,  7779, 29058,  8625, 13327],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  4315, 22043,  2094,  3565,\n",
      "              4735,  8064, 13323, 18891,  2271,  3594],\n",
      "            [ 2054,  2003,  1996, 10479,  2518,  2464,  2104,  1996,  2087,  3928,\n",
      "             24635,  1998,  2129,  2502,  2003,  2009],\n",
      "            [ 1996, 16994, 14913,  2375,  3813,  2018,  2019,  2436,  1999,  1048,\n",
      "              1037,  2005,  2129,  2116,  2086,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996, 27701,  4169,  2008,  3065,\n",
      "              2048,  2398,  2007,  3093,  7244,     0],\n",
      "            [ 1999,  2026, 24272,  2129,  2003,  2720, 11895,  5017,  2850,  2041,\n",
      "              1997,  2173,  2006,  1996,  3888,     0],\n",
      "            [ 2054,  2047,  5979,  1040,  1037,  3555,  2026,  3095,  1998,  1045,\n",
      "             13332,  1996, 10102,  3134,  3283,     0],\n",
      "            [ 2054,  6568,  7815,  3850,  2001,  7153,  2011,  1996, 13146,  1997,\n",
      "              2198,  1042,  5817,  1055, 10102,     0],\n",
      "            [ 2006,  2029,  3462,  2106,  6904,  4213,  2480,  2017,  8977, 10797,\n",
      "              2250, 24386,  1998, 13446,  2635,     0],\n",
      "            [ 2054,  2394,  2773,  3310,  2013,  1996,  2214,  2413,  2522, 12229,\n",
      "              7959,  2226,  3574,  3104,  2543,     0],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  2922,  2300,  9530,  8043,\n",
      "              6212,  5666,  2622,  1999,  2859,     0],\n",
      "            [ 2129,  2064,  1045,  2131,  2619,  1055,  3042,  2193,  2065,  1045,\n",
      "              2069,  2031,  2037,  3898,  2171,     0],\n",
      "            [ 2054,  1055,  2019,  3733,  2126,  2000,  4175,  1996, 15796,  2193,\n",
      "              1997,  3869,  1999,  1037,  2697,     0],\n",
      "            [ 2054,  2447, 26783,  2015,  2019,  2779,  1997,  1017,  2335,  2076,\n",
      "              1037,  3598,  3313,  4974,  2121,     0],\n",
      "            [ 2054,  2003,  1996,  2744,  2005,  1996,  7680,  1997,  2035,  7403,\n",
      "              3430,  1999,  1037,  2445, 15923,     0],\n",
      "            [ 2054,  1055,  1996,  4292,  1997,  2198,  3393, 12385,  2063,  1055,\n",
      "              1037,  2235,  2237,  1999,  2762,     0],\n",
      "            [ 2054,  2343,  1055,  5440, 10213, 20563,  3508,  2001,  2272,  2085,\n",
      "              1998,  2292,  2149,  3114,  2362,     0],\n",
      "            [ 2054,  2515,  1054,  1041,  1049,  3233,  2005,  2004,  1999,  1996,\n",
      "              2600,  2177,  1054,  1041,  1049,     0]], device='cuda:0'), tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [5]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1995'], ['2922'], ['1802'], ['389'], ['4891'], ['3758'], ['2043'], ['3607'], ['5073'], ['1857'], ['3593'], ['4149'], ['1652'], ['2826'], ['1593'], ['2901'], ['2570'], ['3888'], ['3616'], ['3687'], ['61'], ['2941'], ['1225'], ['3373'], ['421'], ['259'], ['5382'], ['3901'], ['5144'], ['1689'], ['192'], ['3403']],\n",
      "    text: (tensor([[ 2054,  2106, 14420,  3472,  8446,  8117,  5004, 13520,  2694,  2000,\n",
      "              2022,  2006,  2089,  1023,  3777],\n",
      "            [ 2054, 25850, 24667, 16263, 14925,  4371,  2863,  7367, 12821, 25032,\n",
      "              5243,  1998,  8827, 11069,  6190],\n",
      "            [ 2054,  9348,  2340, 19748, 13128,  1996,  3573,  2096,  9143,  1998,\n",
      "              2632, 13626,  2378,  2081,  2381],\n",
      "            [ 2054,  2003,  1996,  2224,  1997,  1037,  2484,  3178,  5119,  2612,\n",
      "              1997,  1037,  2260,  3178,  5119],\n",
      "            [ 2171,  1996,  9476, 22519,  9530, 26949,  2011,  1996,  3894,  3614,\n",
      "              4207,  2011,  7912,  1998,  8057],\n",
      "            [ 2054,  8637,  3059,  4825,  2064,  2022,  2179,  2012, 23688,  2225,\n",
      "             27787,  2395,  2047,  2259,  2103],\n",
      "            [ 2054,  5021,  1997,  2694,  1055,  3585,  2287,  2253,  2011,  1996,\n",
      "             12652,  2505,  2005,  1037,  4756],\n",
      "            [ 2054, 25068,  2180,  2019,  3378,  2811,  8554,  2004,  1996,  4602,\n",
      "              3586,  1997,  1996,  3983,  2301],\n",
      "            [ 2054,  2079,  1996,  2417,  1998,  2317, 13560,  2006,  1037, 13362,\n",
      "             22231,  2361,  6536,  3233,  2005],\n",
      "            [ 1999,  2054,  2143,  2106,  7112, 28740,  1055,  3899,  2732,  2004,\n",
      "              1996,  2364,  2839,  1055,  3899],\n",
      "            [ 2054,  2236,  3257,  2515,  1996,  4990,  1999,  2105,  1996,  2088,\n",
      "              1999,  3770,  2420, 10838,  1999],\n",
      "            [ 2054,  3299,  2784,  3759, 17598,  3640,  1996,  2877,  3203,  2007,\n",
      "              1037,  2117,  2474, 18143,  2595],\n",
      "            [16994,  1998, 14913,  2018,  2019,  2436,  1999,  3050,  3349,  2005,\n",
      "              2129,  2146,  2077,  5494,  2009],\n",
      "            [ 2054,  2003,  1996,  2744,  2005,  1996,  2217,  1997,  1996,  3137,\n",
      "              2008,  5344,  1996, 19283,  7266],\n",
      "            [ 2054,  4435,  2193,  4519,  2015,  1996,  2304,  3830,  1997,  1037,\n",
      "              5835,  1997,  2990,  3817,  1055],\n",
      "            [ 2054,  2024, 18712,  2705, 15460, 10668,  7295,  2891, 14262, 11514,\n",
      "             15006,  1998,  2026, 19648,  2891],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  6011, 15185,  1037, 26035,\n",
      "              1999,  2051, 13169,  3157,     0],\n",
      "            [ 2054,  1055,  1996,  4555,  2193,  1997,  4184,  1037, 20601,  2089,\n",
      "              2224,  1999,  1037,  2461,     0],\n",
      "            [ 2054, 15873,  1057,  1055,  2343, 10964,  2010,  2219,  9450,  2044,\n",
      "              3773,  1037, 19083,  2674,     0],\n",
      "            [ 6990, 10654,  3468,  2078,  2003,  2641,  2000,  2022,  1996,  2034,\n",
      "              4823, 11762,  1997,  2054,     0],\n",
      "            [ 2054,  2515,  3668,  6210,  2812,  1998,  2129,  2052,  2028,  4339,\n",
      "              1037,  3259,  2006,  2009,     0],\n",
      "            [ 2054,  2932,  3825,  8471, 27299,  2321,  1037,  2773,  2000,  4339,\n",
      "              1037,  7087, 22158,  3720,     0],\n",
      "            [ 2129,  2003,  1996,  2047,  4811, 17338,  3630,  4179,  3158,  1042,\n",
      "             17788,  1058,  2487,  3194,     0],\n",
      "            [ 2029, 16082,  5510, 26734,  2034,  1055, 13542,  2545,  2030,  1017,\n",
      "             14163, 17140, 17389,  2869,     0],\n",
      "            [ 2073,  2442,  1037,  4715,  3125,  2666,  3233,  2000,  2022,  7936,\n",
      "              2000,  5047,  1996,  3608,     0],\n",
      "            [ 2054,  5869,  7136,  3309,  5296,  1999,  2281,  3150,  2007,  1996,\n",
      "              3279,  1997,  6391,  3268,     0],\n",
      "            [ 2054,  2112,  2106,  6425,  5951,  2377,  1999,  1996,  2458,  1997,\n",
      "              1996,  3780,  1999,  2637,     0],\n",
      "            [ 2054,  5661,  1999,  7397,  2020,  5360,  2011,  1996,  4654, 22500,\n",
      "             11748, 24601,  3514, 14437,     0],\n",
      "            [ 2054,  2515,  2019, 13402,  2078,  4320,  1041, 13820, 10727,  3945,\n",
      "              2041,  1996,  4598,  1997,     0],\n",
      "            [ 2054, 18236,  8637,  2001,  2034,  3107,  1999,  1996, 10646, 13941,\n",
      "              1997,  1996,  3878,  1055,     0],\n",
      "            [ 2029, 21151,  2221,  2610,  2533,  8243,  1996,  2922, 16034, 22613,\n",
      "              1999,  2009,  1055,  2381,     0],\n",
      "            [ 2054,  2106, 25244,  2198, 13835,  4088,  4855,  2000,  2047,  2088,\n",
      "             15526,  1999, 16734,  2475,     0]], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14,\n",
      "            14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1572'], ['4785'], ['5020'], ['5357'], ['4703'], ['165'], ['1357'], ['1950'], ['3266'], ['1529'], ['3747'], ['2146'], ['1439'], ['3189'], ['5216'], ['4743'], ['3370'], ['1516'], ['3875'], ['5312'], ['4782'], ['3'], ['2790'], ['4595'], ['2483'], ['1298'], ['1451'], ['5092'], ['4926'], ['3422'], ['2508'], ['2602']],\n",
      "    text: (tensor([[ 2029,  1997,  1996,  2206,  2600,  1050,  4897,  3340,  2038,  1037,\n",
      "              2732,  2006,  5365,  8459],\n",
      "            [ 2054,  1055,  1996,  6904, 28362, 25311, 20175,  5662,  1997,  5717,\n",
      "              5445,  9358,  8004, 13662],\n",
      "            [ 2054,  2694,  2186,  2838,  1996,  7357,  1997,  1037,  2496,  3232,\n",
      "              2315,  5655,  1998,  7673],\n",
      "            [ 2054,  2003,  1996,  4338,  1997,  1037,  2374,  2004,  3090,  1999,\n",
      "              1996,  5088,  3627,  8654],\n",
      "            [ 2054,  2001, 28722,  6262,  2725,  2000,  7796,  1015,  2199,  1999,\n",
      "              1996,  2220,  3925,  1055],\n",
      "            [ 2029,  2887,  2482,  9338,  2018,  2049,  5221,  7017,  1997,  5096,\n",
      "              1999,  1996,  4968,  3006],\n",
      "            [ 1997,  2336,  2090,  1996,  5535,  1997,  2048,  1998,  5408,  2054,\n",
      "              7017,  3422,  1996, 19047],\n",
      "            [ 2054,  2024,  1996,  2536,  3971,  1999,  2029,  2028,  2064,  5468,\n",
      "              2009,  5310,  9967,  2504],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  2343,  1997, 11721, 17830,\n",
      "              2102,  1057,  1055,  1037],\n",
      "            [ 2054,  2079,  2057,  2655,  1996, 15344,  2240,  2247,  1996,  2327,\n",
      "              1997,  1996,  6857,  4020],\n",
      "            [ 2054,  2079,  2017,  2655,  1037,  3058,  2008,  3397, 24558,  3616,\n",
      "              2066,  1023,  1022,  5818],\n",
      "            [ 2054,  2001,  1996,  8367,  1997,  2446,  3909,  9078, 19149,  3854,\n",
      "              4138,  2705, 11253,  2368],\n",
      "            [ 2054,  6531,  2686,  3658,  2090, 11275,  3927,  1998,  3752,  4296,\n",
      "              2006,  1037, 15404,  2604],\n",
      "            [ 2054, 15607,  6080,  3122, 14574,  3013,  2046,  1996,  5779,  1997,\n",
      "             12883, 17866,  1055, 11018],\n",
      "            [ 3415,  1997,  2808,  2011,  2508,  1037, 23025, 10222,  2121,  2275,\n",
      "              1999,  1996,  2206,  5269],\n",
      "            [ 2054,  2416,  3329, 23372,  8175, 15536, 14273,  2098,  2014, 11300,\n",
      "              3388,  2006, 17078,  2015],\n",
      "            [ 2171,  1996,  4031,  2008,  2003,  2012,  2115, 24665, 10085,  2121,\n",
      "              1055,  2012,  2115, 12206],\n",
      "            [ 2054,  2024,  5696,  9388, 27663,  1055,  1998,  8101,  1055,  4706,\n",
      "              5857,  2000,  2394,  3906],\n",
      "            [ 2054,  2024,  1996,  2034,  2416,  2616,  1997, 19675,  1055,  1037,\n",
      "              6925,  1997,  2048,  3655],\n",
      "            [ 2054,  2079,  2017,  2655,  1037,  2930,  1997,  2115,  4344,  2013,\n",
      "              2028,  4101,  2000,  2178],\n",
      "            [ 2054,  3972,  5555,  5666,  2003,  2124, 27427, 20806, 16280,  2135,\n",
      "              2004,  4060,  3709, 20944],\n",
      "            [ 2054,  1042,  5004,  2140, 13273,  1996, 17763,  2044,  1996,  2822,\n",
      "              2095,  1997,  1996, 10608],\n",
      "            [ 2054,  2047,  7035,  8429,  9466,  2220,  2000,  3789,  2034,  1999,\n",
      "              1057,  1055,  4883,  3864],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  2149,  7739,  4405,  2915,\n",
      "              2091,  2058,  2167,  4420],\n",
      "            [ 2054,  2024,  2070,  4569,  2477,  2000,  2079,  1999,  2522,  9759,\n",
      "             10199,  3290,  2005, 12908],\n",
      "            [ 2043,  2020,  1996,  4386,  2399,  1999,  2029, 14942, 16571,  2638,\n",
      "              6895,  2150,  2759,  2209],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996, 13608, 21435,  2017,  2128,\n",
      "             18243,  2078,  2205,  7629],\n",
      "            [ 1996,  4386,  2399,  1999,  2029,  2095,  3039, 14942, 16571,  2638,\n",
      "              6895,  2000,  2468,  2759],\n",
      "            [ 2054,  2003,  1996,  2812,  3318,  1997,  1996,  2327,  2184,  2327,\n",
      "              1019,  1998,  2327,  1015],\n",
      "            [ 2054,  3435,  2833,  2003,  4810,  2007,  1037,  3595, 12586,  1997,\n",
      "              2340, 17561,  1998, 21729],\n",
      "            [ 2054, 11075,  1999,  1996,  1057,  1055,  4552,  2089,  2025,  2022,\n",
      "              2904,  8776,  2030, 13266],\n",
      "            [ 2054,  2003,  1996,  4816,  5080,  2109,  2000,  3965,  5107,  8834,\n",
      "              7978,  2000,  3751,  7755]], device='cuda:0'), tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "            14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4857'], ['4160'], ['5165'], ['2888'], ['3369'], ['563'], ['2032'], ['3153'], ['3567'], ['3639'], ['4215'], ['1553'], ['3900'], ['4736'], ['4163'], ['1664'], ['16'], ['2154'], ['118'], ['1740'], ['509'], ['1047'], ['4611'], ['716'], ['1046'], ['5348'], ['2947'], ['2666'], ['3172'], ['5309'], ['2875'], ['1343']],\n",
      "    text: (tensor([[ 2054,  2024,  2216,  2210,  2630,  8339,  5668,  1999,  1996,  2690,\n",
      "              1997,  1996,  2346,  2005],\n",
      "            [ 2054,  2003,  1996,  2712, 14971,  2075,  2171,  2005,  1996,  2670,\n",
      "              5955,  1997,  2148,  2637],\n",
      "            [ 2054,  7966,  2003,  2025,  2061,  7968,  2000,  4558,  2019, 11292,\n",
      "              2000,  2663,  1037,  9097],\n",
      "            [ 2054,  2785,  1997,  2111,  2165,  2112,  1999, 18789,  2015,  7417,\n",
      "              1999,  4404,  1999, 16057],\n",
      "            [ 2054,  2024,  2310, 28550,  6895,  6894, 17557,  3775,  1062,  9956,\n",
      "              3490,  1998,  7270,  6916],\n",
      "            [ 2054,  2003,  1996,  4860,  2005, 21522, 18237,  2100,  1051,  4017,\n",
      "             14163, 15379,  2015,     0],\n",
      "            [ 2129,  2116,  2335,  1037,  2154,  2515,  1996,  5171,  2711,  2175,\n",
      "              2000,  1996,  5723,     0],\n",
      "            [ 2054,  2003,  1996,  6587,  2287,  1037,  2879,  2030,  2611,  2064,\n",
      "              2031,  2019, 13892,     0],\n",
      "            [ 2054,  2301,  1055,  1996,  4292,  2005,  2694,  1055,  1996,  7357,\n",
      "              1997,  5863,  7415,     0],\n",
      "            [ 2054,  2003,  1996,  6210,  1997,  1996,  8040,  2527, 11362,  2773,\n",
      "             25353,  9096,  6292,     0],\n",
      "            [ 2054,  2280,  3060,  3003,  2218,  2010,  2406,  1055,  8362,  2516,\n",
      "              2005,  3157,  2086,     0],\n",
      "            [ 2054,  2001,  1996,  3017,  2171,  1997,  1996,  2516,  2839,  1999,\n",
      "              2256,  3335,  8379,     0],\n",
      "            [ 2054,  2374,  2873,  1055,  2466,  2001,  2409,  1999,  1996,  3185,\n",
      "              2448,  2000, 11695,     0],\n",
      "            [ 2054,  2479,  2001,  1996,  4539,  1997,  1996,  1057,  1055,  1055,\n",
      "              3169, 13661,  8111,     0],\n",
      "            [ 2054,  2003,  1996,  2381,  1997,  2980,  7787,  3765,  1998,  2129,\n",
      "              2024,  2027,  2550,     0],\n",
      "            [ 2054,  2106,  1050,  1056,  6857, 22548,  3630,  2079,  1999,  2010,\n",
      "              4013,  8362,  2476,     0],\n",
      "            [ 2054,  2106,  1996,  2069, 21492,  7450,  2000,  1996,  1057,  1055,\n",
      "              4552,  3066,  2007,     0],\n",
      "            [ 2054,  2079,  1996,  2193,  1015,  1016,  1998,  1018,  2812,  2006,\n",
      "              2852, 11565, 11015,     0],\n",
      "            [ 2054,  1055,  1996,  2691,  2171,  2005,  9078,  3723,  4877, 27072,\n",
      "              8516,  2594,  5648,     0],\n",
      "            [ 1999,  2054,  2152,  3891,  2449,  6957,  2106,  5261,  1996,  3306,\n",
      "              6655,  1998,  4558,     0],\n",
      "            [ 2054,  4398,  4322,  3397,  1037, 14257,  3608,  3608, 13959,  1998,\n",
      "              2058, 12314,  7270,     0],\n",
      "            [ 2054,  2106,  2329,  3316,  6293, 12862,  1014,  6197,  1997,  5572,\n",
      "              2046,  1999,  3196,     0],\n",
      "            [ 1999, 16621,  1996, 12156,  2457,  2001,  3140,  2000,  2693,  2013,\n",
      "              4199,  2000,  2073,     0],\n",
      "            [ 2054,  3661,  2003,  2000,  1996,  2157,  1997,  1047,  2006,  1037,\n",
      "              2828, 15994,  9019,     0],\n",
      "            [ 2054,  2515,  1037,  5572, 13102,  7828,  1997,  3043, 17042,  1999,\n",
      "              1037,  2304,  4920,     0],\n",
      "            [ 2129,  2064,  1045,  2298,  2039,  2619,  1055,  1041,  5653,  4769,\n",
      "              2006,  1996,  4274,     0],\n",
      "            [ 2054,  2003,  1996,  6749,  3679,  9095,  2005,  1042, 23518,  5648,\n",
      "              2005,  6875,  2308,     0],\n",
      "            [ 2054,  2003,  3214,  2011,  1996,  2744, 10750,  2000, 16736,  1999,\n",
      "              4431,  2000,  9547,     0],\n",
      "            [ 2054,  2003,  1996,  2087,  4141,  2109,  1015,  3661,  2773,  1999,\n",
      "              1996,  2394,  2653,     0],\n",
      "            [ 2054,  2003,  1996, 20137,  2005,  1996,  5790,  2291,  2005,  2250,\n",
      "              4650,  2121,  8122,     0],\n",
      "            [ 2043, 10646,  3791,  2000,  2131,  2185,  2013,  2009,  2035,  2073,\n",
      "              2515,  2002,  2175,     0],\n",
      "            [ 2054,  2088,  2162,  1045,  2645,  2387,  1020,  1014,  3629,  2730,\n",
      "              1999,  2028,  2154,     0]], device='cuda:0'), tensor([14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "            13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['420'], ['3445'], ['5081'], ['700'], ['3350'], ['4260'], ['3845'], ['2562'], ['1707'], ['3851'], ['301'], ['4853'], ['4719'], ['367'], ['3351'], ['997'], ['4419'], ['1487'], ['1905'], ['4124'], ['4745'], ['1714'], ['3874'], ['2918'], ['2316'], ['5005'], ['2894'], ['1410'], ['3123'], ['2122'], ['4316'], ['1582']],\n",
      "    text: (tensor([[ 2507,  1037,  3114,  2005,  2137,  6505,  2411,  7292,  2015,  7510,\n",
      "              2041,  1997,  2082],\n",
      "            [ 2054,  3220,  1055,  4323,  2299,  2001,  2043,  1996,  4231,  3310,\n",
      "              2058,  1996,  3137],\n",
      "            [ 2054,  8366, 10423,  2001,  2124,  2004,  1996,  3748,  7087,  1997,\n",
      "              1996, 14089, 19707],\n",
      "            [ 2129,  2521,  2079,  2017,  2031,  2000,  2448,  2065,  2017,  2718,\n",
      "              1037,  2188,  2448],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996, 20516,  3116,  1997,  8573,\n",
      "             10888,  1998, 13125],\n",
      "            [ 2054,  2001,  1996,  4366,  2000,  4476,  1997, 10566,  1045,  3390,\n",
      "              2337,  1015,  3845],\n",
      "            [ 2043,  2025, 13896, 12228,  2006, 26312,  2054,  2515,  4205,  4326,\n",
      "              2655,  2010,  9518],\n",
      "            [ 2040,  2356,  1996,  3315,  3160,  2031,  2017,  2412,  2042,  2000,\n",
      "              3751,  3203,  2455],\n",
      "            [ 2054,  2442,  1037,  5869,  7136,  2304, 17364, 11033,  2079,  2043,\n",
      "              2002,  6561,  2385],\n",
      "            [ 2054,  2662,  3099,  2056, 27118,  7542,  2089,  2022,  1996,  3284,\n",
      "              2433,  1997,  2895],\n",
      "            [ 2054,  9121,  2194,  2003,  1996,  2088,  1055,  2053,  1015,  9338,\n",
      "              1997,  2931, 26278],\n",
      "            [ 2054,  3780,  2513,  1037, 17618,  3396,  2005,  1996, 27105,  2466,\n",
      "              5261,  1055,  2088],\n",
      "            [ 2054,  2001,  1996, 10576,  2008,  4930,  1996,  2103,  1997,  3899,\n",
      "              4665,  1999,  6166],\n",
      "            [ 2054,  3644,  6209,  2387,  1996,  2707,  1997,  1996,  3381,  3054,\n",
      "              5243,  3367,  2162],\n",
      "            [ 2054,  2024,  1996,  2069,  2867,  7792,  2000,  3556,  2685,  1999,\n",
      "             11220,  7350,  2170],\n",
      "            [ 2054,  2003,  2019,  2742,  1997,  2019,  5025,  2553,  1997,  2478,\n",
      "              1996, 15276,  7450],\n",
      "            [ 2171,  1996,  2775,  2187,  2006,  1037, 26581,  2012,  1996,  2927,\n",
      "              1997, 13753,  8975],\n",
      "            [ 2054,  2024,  2017,  4994,  2043,  2017,  2404,  1037, 11915, 18223,\n",
      "              2000,  2115,  4540],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  3899,  2006,  1996,  8579,\n",
      "              2121,  2990,  3482],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  6722,  8475,  1997,  1996, 19898,\n",
      "              1055,  2599,  3899],\n",
      "            [ 2054,  2240,  4055,  1996,  2167,  1998,  2148,  1999,  1996,  1057,\n",
      "              1055,  2942,  2162],\n",
      "            [ 2129,  2052,  1045,  2424,  1996,  3976,  1997,  2367, 11595,  2008,\n",
      "              2031,  2042,  6955],\n",
      "            [ 2054,  2079,  9180,  7158,  5261,  5954,  1998,  4922,  1047,  3044,\n",
      "              2031,  1999,  2691],\n",
      "            [ 2054,  2024,  1996,  3616,  2008,  4906,  2046, 10768, 10867, 12162,\n",
      "              1055,  2197,  9872],\n",
      "            [ 2054,  2001,  1996,  2171,  1997,  1996,  1057,  1055,  1055,  2034,\n",
      "             15371,  2686,  2565],\n",
      "            [ 2054,  8592,  2240,  2515, 10645,  4048,  2063,  3389, 29360,  4748,\n",
      "             16874,  5562,  2005],\n",
      "            [ 2054,  2079,  2751,  7529,  4558,  2065,  2921,  1999, 25361,  5507,\n",
      "              2030,  2770,  2300],\n",
      "            [ 2054,  2001,  1996,  5372,  4756,  1999, 24501, 29513,  2015,  2000,\n",
      "              2360, 22708,  5980],\n",
      "            [ 2054,  2318,  1999,  9037,  2043,  2751,  2001,  3603,  2012, 10514,\n",
      "             12079,  1055,  4971],\n",
      "            [ 2054,  2003,  1996,  2028,  2518,  2017,  2342,  2077,  2017,  2064,\n",
      "              5309,  2166,  5427],\n",
      "            [ 2054,  2038,  2000,  2022,  2550,  1999,  1037, 25697,  1997,  5292,\n",
      "              4783,  3022, 13931],\n",
      "            [ 2054,  2003,  1037,  2204,  2338,  2000,  3191,  2005,  2111,  2040,\n",
      "              5223,  2000,  3191]], device='cuda:0'), tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "            13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2186'], ['14'], ['3866'], ['1933'], ['127'], ['4319'], ['1769'], ['1266'], ['1762'], ['825'], ['5363'], ['2313'], ['3066'], ['3451'], ['3359'], ['1097'], ['5182'], ['4089'], ['3141'], ['3384'], ['1718'], ['3662'], ['445'], ['5444'], ['242'], ['219'], ['2939'], ['5373'], ['319'], ['5381'], ['1934'], ['3460']],\n",
      "    text: (tensor([[ 2054,  3696,  2003,  1996,  2190,  2293,  2674,  2005,  1037,  7570,\n",
      "              7352, 16186,  3696],\n",
      "            [ 2054,  2003,  2641,  1996,  3465, 21292,  7071,  1996,  5427,  3068,\n",
      "              2038,  2412,  4320],\n",
      "            [ 2054,  2210,  2417,  2482,  2003,  3855,  1999,  3769,  3220,  3159,\n",
      "              1055,  2718,  2299],\n",
      "            [ 2054,  2003,  1996, 13104,  2466,  4953,  5055, 17415,  1998,  5055,\n",
      "              1999,  4234,  3628],\n",
      "            [ 2054, 13675,  7828,  2121,  2587,  1996,  9261,  5208,  2005,  8779,\n",
      "              5308,  2378,  9588],\n",
      "            [ 2054,  5816,  1997,  6688,  2000,  4877, 29578,  5421,  2162,  1998,\n",
      "              3521,  2809,  2335],\n",
      "            [ 2054,  2003,  7150, 10654,  8591,  1055,  2535,  1999,  1996,  2047,\n",
      "              2732,  5233, 28280],\n",
      "            [ 2129,  2172,  5949,  2515,  2019,  2779, 11825, 11190,  3965,  1999,\n",
      "              1037,  2154,     0],\n",
      "            [ 2054,  5522,  2395, 27566,  2015,  2007, 15607,  2533,  5324,  1998,\n",
      "             15479,  2015,     0],\n",
      "            [ 2054,  2103,  3506,  1996,  1057,  1055,  4075,  1997,  4013, 21162,\n",
      "              1998, 18503,     0],\n",
      "            [ 2339,  2079, 27681,  2015,  6170,  2012,  2274,  1051,  5119,  1999,\n",
      "              1996,  2851,     0],\n",
      "            [ 2339,  2106,  2585, 12849, 21898,  3198,  1996,  8495,  2005,  1037,\n",
      "              2773, 13151,     0],\n",
      "            [ 2171,  1996,  2093,  3837, 22416,  2011,  1996, 17617,  2015,  1999,\n",
      "              8348,  5888,     0],\n",
      "            [ 2040,  2003,  6857,  1055,  1998,  7087, 10105, 19099,  1055,  2412,\n",
      "              2439,  2767,     0],\n",
      "            [ 2054,  1057,  1055,  5205,  2320,  2209,  3455,  2005,  1996,  2047,\n",
      "              2259, 27817,     0],\n",
      "            [ 2054,  1055,  1996,  2670,  9841,  2081,  1997, 14695,  2235, 20014,\n",
      "              4355, 10586,     0],\n",
      "            [ 2054,  2882,  9555,  5439,  2977,  2347,  1056,  2218,  2090,  3878,\n",
      "              1998,  3386,     0],\n",
      "            [ 2054,  1055,  1996,  2117,  2087,  2109,  4028,  5195,  1999,  1996,\n",
      "              1057,  1055,     0],\n",
      "            [ 2054,  8682,  2039,  2012,  2697, 10510,  2047,  3933,  2006,  2089,\n",
      "              1020,  3355,     0],\n",
      "            [ 2054,  1055,  1996,  9183,  2744,  2005,  1996, 13563, 13548,  1997,\n",
      "              1037,  9983,     0],\n",
      "            [ 2054, 13552,  3092,  2007,  1037,  3510,  1999,  5612,  2006,  2233,\n",
      "              2538,  6607,     0],\n",
      "            [ 2000,  2131,  1996,  2087, 24689,  7959,  3170,  2054, 14904,  2323,\n",
      "              1045,  4392,     0],\n",
      "            [ 2054,  2299,  2366,  2004,  1996,  5494,  4323,  1997,  1996,  5206,\n",
      "              5356,  2265,     0],\n",
      "            [ 2054,  2106,  2990,  3863,  2007,  1996, 14998,  2005,  1037,  9210,\n",
      "              1997, 13435,     0],\n",
      "            [ 2129,  2116,  2148,  2137,  3032,  2031,  1996,  3661,  1062,  1999,\n",
      "              2037,  3415,     0],\n",
      "            [ 2054,  3029,  1055,  4822,  2020,  3714,  2046,  2012,  2300,  5867,\n",
      "              1999,  3285,     0],\n",
      "            [ 2054,  2003,  1996,  4435,  2171,  1997,  1996,  5072,  5477,  5740,\n",
      "              5831,  3207,     0],\n",
      "            [ 2054,  2616,  1999,  1996,  2394,  2031,  2048,  1057,  1055,  2067,\n",
      "              2000,  2067,     0],\n",
      "            [ 2054,  2194, 21628, 18969,  1996, 17069,  1999,  6830,  2005,  1996,\n",
      "              2914,  2982,     0],\n",
      "            [ 2054,  4475,  2106,  1996,  2093,  2210, 14695,  2224,  2000,  3857,\n",
      "              2037,  3506,     0],\n",
      "            [ 2054,  2024,  1996,  2088,  1055,  2093,  2922, 17401,  1999,  2344,\n",
      "              1997,  2946,     0],\n",
      "            [ 2054,  2106,  3235,  9678,  2695,  2006,  1996,  2277,  2341,  2012,\n",
      "             15966, 21806,     0]], device='cuda:0'), tensor([13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "            12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4428'], ['1983'], ['2138'], ['465'], ['797'], ['5257'], ['1029'], ['1041'], ['2080'], ['1854'], ['480'], ['3083'], ['1415'], ['3829'], ['77'], ['3931'], ['1468'], ['128'], ['2085'], ['2967'], ['2747'], ['1282'], ['1629'], ['133'], ['1374'], ['4206'], ['4567'], ['1683'], ['1476'], ['1594'], ['2207'], ['3818']],\n",
      "    text: (tensor([[ 2054,  4773,  4573,  2024,  5799,  2000,  1996,  3189,  2006, 11046,\n",
      "              6422, 16302],\n",
      "            [ 2054,  2106,  2198,  1042,  5817,  5136,  2010,  4602, 14154, 11563,\n",
      "              1999,  2436],\n",
      "            [ 2054,  2744,  2965,  1037,  4424,  8432,  2090,  1037,  3287,  1998,\n",
      "              1037,  2931],\n",
      "            [ 1999,  2054,  2181,  1997,  1996,  2088,  2001,  1996,  2416,  2154,\n",
      "              2162,  4061],\n",
      "            [ 1996,  3059,  3063,  5003,  9496, 12426, 21877,  6216, 24860,  2003,\n",
      "              2129,  2214],\n",
      "            [ 2054,  2515,  1037,  2158,  6114,  2013, 16510,  9892,  2594, 28774,\n",
      "              6790,  2031],\n",
      "            [ 2054,  2024,  1996,  3415,  1997,  2035,  1996,  1057,  1055,  3212,\n",
      "              2948, 11363],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  2744,  1996,  6613,  2217,\n",
      "              1999,  9116],\n",
      "            [ 2054,  2024,  1996,  3284,  7079, 10238,  2006,  1037, 20996,  9307,\n",
      "              4674,  2795],\n",
      "            [ 2054,  2020,  1996,  2093, 17678,  5369,  9243,  1996, 12566,  2191,\n",
      "              2000, 25182],\n",
      "            [ 2054,  2079, 10506, 26736,  2015,  2079,  1999, 13675,  2319,  9766,\n",
      "             22132,  2015],\n",
      "            [ 2054,  2020,  8670, 15379, 10424, 16429,  4509,  2121,  1998,  5951,\n",
      "              2559,  2005],\n",
      "            [ 2054,  2064,  2017,  2022, 16981,  2005,  2383,  1037,  3899,  2006,\n",
      "              1037,  3509],\n",
      "            [ 2054,  2024,  1996,  3415,  1997,  7445,  2522, 19966, 10207,  1055,\n",
      "              2048,  4124],\n",
      "            [ 1996, 13931,  2655,  2891,  2819,  2003,  1999,  2054,  2112,  1997,\n",
      "              1996,  2303],\n",
      "            [ 2054,  8511, 10423,  2001,  2915,  2757,  2648,  1037,  7756, 27308,\n",
      "              1999,  2089],\n",
      "            [ 2029,  2557,  3703,  2250,  1996,  3958,  8945,  4819,  8540,  2557,\n",
      "              2831,  2265],\n",
      "            [ 2054,  3682,  2194,  4447,  2049,  4031,  2003,  1996,  6602,  1997,\n",
      "              1996, 26796],\n",
      "            [ 2054,  2515,  1996,  1039,  3233,  2005,  1999,  1996,  8522,  1041,\n",
      "             11338,  2475],\n",
      "            [ 2129,  2116,  2053,  6998,  2001,  1996,  2054,  1055,  2026,  2240,\n",
      "              5997,  3039],\n",
      "            [ 2054,  2148,  3060,  3135,  2018,  1037,  2997,  5618,  1997,  6640,\n",
      "              2575,  2454],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  2026,  2126,  2517,  2011,  2703,\n",
      "              2019,  2912],\n",
      "            [ 2171,  1996,  2176,  3441,  4838,  1999, 13257, 24249,  1055,  2214,\n",
      "              2047,  2259],\n",
      "            [ 2054,  5365,  3899,  2351,  1999,  1996,  2608,  1997,  3744, 22545,\n",
      "              1999,  4673],\n",
      "            [ 2054,  2106,  2720, 23848,  9541, 13109,  8649,  2006,  2694,  2005,\n",
      "              2236,  3751],\n",
      "            [ 2054,  2161,  2515,  1037,  7632, 14545,  2140,  4023,  5373,  2202,\n",
      "              2173,  1999],\n",
      "            [ 2054,  2001,  1996,  2171,  1997, 15462, 22132,  8445,  1055,  2252,\n",
      "              1999, 24592],\n",
      "            [ 2054,  3047,  1999,  3899,  4665,  1999,  6166,  2000,  2191,  2008,\n",
      "              2095,  4622],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  3813,  2008,  3084, 11867,\n",
      "             19042,  2618],\n",
      "            [ 2054,  2079,  1045,  2655,  1996,  4124,  1998,  5727,  1997,  2026,\n",
      "              2034, 12334],\n",
      "            [ 2073,  2515,  1996,  6881,  4338,  1997,  1996,  4596,  3869,  5442,\n",
      "             21754,  2013],\n",
      "            [ 2054,  6804,  3084,  1037, 21688,  9004,  2130,  2056,  2000,  6807,\n",
      "              2049,  3040]], device='cuda:0'), tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "            12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [5],\n",
      "            [4],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1058'], ['3283'], ['5'], ['3492'], ['2379'], ['769'], ['3554'], ['3076'], ['3140'], ['1349'], ['3038'], ['4442'], ['1940'], ['3757'], ['3299'], ['3809'], ['5298'], ['3917'], ['2609'], ['2273'], ['4456'], ['2608'], ['5245'], ['2292'], ['1984'], ['1786'], ['1961'], ['2143'], ['4894'], ['2067'], ['589'], ['1424']],\n",
      "    text: (tensor([[ 1999,  2029,  4901,  3465,  3678,  3185,  2106, 16615,  6505,  2377,\n",
      "              1037,  2535],\n",
      "            [ 2054,  2024,  2017,  3236,  1999,  2065,  1037,  5292,  5092, 16429,\n",
      "             13783,  2039],\n",
      "            [ 2054, 17152,  7028,  8040, 28819, 16570, 10312,  1996,  8513,  2013,\n",
      "              2026,  6265],\n",
      "            [ 2054,  2003,  1996,  4602,  3120,  1997,  2317,  3894,  1999,  1996,\n",
      "              8348,  5304],\n",
      "            [ 2054,  2003,  1996, 12066,  2744,  2109,  2005,  1996,  2120,  4879,\n",
      "              1997,  4812],\n",
      "            [ 2029,  2606,  2729,  4031,  2409,  2149,  5223,  2008,  3897,  9378,\n",
      "              2009,  2185],\n",
      "            [ 2054,  2048,  6470,  4061,  1996,  2034,  2712,  2645,  2090,  3707,\n",
      "              3139,  3719],\n",
      "            [ 2054,  2003,  1996, 13296,  3252,  1997,  1996,  2047,  6768, 28232,\n",
      "             12338,  3199],\n",
      "            [ 2171,  1037,  3185,  2008,  1996,  3883, 12834, 25200,  2018,  1037,\n",
      "              2535,  1999],\n",
      "            [ 2054,  2079,  1996,  4144,  1040,  1039,  3233,  2005,  1999,  2899,\n",
      "              1040,  1039],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  8235,  2329, 11708,  2369,\n",
      "              2049,  4325],\n",
      "            [ 2040,  6791,  2492,  8610, 22209, 17083, 10199,  1999,  1996,  5532,\n",
      "              4419,     0],\n",
      "            [ 2054,  2001,  1996,  2171,  1997, 17484,  2006, 12054,  2483,  1055,\n",
      "             12187,     0],\n",
      "            [ 2054,  1055,  1996,  2087, 10059, 18767,  2266,  1997,  1996, 20949,\n",
      "              2155,     0],\n",
      "            [ 2006,  2054,  3927,  2003,  1996,  2434,  7842,  5705,  2533,  3573,\n",
      "              2284,     0],\n",
      "            [ 2054,  4708,  2515,  1996,  8945,  2226, 14356,  8843,  1997,  3899,\n",
      "              4685,     0],\n",
      "            [ 2129,  2146,  2323,  2017,  5438,  2115, 17022, 16405, 11796, 17022,\n",
      "             20209,     0],\n",
      "            [ 2054,  2020,  1996,  3415,  1997,  1996,  2093,  3719,  2109,  2011,\n",
      "              8912,     0],\n",
      "            [ 2054,  2003,  1996, 10014,  2369,  1996, 11173,  1999,  1996,  3239,\n",
      "              2170,     0],\n",
      "            [ 2054,  3609, 10029,  7541,  2000,  1996,  3095,  2006,  5706,  1055,\n",
      "              5210,     0],\n",
      "            [ 2054,  2350,  8582,  2038,  1996,  2190,  3808,  2501,  1999,  1996,\n",
      "              2088,     0],\n",
      "            [ 2054,  3573,  4447,  2000,  2022,  1996,  2088,  1055,  2922,  2533,\n",
      "              3573,     0],\n",
      "            [ 1999,  2054,  2406,  2003,  1037,  5881,  2041,  4416,  1037,  5379,\n",
      "             14806,     0],\n",
      "            [ 2054,  8316,  2001,  8826,  2011,  1039,  1039, 17454,  2063,  1999,\n",
      "              4437,     0],\n",
      "            [ 2054,  1055,  1996, 22498,  2005, 13012,  3490, 13181,  3406,  7630,\n",
      "              8625,     0],\n",
      "            [ 2054,  2299,  2106, 22732,  3931,  2275,  2111,  5613,  2000,  1999,\n",
      "              3925,     0],\n",
      "            [ 2054,  2024,  1996,  5640, 16371, 28990,  2015,  2013,  1015,  2000,\n",
      "              2184,     0],\n",
      "            [ 2054,  4153,  2001, 11556,  4540, 10686,  3909,  2058,  2043,  2016,\n",
      "              5419,     0],\n",
      "            [ 2054,  2024,  1996,  2034,  1998,  2197,  4144,  1997,  1996,  3306,\n",
      "             12440,     0],\n",
      "            [ 2054,  2003,  1996, 12066,  2433,  1997,  1996,  2120,  4879,  1997,\n",
      "              4812,     0],\n",
      "            [ 2043,  3752,  6219, 14997,  2054,  2515, 25212, 29405,  2060,  3233,\n",
      "              2005,     0],\n",
      "            [ 1996,  8956,  2015,  3390,  2037,  2886,  2006, 13085,  2006,  2054,\n",
      "              2154,     0]], device='cuda:0'), tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [5],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [5],\n",
      "            [5],\n",
      "            [4]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1737'], ['3330'], ['761'], ['4474'], ['4491'], ['328'], ['688'], ['4113'], ['4188'], ['4639'], ['2255'], ['3721'], ['5164'], ['1168'], ['977'], ['832'], ['5255'], ['4231'], ['1248'], ['2640'], ['3921'], ['4929'], ['1955'], ['3775'], ['652'], ['3278'], ['2968'], ['968'], ['3709'], ['3081'], ['4414'], ['830']],\n",
      "    text: (tensor([[ 1999,  2054,  2110,  2001,  2045,  2019,  2340,  2454, 25234,  3514,\n",
      "             14437],\n",
      "            [ 2054,  2024,  1996,  2327,  2702,  2035,  2051,  2769,  2437,  5088,\n",
      "              2780],\n",
      "            [ 2339,  2001,  1996,  1048,  1037,  2436,  1997, 16994,  1998, 14913,\n",
      "              2701],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  1996,  6084,  2090,  4701,  1998,\n",
      "              6435],\n",
      "            [ 2054,  2020,  8817,  1997,  4268,  4147,  2006,  2037,  4641,  1999,\n",
      "              3982],\n",
      "            [ 2029, 13426,  2221,  6319, 23277, 25508,  2015, 22156,  2007,  1037,\n",
      "              3274],\n",
      "            [ 1999,  2054,  4386,  2399,  2106, 14942, 16571,  2638,  6895,  2468,\n",
      "              2759],\n",
      "            [ 2054,  2001,  1996, 14429,  8658,  1997,  2762,  1055,  1057,  1016,\n",
      "              6982],\n",
      "            [ 2054,  7433,  9560,  3463,  2043,  1037,  2447,  2038,  2053,  3423,\n",
      "              2693],\n",
      "            [ 2129,  2106,  3565,  2343,  5114,  2010,  4204,  2006,  1996,  6579,\n",
      "              2186],\n",
      "            [ 2054,  2003,  1996, 11749,  1997,  1037,  2899, 12281,  4939,  1055,\n",
      "              5470],\n",
      "            [ 2054,  2001,  1996,  8320,  2075,  5390,  1997,  1996,  2220,  2137,\n",
      "             24517],\n",
      "            [ 2054,  1055,  1996,  4489,  2090,  1056,  6199,  1998,  7037, 13594,\n",
      "              4653],\n",
      "            [ 2054,  3042,  2193,  2064,  1045,  2655,  2000,  2031,  1037,  3392,\n",
      "              8461],\n",
      "            [ 2054,  2515,  2643,  3443,  1999,  1996,  2034,  6251,  1997,  1996,\n",
      "              6331],\n",
      "            [ 2054,  2024,  2070, 10247,  2005,  2311,  1037,  2543,  1999,  1037,\n",
      "             13788],\n",
      "            [ 2054,  2020,  1996,  2197,  3415,  1997, 20067,  2015, 12220,  1998,\n",
      "             12085],\n",
      "            [ 2054,  2450,  8070,  2038,  4930,  2041,  6945,  3766,  1998,  9180,\n",
      "              7158],\n",
      "            [ 2054,  2406,  1998,  2530,  3220,  2003,  2124,  2004,  1996,  3165,\n",
      "              4419],\n",
      "            [ 2054,  2024,  1996,  9530,  9103, 12540,  2015,  1997,  5256,  1998,\n",
      "              8271],\n",
      "            [ 2054,  2003, 10173,  2000,  2327, 10814,  2058,  2090,  2230,  1998,\n",
      "             12609],\n",
      "            [ 2054,  2064,  1045,  2079,  2000,  2131,  2046,  2019,  7768,  2223,\n",
      "              2082],\n",
      "            [ 2129,  2064,  1045,  4089,  6366,  2417,  4511, 27094,  2013,  1056,\n",
      "             11344],\n",
      "            [ 2129,  2515,  2833,  3609,  7461,  2129,  2017,  2228,  2009,  2097,\n",
      "              5510],\n",
      "            [ 2054,  2003,  1996,  5583,  1997,  2659,  3778,  2105,  1996, 26640,\n",
      "              2170],\n",
      "            [ 2171,  1996,  2413,  3439,  2558,  2076,  1996,  5853,  1997,  8891,\n",
      "              3523],\n",
      "            [ 2054,  2003,  1996,  2986,  2005,  2383,  1037,  3899,  2006,  1037,\n",
      "              3509],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1037,  5439,  2607,  1999, 21381,\n",
      "              3509],\n",
      "            [ 2129,  2515,  9388,  2140,  2433,  1998,  2054,  9754,  2515,  2009,\n",
      "              5383],\n",
      "            [ 2040,  1055,  3336,  2001,  4086, 26034,  2006,  1996,  4831,  6672,\n",
      "              9476],\n",
      "            [ 2054,  1055,  1996,  2248,  2557,  3642,  2773,  2005,  1996,  3661,\n",
      "              1042],\n",
      "            [ 2054,  2047,  2690,  2082,  2001,  2328,  1999,  4407,  3552,  2197,\n",
      "              2095]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5287'], ['3705'], ['2754'], ['969'], ['3816'], ['4200'], ['3407'], ['3192'], ['2287'], ['103'], ['2783'], ['3099'], ['5108'], ['3905'], ['2394'], ['4651'], ['5123'], ['4627'], ['2350'], ['1564'], ['1140'], ['3794'], ['4730'], ['4299'], ['1236'], ['2161'], ['3387'], ['3122'], ['4844'], ['1724'], ['424'], ['3630']],\n",
      "    text: (tensor([[ 2054,  2079,  1037,  6323,  1998, 15116,  1997,  5317,  2031,  1999,\n",
      "              2691],\n",
      "            [ 2054,  3754,  2038,  1996,  6953, 22769,  5820,  2439,  2083,  4968,\n",
      "              3370],\n",
      "            [ 2054,  1055,  1996,  2197,  2240,  1997, 19675,  1055,  1037,  4234,\n",
      "              8594],\n",
      "            [ 2054,  2024,  2070,  1997,  1996,  3278,  3439,  2824,  1997,  1996,\n",
      "              4134],\n",
      "            [ 2054,  2003, 12101, 11113,  9759,  2290,  1055, 18906, 29469,  2389,\n",
      "             11749],\n",
      "            [ 2054,  2001,  1996,  1058,  1022, 10869, 14558,  1996,  5510,  8569,\n",
      "              2094],\n",
      "            [ 2054,  2097,  1996,  2662,  3806,  4171,  2022,  1999,  1996,  2095,\n",
      "              2456],\n",
      "            [ 2054,  2001,  3157, 22701,  2015,  1996,  2547,  2265,  2013,  3326,\n",
      "              2055],\n",
      "            [16994,  1998, 14913,  2701,  2037,  3050,  3349,  2436,  2005,  2054,\n",
      "              3114],\n",
      "            [ 2054,  2785,  1997,  4176,  2020,  1999,  1996,  5122, 18153, 19419,\n",
      "              3690],\n",
      "            [ 2054,  2177,  2356,  1996,  3315,  3160,  2079,  2017,  2903,  1999,\n",
      "              3894],\n",
      "            [ 2054,  1057,  1055,  2110,  2038, 10878, 18623,  2004,  2049,  2110,\n",
      "              6546],\n",
      "            [ 2054,  2123, 17602,  2299, 20342,  7666,  1996,  2154,  8937,  9079,\n",
      "              2351],\n",
      "            [ 2054,  2079,  4500,  5344,  1997,  1037,  3280,  2467,  5587,  2039,\n",
      "              2000],\n",
      "            [ 2054,  2001,  1996, 14392,  1999,  1996,  3979,  1997, 15860,  8945,\n",
      "             18246],\n",
      "            [ 2171,  1997,  1996,  3203,  1996,  2307, 11721,  3215,  3762, 17527,\n",
      "              2005],\n",
      "            [ 2029,  5396,  2003, 10654,  3468,  2078,  1996,  2034,  4823, 11762,\n",
      "              1999],\n",
      "            [ 2054,  2450,  2001,  2051,  1055,  2158,  1997,  1996,  2095,  2005,\n",
      "              3999],\n",
      "            [ 2054,  3867,  1997,  2088,  1055,  4840,  2300,  2003,  2179,  1999,\n",
      "              2710],\n",
      "            [ 2054,  2003,  1996,  3382,  1997,  9530,  3401, 14966, 17718, 21531,\n",
      "             13461],\n",
      "            [ 2054,  2001, 21127,  1055,  6226,  5790,  2044,  2184,  2086,  1999,\n",
      "              2373],\n",
      "            [ 2054,  2003,  1996,  3091,  1997,  3675,  2090,  1996,  5924,  1998,\n",
      "              3607],\n",
      "            [ 2129,  2079,  1045,  2113,  2129,  2172,  2769,  2000,  3828,  2005,\n",
      "              5075],\n",
      "            [ 2054,  2024,  2111,  2725,  2000,  2393,  4652,  1996, 14446,  1997,\n",
      "              5055],\n",
      "            [ 2054,  2024,  1996,  2350,  5966,  1999,  1996,  3234,  1998,  8938,\n",
      "             11822],\n",
      "            [ 1999,  1996,  4679,  5507,  2063,  2694,  3293,  2040,  2003,  1996,\n",
      "              6492],\n",
      "            [ 2054,  2003,  1996,  2364,  4646,  1997, 13365, 18479, 23722,  8873,\n",
      "              2618],\n",
      "            [ 1996,  7012,  4525,  2013,  2088,  2162,  2462,  2024,  2124,  2004,\n",
      "              2054],\n",
      "            [ 2054,  2171,  2106,  2374,  1055,  2047,  2259, 13785, 11092,  1999,\n",
      "              3699],\n",
      "            [ 2054,  2931,  5276,  2550, 10968,  2015,  1997,  3541,  2047,  2563,\n",
      "              2166],\n",
      "            [ 2054,  2024,  2070,  5875,  8866,  1998,  2592,  2055,  6077,  3709,\n",
      "              4667],\n",
      "            [ 2981,  3165, 21405,  1055,  4070,  2005,  2054,  7017,  1997,  3165,\n",
      "              2537]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "            11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2588'], ['2728'], ['5337'], ['2892'], ['1894'], ['4202'], ['870'], ['3211'], ['3075'], ['613'], ['639'], ['1550'], ['4615'], ['1612'], ['3235'], ['542'], ['5008'], ['3919'], ['2781'], ['1005'], ['3009'], ['1139'], ['3271'], ['4105'], ['3899'], ['2099'], ['2280'], ['1642'], ['5435'], ['3328'], ['4421'], ['5269']],\n",
      "    text: (tensor([[ 2054,  5021,  6167,  2823,  2838,  1037,  5653,  2386,  2315, 26892,\n",
      "              8002],\n",
      "            [ 2054,  2003,  1996,  2299, 21952,  2000,  6014,  2011,  2419, 22116,\n",
      "              2055],\n",
      "            [ 2054,  1055,  1996,  2690,  2171,  1997,  3185,  3135,  3312,  1041,\n",
      "             17780],\n",
      "            [ 2054,  2024,  1996,  2087,  4042,  2853,  2011,  2028,  3063,  2030,\n",
      "              2316],\n",
      "            [ 2054,  2161,  4269,  2007,  1996,  2310, 12789,  2140,  1041, 12519,\n",
      "             11636],\n",
      "            [ 2054,  3661,  2515,  2175, 28483, 16179,  1055,  2690,  2171,  2707,\n",
      "              2007],\n",
      "            [ 2029,  6359, 13156,  2351,  2012,  2712,  2088,  1997,  1037, 28079,\n",
      "              8985],\n",
      "            [ 2054,  2020,  1996,  5103,  7443,  2066,  2076,  1996,  3870,  2937,\n",
      "              2335],\n",
      "            [ 2054,  2024,  1996,  3901,  1997,  1996,  2479,  1997,  4649, 15853,\n",
      "              2170],\n",
      "            [ 2054,  3696,  2003,  1996,  2300,  6839,  1996, 28501,  2389,  6454,\n",
      "              2005],\n",
      "            [ 2054,  2154,  1997,  1996,  2733,  5927,  1996,  2087, 10611,  2482,\n",
      "             13436],\n",
      "            [ 2054,  2024,  1996,  5751,  1997,  1037,  2406,  2183,  2046,  1037,\n",
      "             19396],\n",
      "            [ 2171,  1996,  2273,  1055, 10918,  2008,  2003,  3378,  2007,  1996,\n",
      "              2712],\n",
      "            [ 2054,  2785,  1997,  1037,  2998,  2136,  2003,  1996,  5273, 24186,\n",
      "              2015],\n",
      "            [ 2054,  2311,  2328,  1999,  2324,  3397, 28469,  2661,  1997,  2338,\n",
      "             15475],\n",
      "            [ 2054,  2024,  1996,  5664,  3558,  3494, 14606,  1997,  1996, 13771,\n",
      "              3586],\n",
      "            [ 2043,  2001,  1996,  2034,  3144,  2540, 22291,  2005,  1037,  2529,\n",
      "                 0],\n",
      "            [ 2073,  2064,  1045,  2424,  1996,  3570,  1997,  2026,  4171,  2709,\n",
      "                 0],\n",
      "            [ 3005, 22590,  2075,  2001, 12061,  1996,  4126,  1997,  1996,  2301,\n",
      "                 0],\n",
      "            [ 2054,  3297,  4823, 11762,  8617,  1996,  2662,  7048,  3598,  2136,\n",
      "                 0],\n",
      "            [ 2040,  2580,  1996,  6071,  1999,  2984, 15828,  1055,  3117, 22478,\n",
      "                 0],\n",
      "            [ 2054,  2406,  2001,  1996,  4292,  1997,  2017,  2069,  2444,  3807,\n",
      "                 0],\n",
      "            [ 2054,  2003,  1996,  8917,  2378,  1997,  1060, 11636, 11636, 11636,\n",
      "                 0],\n",
      "            [ 2073,  2064,  1045,  2424,  2489,  3682,  7644,  2005,  2759,  2189,\n",
      "                 0],\n",
      "            [ 2054,  5983, 21183,  6132, 12146,  2024,  2109,  2005, 26920,  4268,\n",
      "                 0],\n",
      "            [ 2054,  1055,  1996,  2248, 10168,  5093,  4119,  5384,  2788,  2170,\n",
      "                 0],\n",
      "            [ 2054,  2003,  1037, 19130,  2606,  8248,  2941,  2081,  2041,  1997,\n",
      "                 0],\n",
      "            [ 2054,  1055,  1996,  4489,  2090,  1046,  1040,  1998,  2222,  1049,\n",
      "                 0],\n",
      "            [ 2054,  2111,  2191,  2039,  2431,  1996,  3354,  2586,  1055,  2313,\n",
      "                 0],\n",
      "            [ 2054,  2024,  1996,  5918,  2005,  3352,  1037,  6926,  1997,  2660,\n",
      "                 0],\n",
      "            [ 1999,  7813,  8925,  2064,  2017,  2171, 18906,  3351,  1055,  3899,\n",
      "                 0],\n",
      "            [ 2054,  2081,  1996,  2460,  2973,  2732, 12505,  6167,  2061,  4310,\n",
      "                 0]], device='cuda:0'), tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10,\n",
      "            10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1413'], ['1976'], ['3573'], ['268'], ['3337'], ['1566'], ['2295'], ['2715'], ['1100'], ['2466'], ['4845'], ['3385'], ['3539'], ['611'], ['616'], ['4353'], ['1840'], ['3040'], ['1493'], ['2645'], ['1557'], ['2285'], ['4836'], ['2195'], ['2633'], ['3913'], ['4662'], ['5176'], ['4415'], ['4841'], ['3543'], ['5099']],\n",
      "    text: (tensor([[ 2054,  3699,  3312,  1048,  2158, 28563,  2143,  3465,  2654,  2454],\n",
      "            [ 2054,  2003,  6334,  2076,  1996,  2733,  1997,  2337,  2538,  2676],\n",
      "            [ 2029,  1057,  1055,  2343,  2003,  3950,  1999,  2899,  1040,  1039],\n",
      "            [ 2000,  2054,  2515,  7513,  1055,  3645,  1017, 12533,  2049,  3112],\n",
      "            [ 2029, 13297,  2106,  6904,  4213,  2480,  2017,  8977,  7632, 17364],\n",
      "            [ 2054,  3032,  2031,  1996,  2922,  4273,  2749,  1999,  1996,  2088],\n",
      "            [ 2054, 27701,  6743,  2003,  1999,  3002,  2848,  1055,  5040, 13546],\n",
      "            [ 2054,  2001,  2632,  6178,  5643,  2633,  8580,  2005,  1999,  4739],\n",
      "            [ 2054,  2003,  1996,  4654,  8586, 16161,  2099,  1999,  1037,  2097],\n",
      "            [ 2054,  4153, 11197,  5296,  1998,  7569,  1999,  4291,  4290,  6496],\n",
      "            [ 2054,  2931,  8343,  1999,  1996,  2208,  1997,  9789,  2003,  2309],\n",
      "            [ 2054,  3827,  2003,  2179,  1999,  9808, 11493,  2075,  2047,  2259],\n",
      "            [ 1999,  4748, 25897,  2054,  4066,  1997, 12035, 10069,  2020,  2045],\n",
      "            [ 2040,  2351,  1015,  2519,  2013,  2073,  2198,  1042,  5817,  2106],\n",
      "            [ 2043,  2003,  1996,  2609,  7479,  3980,  4012,  2183,  2000,  2330],\n",
      "            [ 2054,  2003,  2921,  1999,  3481, 11994,  2008,  2003,  2061,  7070],\n",
      "            [ 2054, 15607,  2414,  4735,  2457,  2001,  2320,  1037, 16708,  3317],\n",
      "            [ 2054,  2003,  2009,  2066,  2000,  3325,  1037,  2379,  2331,  2792],\n",
      "            [ 2054,  2003,  4097,  8226,  4917,  1055,  7203,  2158,  7203,  2007],\n",
      "            [ 2054,  2024,  2198,  1039, 22982,  1998,  2888,  5726,  2124,  2004],\n",
      "            [ 2054,  2003,  1996,  2394,  5449,  2005,  1996,  2773, 10250, 25099],\n",
      "            [ 2054,  2079,  1045,  2342,  2000,  4553,  2000,  2640,  4773,  5530],\n",
      "            [ 2054,  2003,  1996,  6149,  2126,  2000,  2224,  2089,  5443,  2453],\n",
      "            [ 2054,  4435,  1997,  2317, 19379,  2003,  2145,  2081,  1999,  7394],\n",
      "            [ 2054,  2154,  2003,  2124,  2004,  1996,  2120,  2154,  1997,  7083],\n",
      "            [ 2054,  2106,  1996,  3418,  2015,  2655,  1996,  2176,  2307,  3787],\n",
      "            [ 2129,  2106,  1996,  2706,  1997,  1996,  2095,  2131,  2045,  2171],\n",
      "            [ 2073,  2106,  1996,  2943,  2005,  1996,  2502,  9748,  2272,  2013],\n",
      "            [ 2054,  2024,  1996,  2654,  9049,  2015,  1999,  1996,  2394,  2653],\n",
      "            [ 2054,  2003,  5003,  9496, 12426, 21877,  6216, 24860,  1055,  2287],\n",
      "            [ 2073,  2003,  1996,  7778, 10061,  1997,  1996,  2142,  2163,  3784],\n",
      "            [ 2054,  2003,  1037, 11375,  1997, 19021, 28173, 16940,  3401,  4570]],\n",
      "           device='cuda:0'), tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "            10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3],\n",
      "            [2]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2011'], ['3418'], ['4021'], ['2125'], ['1727'], ['3091'], ['4586'], ['4610'], ['9'], ['1968'], ['512'], ['3005'], ['3118'], ['1356'], ['1286'], ['3658'], ['3045'], ['3111'], ['2216'], ['2332'], ['1709'], ['3232'], ['1394'], ['1759'], ['1554'], ['614'], ['1416'], ['1543'], ['5297'], ['820'], ['3051'], ['4339']],\n",
      "    text: (tensor([[ 2054,  2024,  7861, 28522, 15975,  2094,  2006,  1996, 22193,  5074],\n",
      "            [ 2054,  2003,  1996,  4489,  2090,  1037,  2267,  1998,  1037,  2118],\n",
      "            [ 2054,  2282,  2106,  1059,  1039,  4249,  2562,  2010,  3075,  1999],\n",
      "            [ 2054,  2592,  2064,  2017,  2425,  2033,  2055,  3364,  2508, 16759],\n",
      "            [ 2054,  2323,  2017, 14315,  2000, 16889,  1037, 10095,  1999,  6921],\n",
      "            [ 2054, 20121,  2003,  4202, 16589,  1055,  2307,  7006,  1997,  2643],\n",
      "            [ 2054,  2024,  2047,  3274,  2399,  2005,  3645,  5345,  2030,  5818],\n",
      "            [ 2054,  1055,  8200,  2055,  1037,  5340, 15457,  2094,  1055,  2519],\n",
      "            [ 2171,  1996, 11228,  4320, 17284,  4477,  1997,  1996,  2214,  2225],\n",
      "            [ 2054,  2001,  1996,  9560,  1997,  1996,  3386,  8038, 24458,  3034],\n",
      "            [ 2054,  2001,  1996,  2958,  1997,  2624,  6446, 12569,  2081,  1997],\n",
      "            [ 2054,  2081,  1996,  4344,  6597,  1999,  2530,  2047,  2259,  2110],\n",
      "            [ 2054,  2024,  2070,  5072,  5144,  1997,  2273,  9247,  6777,  5007],\n",
      "            [ 2054,  2515,  2019, 11209,  2618,  2482,  3954,  2655,  3707, 15772],\n",
      "            [ 2054,  1055,  1996,  2053,  1015,  6359,  1999,  3919,  3550,  3032],\n",
      "            [ 2054, 11938,  2030, 27885,  8043, 26711,  2024,  6334,  1999,  3304],\n",
      "            [ 2054,  4883,  3447,  8315,  4841,  2000,  8849,  1996,  2047,  8880],\n",
      "            [ 2054,  2003,  1996, 18937,  2005,  2111,  2040,  2113,  1996,  4489],\n",
      "            [ 2073,  2515,  1996,  1057,  1055,  2131,  2087,  1997,  2049,  2943],\n",
      "            [ 2129,  2980,  2515,  1996,  2503,  1997,  2019,  3161, 12779,  2131],\n",
      "            [ 2054,  2828,  1997,  9256,  2003, 17869,  5162, 26046,  6820, 22083],\n",
      "            [ 2073,  2064,  2017,  2424,  1996, 11691,  4875,  6494,  2361,     0],\n",
      "            [ 2054,  2515,  2169,  1997,  1996, 16548,  3465,  1999, 15404,     0],\n",
      "            [ 1037,  2522, 10623,  2072,  2003,  1037,  2785,  1997,  2054,     0],\n",
      "            [ 2054,  2524,  1997,  4994,  3063,  4993,  3103, 14156,  2015,     0],\n",
      "            [ 2054,  4176,  2079,  2017,  2424,  1999,  1996,  4518,  3006,     0],\n",
      "            [ 2073,  2106,  1996,  2645,  1997,  1996, 23708,  2202,  2173,     0],\n",
      "            [ 2054,  2097,  4148,  2043, 13365,  2003,  2404,  1999,  2300,     0],\n",
      "            [ 2129,  2116,  2020,  1999,  5270,  2012,  1996,  2197, 15264,     0],\n",
      "            [ 2129,  2116,  2706,  2515,  1037,  3671,  2529, 10032,  2197,     0],\n",
      "            [ 2129,  2079,  2017,  5466,  1037,  2160,  9028,  6562,  2283,     0],\n",
      "            [ 2054,  2479,  2003,  2188,  2000, 11342,  2170, 28566,  2015,     0]],\n",
      "           device='cuda:0'), tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "            10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4920'], ['1972'], ['4077'], ['2730'], ['1576'], ['1608'], ['1330'], ['3716'], ['5294'], ['1548'], ['2660'], ['3311'], ['27'], ['3393'], ['4071'], ['4695'], ['2139'], ['5070'], ['2916'], ['624'], ['5046'], ['1448'], ['1375'], ['4208'], ['1877'], ['5408'], ['439'], ['487'], ['4447'], ['278'], ['3352'], ['1084']],\n",
      "    text: (tensor([[ 2054,  5907,  2003,  2025,  3039,  2000,  3789,  1999, 13085],\n",
      "            [ 2054,  5320,  2064,  5484, 14699,  2015,  1999,  1996,  2677],\n",
      "            [ 2054,  2003,  1996,  2381,  1997,  1996,  2606, 21190,  2121],\n",
      "            [ 2054,  2024,  3724,  1998, 11211,  1999, 14910,  2361,  4210],\n",
      "            [ 2054,  2001,  1996,  8297,  2000,  1996,  4231,  1055, 13212],\n",
      "            [ 2054,  1055,  1996,  2117,  5221,  4855,  2932,  1999,  2637],\n",
      "            [ 2054,  2942,  2162,  2001,  4061,  2090,  4266,  1998,  3912],\n",
      "            [ 2171,  1996,  3435,  2833,  4677,  2007,  1996,  3585, 13540],\n",
      "            [ 2054,  2001,  1996,  3466,  1997,  1996,  8038, 24458,  3034],\n",
      "            [ 2054,  2024,  1996,  9646,  1997,  2019,  3256,  3873,  3125],\n",
      "            [ 2054,  2842,  2038,  1996, 25430, 14083,  7556,  2768,  2005],\n",
      "            [ 1999,  2054,  3971,  2106,  7332,  4921,  2490,  2845,  4935],\n",
      "            [ 2054,  2003,  1996,  3284, 14297,  1999,  1996,  2142,  2163],\n",
      "            [ 2054,  2003,  1996,  6493,  2314,  1999,  1996,  2142,  2163],\n",
      "            [ 2129,  2116, 16300,  2024,  2109,  1999,  8301, 26328,  2015],\n",
      "            [ 2054,  2003,  1996,  4587,  2311,  1999,  1996,  2142,  2163],\n",
      "            [ 2054,  2001,  2170,  1996,  2088,  1055,  2922,  2533,  3573],\n",
      "            [ 2129,  2079,  2017,  2424,  1996,  2181,  1997,  1037,  4418],\n",
      "            [ 1999,  2148,  4420,  2129,  2116,  2137,  3548,  2024,  2045],\n",
      "            [ 2054,  2003,  3021,  6733,  1997,  7513,  1041,  5653,  4769],\n",
      "            [ 2054,  2003,  1996,  2190,  2126,  2000,  3604,  1999,  2900],\n",
      "            [ 2004, 19362, 15464,  2063,  2003,  2036,  2124,  2004,  2054],\n",
      "            [ 2054,  2024,  1996,  2616,  2000,  1996,  3010,  2120, 11971],\n",
      "            [ 2054,  2003,  1996,  2088,  2501,  2005,  1996,  6493,  2606],\n",
      "            [ 2054,  2003,  1996,  2190,  3292,  2495,  2118,  2030,  2267],\n",
      "            [ 2054,  2442,  2022, 14872,  2000,  3965,  1037, 12728,  8797],\n",
      "            [ 2054,  3853,  2515,  1037,  2451,  1055,  2300,  3578,  3710],\n",
      "            [ 2054, 12991,  7751,  2003,  3621,  3805,  1997,  2049,  2051],\n",
      "            [ 2054,  2003,  4583,  2335,  4086,  2121,  2084, 11942,  5699],\n",
      "            [ 2054,  2003,  1996,  7290,  2504,  1997,  1996,  2137, 14814],\n",
      "            [ 2054,  2024,  1996,  6747,  2005, 15967,  6853,  1999,  5374],\n",
      "            [ 2054,  2003,  3725,  1055,  6664,  2006,  1996,  2822,  8240]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [4],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3367'], ['2076'], ['3589'], ['3642'], ['848'], ['4072'], ['3668'], ['1004'], ['775'], ['3399'], ['83'], ['709'], ['3855'], ['860'], ['2769'], ['4424'], ['5199'], ['1423'], ['2807'], ['4047'], ['3481'], ['3886'], ['2374'], ['3464'], ['413'], ['3326'], ['2145'], ['970'], ['211'], ['5424'], ['2677'], ['4507']],\n",
      "    text: (tensor([[ 2054,  2003,  1037, 10675,  2005,  2004, 19362, 15464,  2063],\n",
      "            [ 2054,  2457,  2515,  3960, 19133,  6235,  1999,  1996, 17937],\n",
      "            [ 2054,  5761,  2106,  7207,  2202,  2000,  4468,  1996,  4433],\n",
      "            [ 2054,  2158,  2081, 21938,  2003,  1015,  6146,  2661,  2146],\n",
      "            [ 2054,  2003,  1996,  2440,  2171,  1997,  1996, 20228,  2080],\n",
      "            [ 2054, 15644,  2024,  2045,  2005,  3633, 24260,  3436,  2668],\n",
      "            [ 2054,  2394,  3035,  2018,  2416,  3093,  2006,  2028,  2192],\n",
      "            [ 2054,  2001,  1996, 10200,  4823,  2177,  2005,  6060,  7369],\n",
      "            [ 2054,  3439,  2724,  3047,  1999,  3899,  4665,  1999,  6166],\n",
      "            [ 2054,  2576,  2283,  2003, 26403, 27132,  1037,  2112,  1997],\n",
      "            [ 2054,  2003,  1996,  8367,  2005,  1996,  2110,  1997,  5900],\n",
      "            [ 2129,  2521,  2064,  1037,  2158,  3604,  1999,  6058,  2686],\n",
      "            [ 2073,  2106,  1996,  2744,  2543, 24759, 15916,  2272,  2013],\n",
      "            [ 2054,  1057,  1055, 12295,  2056,  2562,  1996,  4752,  3336],\n",
      "            [ 2054,  2691, 11468,  2031,  1996,  4602,  3528,  1997, 15910],\n",
      "            [ 2339,  2106, 13481,  2034,  2272,  2000,  2660,  1998, 20526],\n",
      "            [ 2073,  1999,  1037,  3392,  2515,  7760,  6038, 25078,  5258],\n",
      "            [ 2054,  2024,  2070,  2590,  2824,  1997,  1996,  9500,  1055],\n",
      "            [ 2129,  2079,  2017,  2224,  8736,  2004,  4941,  2000,  2582],\n",
      "            [ 2054,  2003,  1996,  3185,  5655, 27656,  2712, 24848,  2140],\n",
      "            [ 2054,  1055,  1996,  3284,  2825,  7226,  1999,  3206,  2958],\n",
      "            [ 2054,  2003,  1996,  3274,  2005,  1996,  2717,  1997,  2149],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  5522,  4518,  3863],\n",
      "            [ 2054,  2323,  2017,  2079,  2005,  2019, 10792, 11867, 21166],\n",
      "            [ 2073,  2001,  1996,  5622, 27390,  2937,  3072, 14112, 15376],\n",
      "            [ 2054,  6759,  2024,  2218,  1999,  2047,  2259,  2023,  2733],\n",
      "            [ 2054,  6433,  2043,  7407,  9326,  1037,  2303,  1997,  2300],\n",
      "            [ 2171,  1996,  2069, 12905, 11544,  1997,  4556,  3306,  3248],\n",
      "            [ 2054,  2001,  1996,  2495,  2291,  1999,  1996,  3624,  1055],\n",
      "            [ 2054,  5404,  1055,  2171,  2003,  5421,  2004,  7006, 24702],\n",
      "            [ 2054,  2003,  1996,  2440,  5579,  1997,  1037,  3203, 11829],\n",
      "            [ 2054,  1055,  1996,  2087,  2691,  2395,  2171,  1999,  2637]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5195'], ['926'], ['3911'], ['91'], ['4023'], ['2241'], ['2479'], ['2325'], ['3363'], ['4577'], ['2966'], ['3971'], ['4144'], ['4852'], ['4712'], ['2234'], ['4998'], ['4366'], ['3726'], ['1698'], ['1832'], ['1669'], ['3030'], ['2509'], ['438'], ['2349'], ['2088'], ['1222'], ['4943'], ['4792'], ['1242'], ['2647']],\n",
      "    text: (tensor([[ 2054,  3573,  2515,  9246,  5954,  4748, 16874,  5562,  2005],\n",
      "            [ 2029,  2003,  1996,  2922,  5119,  6705,  7968,  1999,  2885],\n",
      "            [ 8042,  2234,  2000,  2373,  1999,  2762,  1999,  2054,  2095],\n",
      "            [ 2054,  5320,  1996,  2303,  2000, 13277,  1999,  3147,  7715],\n",
      "            [ 2054,  8942,  2839,  5906,  2105,  2006,  1037,  7151, 23490],\n",
      "            [ 2054,  2001,  2703, 21122,  7054,  1055, 23060,  1055,  2171],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  7437, 22962,  1055,  2316],\n",
      "            [ 2073,  2064,  1045,  4553,  2055,  5212,  2175,  8737,  2545],\n",
      "            [ 2054,  2003,  5622,  1048, 11113,  3678,  1055,  2197,  2171],\n",
      "            [ 2054,  2024,  1996,  2274,  2087,  2759,  2224,  7159,  2967],\n",
      "            [ 2054,  1055,  1996,  2087,  2691,  2171,  1999, 13640, 24468],\n",
      "            [ 2054,  2785,  1997,  6552,  2515,  1996, 22015,  2444,  1999],\n",
      "            [ 2073,  2003,  1996,  2880,  5717,  1997,  1996,  2712,  2504],\n",
      "            [ 2054,  2106, 19065,  5503,  2360,  2008,  2288,  2032,  4727],\n",
      "            [ 2073,  2003,  2028,  1055, 13931,  2655,  2891,  2819,  2179],\n",
      "            [ 2073,  2106,  9678,  4653,  2010, 13568,  2274,  2122,  2015],\n",
      "            [ 2054,  2003,  1996,  8674,  1997,  1037,  8254,  2063,  4400],\n",
      "            [ 2054,  2001,  2198, 14233, 12750,  1055,  8932,  7452, 20430],\n",
      "            [ 2054,  2003,  1996,  2166,  5987, 11656,  1997,  2019, 10777],\n",
      "            [ 2054,  2001,  1996,  2449,  1997,  1996,  6579,  3712, 12505],\n",
      "            [ 2054,  3226,  2764,  1996,  2801,  1997,  8962, 20051,  2818],\n",
      "            [ 2054,  2785,  1997,  3899,  2003,  8040,  9541,  3762, 20160],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1037,  3309,  1999,  9506],\n",
      "            [ 2054,  1055,  2047,  1999,  1996, 10690,  2088,  1999,  2639],\n",
      "            [ 2054,  2079, 12170, 27108, 12556,  4176,  2031,  2048,  1997],\n",
      "            [ 2054,  2210,  2879,  1998,  3899,  2444,  1999,  1037, 10818],\n",
      "            [ 2129,  2079,  2017,  5468,  1996,  3684,  1997,  1996,  3103],\n",
      "            [ 2054,  2024,  1996,  2034,  2702, 27950, 13665,  2015,  2979],\n",
      "            [ 2054,  2003, 11318,  2175, 28483, 16179,  1055,  2690,  3988],\n",
      "            [ 2054,  2001,  2198,  1042,  5817,  1055,  3624,  3049,  2299],\n",
      "            [ 2054,  2024,  1996,  2922, 18710,  3111,  1999,  1996,  2088],\n",
      "            [ 2054,  2024,  2070,  2204, 11110,  2005,  4268,  2000,  2079]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "            9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4199'], ['4432'], ['5447'], ['1023'], ['3940'], ['3830'], ['5062'], ['4910'], ['3750'], ['1750'], ['3562'], ['1602'], ['69'], ['983'], ['4638'], ['4498'], ['2987'], ['196'], ['3624'], ['5218'], ['3022'], ['921'], ['3292'], ['2935'], ['2422'], ['442'], ['4478'], ['4612'], ['4471'], ['3295'], ['4906'], ['2957']],\n",
      "    text: (tensor([[ 2054,  2106,  4658,  2192,  5355,  2175,  2000,  7173,  2005],\n",
      "            [ 2054,  2001, 14957,  2232, 12436,  4063,  1055,  2365,  2315],\n",
      "            [ 2054,  1055,  1996,  4338,  1997,  1037, 19130,  1055,  8560],\n",
      "            [ 2054,  2003,  5610,  2100,  1996,  4562,  1055,  2690,  2171],\n",
      "            [ 2054,  2003,  2178,  2171,  2005,  2379, 25807,  2098,  2791],\n",
      "            [ 2054,  2329,  2694,  2186,  4427,  2035,  1999,  1996,  2155],\n",
      "            [ 2029,  1997,  1996,  2698, 28984,  3310,  2034, 12440, 15004],\n",
      "            [ 2054,  2003,  1996,  5499, 13637,  2000,  1996,  2417,  2892],\n",
      "            [ 2054,  2001,  3533, 15125,  8988,  1055,  2034,  3206,  4276],\n",
      "            [ 2029,  4901,  3465,  3678,  3185,  7336,  1996, 16615,  6505],\n",
      "            [ 2054,  2828,  1997,  5593,  2106, 11044,  2310, 12119,  2031],\n",
      "            [ 2054,  2079, 19130,  2015,  3573,  1999,  2037, 14910,  4523],\n",
      "            [ 2054,  2024, 12731,  4095,  2386,  1998, 16045,  2124,  2005],\n",
      "            [ 2054,  2003,  2304,  4564,  2148,  7734,  2087,  3297,  2005],\n",
      "            [ 2040,  2001,  2641,  2000,  2022,  1996,  2269,  1997,  6825],\n",
      "            [ 2054,  2020,  1996,  2274,  3098,  2616,  2006,  3841,  9036],\n",
      "            [ 2054, 15300,  5836,  1037,  4477,  2007,  2252,  1998,  6099],\n",
      "            [ 2054, 24369,  2363,  2019,  5756,  3014,  2013,  7855,  2118],\n",
      "            [ 2054,  2003,  1996,  1058, 13626,  2140,  3231,  1997,  2668],\n",
      "            [ 2054,  2194,  1055, 11749,  2001,  2010,  3040,  1055,  2376],\n",
      "            [ 2054,  2106,  1996,  2698, 28984,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2001,  2137,  5154,  5394,  2198, 11526,  1055,  8367],\n",
      "            [ 2054,  2301,  2106,  2396,  1055,  6298,  2558,  4088,  1999],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  1996,  2773, 18565,     0],\n",
      "            [ 2054,  1057,  1055,  2118, 21979,  1996,  2922,  3075,     0],\n",
      "            [ 2129,  2172,  4586, 19635,  2019,  4960,  1997,  4542,     0],\n",
      "            [ 2029,  3348,  2003,  6380,  6830,  2916,  1999, 13085,     0],\n",
      "            [ 2054,  2003,  1996,  2034,  2154,  1997,  1996,  2733,     0],\n",
      "            [16933,  5209,  2109,  2000,  2022,  2081,  2011,  3183,     0],\n",
      "            [ 1999,  2054,  2095,  2001,  1996,  4068,  2813,  7019,     0],\n",
      "            [ 2054,  2024,  1996,  6666,  1997,  1037, 12037,  3698,     0],\n",
      "            [ 2054,  4082,  2291,  2079,  9980, 11892,  6681,  2224,     0]],\n",
      "           device='cuda:0'), tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3708'], ['1752'], ['4162'], ['556'], ['220'], ['197'], ['1335'], ['4444'], ['2685'], ['2415'], ['4100'], ['1884'], ['4307'], ['4948'], ['2351'], ['1937'], ['5103'], ['352'], ['3954'], ['3902'], ['3572'], ['593'], ['4568'], ['865'], ['1827'], ['5147'], ['3116'], ['2101'], ['5224'], ['2369'], ['2866'], ['707']],\n",
      "    text: (tensor([[ 2054,  2003,  1996,  3552,  2110,  3318,  4171,  3446],\n",
      "            [ 2129,  2515,  1037,  4045, 10250, 19879,  4263,  2147],\n",
      "            [ 2054,  2024,  1996,  2184, 11629,  2015,  1997,  5279],\n",
      "            [ 2054,  2003,  1996,  2190,  2267,  1999,  1996,  2406],\n",
      "            [ 2054,  2003,  1996,  2640,  1997,  1996,  2911, 20753],\n",
      "            [ 2043,  2001,  1996,  2034,  2813,  2395,  3485,  2405],\n",
      "            [ 2043,  2001,  1996,  9546,  3797, 21547,  3367,  2543],\n",
      "            [ 2054,  3257,  2079,  2087,  3598, 23232,  6510,  2646],\n",
      "            [ 1996,  2143, 16113,  2001,  2081,  1999,  2054,  2095],\n",
      "            [ 2054,  2003,  5980,  5215,  1055,  3058,  1997,  4182],\n",
      "            [ 2054,  2003,  1996,  2313,  1997,  1996,  2142,  2163],\n",
      "            [ 2054,  2024,  1996,  2698, 16278,  1997,  1996,  2088],\n",
      "            [ 2054,  2557,  2276,  2106,  2703,  7702,  2147,  2005],\n",
      "            [ 2054,  2003,  1996,  2088,  2313,  2004,  1997,  2651],\n",
      "            [13229,  1055,  2034,  3743,  4158,  2006,  2054,  3058],\n",
      "            [ 2054,  2079,  1996,  2413,  2655,  2474,  2158,  5403],\n",
      "            [ 2054,  2024, 19399,  1999,  1996,  3011,  1055, 19116],\n",
      "            [ 2054,  2024,  1996, 13908,  5711,  1997,  1037, 13361],\n",
      "            [ 2054,  2003,  1996, 28501,  3696,  2005,  2257,  2403],\n",
      "            [ 2054,  2515,  6746,  1055, 11320, 10196,  4330, 14970],\n",
      "            [ 2054, 13930,  2106, 19781,  2618,  2595,  2177,  2681],\n",
      "            [ 2054,  1055,  8455,  2043,  1037, 14199, 15701,  3514],\n",
      "            [ 2054,  1057,  1055,  2231,  4034, 18687, 11749,  2015],\n",
      "            [ 2339,  2020,  2111,  8733,  2005,  1996,  5148,  2162],\n",
      "            [ 2054,  1055,  1996,  2088,  1055,  6493,  8636,  2958],\n",
      "            [ 2054,  2003,  1996,  1055,  1052,  3156,  2109,  2005],\n",
      "            [ 2029, 16696,  2001,  2823,  2170, 26219,  2099,  2509],\n",
      "            [ 2054,  2003,  1037,  2470,  5590,  1999,  3137,  8218],\n",
      "            [ 2054,  2003,  1996,  2922,  2688,  1999,  1996,  2088],\n",
      "            [ 2054,  2079,  2087,  9045,  3942,  1999, 24964,  5244],\n",
      "            [ 2054,  2003,  3214,  2011,  2668,  7367,  2094,  3446],\n",
      "            [ 2054,  2001,  3035,  3848,  1055,  2516,  4953,  2634]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [4],\n",
      "            [4],\n",
      "            [3],\n",
      "            [4],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['1890'], ['4620'], ['4497'], ['933'], ['3935'], ['4018'], ['37'], ['2690'], ['2893'], ['866'], ['4402'], ['4502'], ['5275'], ['4774'], ['267'], ['53'], ['879'], ['5174'], ['2805'], ['2606'], ['4675'], ['4780'], ['1338'], ['955'], ['1678'], ['348'], ['2169'], ['3178'], ['314'], ['1316'], ['1625'], ['3788']],\n",
      "    text: (tensor([[ 2054,  2003,  1037, 11265, 10976, 26210,  3351,  2239],\n",
      "            [ 2054, 15607,  2813,  6753,  1996,  2919, 21682, 14493],\n",
      "            [ 2054,  2024,  1996,  2783,  7521,  4277,  1999,  2149],\n",
      "            [ 2054,  2001,  7905,  2100,  1998,  2033, 23935,  8671],\n",
      "            [ 2054,  2515,  1037,  2521, 16252,  2404,  6007,  2006],\n",
      "            [ 2054,  2515,  2009,  2202,  2000,  2468,  1037,  5160],\n",
      "            [ 1999,  2054,  4676,  2001, 18301,  1996,  3267,  7804],\n",
      "            [ 2054,  2001,  1996,  2905,  2911,  1997,  1996,  4386],\n",
      "            [ 1996,  2117,  2087,  2759,  4368,  4969,  2003,  2054],\n",
      "            [ 2054,  2283,  2001, 10180, 10888,  1037,  2266,  1997],\n",
      "            [ 2054,  2001,  1996,  3025,  2171,  2005,  1996,  5663],\n",
      "            [ 2054,  2515,  6554,  2332,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2248,  3029,  2001,  2631,  2011, 10254, 12975],\n",
      "            [ 2054,  2003,  1996, 21877,  4135, 26029, 20281,  2223],\n",
      "            [ 2054,  2003,  1996,  4438,  6210,  1997, 13800,  5394],\n",
      "            [ 2073,  2106,  1996,  2744,  6564,  2098,  2272,  2013],\n",
      "            [ 2054,  2001,  1996,  6139,  1997, 18193,  5785,  9082],\n",
      "            [ 2054,  2003,  1996,  2088,  1055,  2190,  4855, 17387],\n",
      "            [ 2054,  1055,  1996,  2171,  1997,  1996,  9925,  3780],\n",
      "            [ 2054,  2003,  1996,  5072,  5512,  1997,  1037, 22635],\n",
      "            [ 2054,  2003,  1996,  4633,  2066,  2006,  1996,  4231],\n",
      "            [ 2054,  2001,  5261, 22959,  2618,  1055,  4323,  2299],\n",
      "            [ 2054,  2003,  1996,  2431,  2166,  1997,  1052,  3590],\n",
      "            [ 2054,  2003,  1996,  7982,  4418,  1999, 13941,  2170],\n",
      "            [ 2054,  2024,  1996,  2922,  8860,  1999,  1996,  2149],\n",
      "            [ 2054,  2024,  1996,  2367,  8107,  1997,  3001,  4106],\n",
      "            [ 1996,  4589,  4605,  2003,  2284,  1999,  2054,  2103],\n",
      "            [ 2054,  2406,  2097,  2718,  1996,  2095,  1016,  2034],\n",
      "            [ 2054,  2154,  2001,  7247,  6496,  4457,  1999,  3758],\n",
      "            [ 2054,  2785,  1997,  2671,  2003,  2522, 25855,  6483],\n",
      "            [ 2054,  2024,  1037,  3598,  2136,  1055,  2543,  3549],\n",
      "            [ 2054,  2003, 11280,  6097, 15987,  2063,  2124,  2004]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['5376'], ['4514'], ['3021'], ['2898'], ['102'], ['1870'], ['3482'], ['299'], ['4889'], ['305'], ['2828'], ['3910'], ['3003'], ['4865'], ['2086'], ['1668'], ['466'], ['2474'], ['1644'], ['258'], ['4648'], ['5166'], ['692'], ['4607'], ['1918'], ['3673'], ['5377'], ['3987'], ['4318'], ['5000'], ['3291'], ['703']],\n",
      "    text: (tensor([[ 2054,  2003,  1996, 13805,  8316,  1997,  8744,  7893],\n",
      "            [ 6972,  8997,  2003,  2190,  2124,  2005,  2054,  6344],\n",
      "            [ 2054,  3466,  2515, 15012,  2031,  2006, 18870,  4367],\n",
      "            [ 2054,  1055,  1996,  3284,  2192,  1999,  3442, 11662],\n",
      "            [ 2054,  2106, 23006,  2079,  2000, 18375,  1055,  2606],\n",
      "            [ 2054,  1055,  2178,  2773,  2008,  2965,  4282,  2035],\n",
      "            [ 2054,  2003,  1996,  2966,  4650,  1997, 23760, 29048],\n",
      "            [ 2054,  2003,  3763,  2005,  4297, 25377, 12870,  3372],\n",
      "            [ 2054,  2003,  1996,  4489,  2090,  2606,  1998,  6519],\n",
      "            [ 2054,  2024,  1996,  1021,  4790,  1997,  1996,  4552],\n",
      "            [ 2054,  2515, 10250, 25099, 17637,  2000,  1999,  2394],\n",
      "            [ 2054,  2003,  1996, 22498,  2005,  2434,  3941,  7751],\n",
      "            [ 2054,  4796,  2441,  2006,  2264,  1998,  2225,  4068],\n",
      "            [ 2054,  2003,  1996,  3793,  1997,  1996,  3587,  7450],\n",
      "            [ 2040,  2003,  1996,  3306,  2643,  1997,  1996,  2712],\n",
      "            [ 2054,  2001,  2637,  1055, 28290,  2098, 11307,  9907],\n",
      "            [ 2054,  2003,  1996, 26849,  2732,  5710,  2013,  3011],\n",
      "            [ 2054,  2003,  4012,  4502,  4160,  1055,  3260,  4861],\n",
      "            [ 2054,  2001,  1996,  2535,  1997,  1996,  5781,  9054],\n",
      "            [ 2054,  2003,  1996, 13314,  2005, 10289,  8214,  2118],\n",
      "            [ 2054,  2020,  1996,  2034,  4230,  4716,  2011, 12076],\n",
      "            [ 2054,  2003,  1996,  2394,  3574,  1997, 10250, 25099],\n",
      "            [ 2054,  2515,  1037,  9152, 19466,  2923,  2903,  1999],\n",
      "            [ 2054,  2515,  6141,  7980,  2079,  2005,  1037,  2542],\n",
      "            [ 2054,  2003,  1996,  2171,  1997,  3335,  2634,  2807],\n",
      "            [ 2054,  3599,  4919,  2515,  3637,  2079,  2005,  2017],\n",
      "            [16933,  3194,  3765,  2020,  2081,  2011,  2054,  2194],\n",
      "            [ 2054,  2516,  2515,  9971,  2888,  2402,  2386,  4366],\n",
      "            [ 2054,  2465,  2003, 20427,  2004,  1996, 22846,  2666],\n",
      "            [ 2054,  2003,  1037,  2711,  1055, 17522, 23035,  2597],\n",
      "            [ 2339,  2003,  1996,  2773, 22498,  2061,  2146,     0],\n",
      "            [ 2073,  2024,  1996,  5133,  4542,  3224, 20611,     0]],\n",
      "           device='cuda:0'), tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "            8, 8, 8, 8, 8, 8, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2268'], ['4241'], ['276'], ['2047'], ['1941'], ['1037'], ['2669'], ['1694'], ['5050'], ['5121'], ['132'], ['2961'], ['1420'], ['3394'], ['3934'], ['4701'], ['3847'], ['2870'], ['3290'], ['130'], ['4052'], ['4323'], ['884'], ['3033'], ['1347'], ['5246'], ['1606'], ['5325'], ['1363'], ['1110'], ['774'], ['1978']],\n",
      "    text: (tensor([[ 2054,  2515, 28619,  4859, 21716,  2594,  2812],\n",
      "            [ 2040,  2001,  1996,  2034,  2450,  1999,  2686],\n",
      "            [ 2054,  2003,  9587,  2135,  2497,  4181,  2819],\n",
      "            [ 2054,  2024,  1996, 12971,  1997,  2047,  2563],\n",
      "            [ 2054,  2003,  1037,  3571,  1997,  2108,  6530],\n",
      "            [ 2129,  2079,  1045,  2424,  2041,  2055,  5841],\n",
      "            [ 2073,  2003,  1996,  2529,  3096,  2560,  7591],\n",
      "            [ 2054,  2003,  1996,  2922,  3528,  1997, 23265],\n",
      "            [ 2043,  2001,  1996,  2112, 10222,  2239,  2328],\n",
      "            [ 2054,  6087,  2003, 17454, 12380,  2081,  1997],\n",
      "            [ 2054,  2003,  1037,  2143,  4626, 12582,  2375],\n",
      "            [ 2054, 15607,  2314,  6223,  2083,  4524, 14697],\n",
      "            [ 2054,  2003,  1996, 13747,  2311,  1999,  2900],\n",
      "            [ 2054,  2515,  1996,  3149, 10978,  3233,  2005],\n",
      "            [ 2054,  3047,  2000, 13433,  8737,  7416,  2072],\n",
      "            [ 2054,  2003,  2343, 11296,  1055,  4182, 13701],\n",
      "            [ 2054,  6139,  2038,  1996,  3284,  8179,  3446],\n",
      "            [ 2073,  2003,  2115, 13931,  2655,  2891,  2819],\n",
      "            [ 2054,  2003,  1996,  2190,  3784,  2399,  2609],\n",
      "            [ 2054,  3117,  4427,  1996,  3185,  6085, 23195],\n",
      "            [ 2054,  2679,  2003,  1015, 14989,  2661,  2146],\n",
      "            [ 2054,  2003,  6970, 20051,  2050,  4274,  2326],\n",
      "            [ 2054,  2024,  1996,  2542,  3785,  1999,  7394],\n",
      "            [ 2007,  3183,  2106,  5747, 12826, 24111, 16543],\n",
      "            [ 2054,  2003,  3021,  7977,  1055, 10373,  4769],\n",
      "            [ 2054,  2024,  1996,  2274,  3937,  5742, 13692],\n",
      "            [ 2054,  2003,  4141,  2641,  1996,  3587,  3168],\n",
      "            [ 2054,  2003,  1996,  2087,  4235, 13237,  3269],\n",
      "            [ 2054,  2311,  2024,  2329, 19799, 10249,  1999],\n",
      "            [ 2054,  2024,  7538, 13051,  1999, 24964,  5244],\n",
      "            [ 2054,  2001,  6117,  1055,  2034,  4552,  2170],\n",
      "            [ 2054,  3032,  2031,  1996,  2190,  8785,  2493]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [4],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['519'], ['2920'], ['271'], ['4518'], ['4333'], ['4386'], ['47'], ['5150'], ['1908'], ['2074'], ['4789'], ['1492'], ['4840'], ['416'], ['5143'], ['669'], ['845'], ['1359'], ['3028'], ['4779'], ['1007'], ['2063'], ['3718'], ['104'], ['2133'], ['1327'], ['4828'], ['453'], ['3114'], ['3478'], ['4761'], ['1213']],\n",
      "    text: (tensor([[ 2054,  2003, 29153,  1055,  2364, 19502,  9167],\n",
      "            [ 2054,  2515,  1037,  2002, 12798, 10727,  2817],\n",
      "            [ 2054,  2106, 22953, 13663, 22244,  2229,  4521],\n",
      "            [ 2054,  4774,  2106, 27832,  2293,  3363,  7523],\n",
      "            [ 2054,  2024,  1996,  2176,  7111,  1999, 15404],\n",
      "            [ 2054,  2003,  1037, 13045,  1999,  3274,  3408],\n",
      "            [ 2054,  2003,  4523,  4839,  1999,  1996,  7139],\n",
      "            [ 2054,  2024,  1996, 12760,  1997, 16787, 15270],\n",
      "            [ 2054,  2003,  1996,  5072,  6454,  2005, 14114],\n",
      "            [ 2054,  2003,  3565, 15239,  1055,  3595,  4767],\n",
      "            [ 2054,  2003,  1996,  7268, 15156,  2005, 28519],\n",
      "            [ 2129,  3435,  2079, 18178, 12928,  7898,  2448],\n",
      "            [ 2054,  2515,  1037, 21877, 26173,  3334,  5468],\n",
      "            [ 2054, 26572, 20281,  2111, 21490,  2047,  3414],\n",
      "            [ 2054,  2003,  1996,  2087,  2759,  2197,  2171],\n",
      "            [ 2129,  3435,  2515,  1996,  7915,  2482,  2175],\n",
      "            [ 2054,  2003,  1040,  1038,  6201,  2124,  2005],\n",
      "            [ 2171,  2019,  2396,  3916,  1999,  2047,  2259],\n",
      "            [ 2073,  2106,  1996,  2744,  6353,  2272,  2013],\n",
      "            [ 2129,  2515,  2236,  6341,  9922, 15138, 10735],\n",
      "            [ 2073,  2106,  1996,  2744,  6564,  2272,  2013],\n",
      "            [ 2054,  1055,  1996,  9350, 13821,  1999,  9780],\n",
      "            [ 2054,  2003,  1996,  4761,  1997,  8362,  2154],\n",
      "            [ 2029,  1997,  1996,  2206,  2001, 10588,  6288],\n",
      "            [ 2054,  2400,  2003,  1996,  7436,  1997,  6475],\n",
      "            [ 2040,  2764,  1996,  2034, 14955,  3695, 17404],\n",
      "            [ 2054,  2024,  2492,  3466,  9099, 20483,  2869],\n",
      "            [ 2054,  1055,  3267,  1055,  3800,  2005, 22668],\n",
      "            [ 2073,  2003,  1996, 12065,  3455,  2136,  2241],\n",
      "            [ 2054,  2064,  2028,  2156,  1999, 24964,  5244],\n",
      "            [ 2054,  2020, 11561,  7920,  1055,  3017,  3415],\n",
      "            [ 2054,  2106,  1996,  3806,  2160,  6080,  2377]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['2956'], ['2262'], ['4128'], ['2599'], ['888'], ['5390'], ['914'], ['5320'], ['4183'], ['2951'], ['657'], ['5279'], ['1645'], ['2318'], ['4506'], ['4659'], ['2906'], ['2012'], ['965'], ['4882'], ['2410'], ['4'], ['4625'], ['4827'], ['2846'], ['502'], ['1093'], ['4139'], ['4555'], ['2424'], ['3389'], ['4523']],\n",
      "    text: (tensor([[ 2040,  2001, 10861,  5753,  2389, 16531,  2140],\n",
      "            [ 2040,  2001,  1059, 16584, 18274, 18414, 25112],\n",
      "            [ 2054,  2079,  2394,  3549, 17042,  3209,  1999],\n",
      "            [ 2054,  2003,  1996, 17974,  2005,  6763, 12122],\n",
      "            [ 2054, 19264,  2628,  8912,  2000,  1996, 10925],\n",
      "            [ 2054,  2515,  1996,  2314, 16470,  4064,  2046],\n",
      "            [ 2054,  1055,  1996,  6730,  2314,  1997,  2634],\n",
      "            [ 2054,  1055,  1037, 10231,  2015,  2447,  2170],\n",
      "            [ 2054,  2024, 13433,  4168, 17643, 12556,  2015],\n",
      "            [ 2054,  2003,  1996,  3284,  3142, 16371, 28990],\n",
      "            [ 2129,  2003, 10957,  4465,  1055,  3058,  4340],\n",
      "            [ 2054,  4774,  2435,  2978,  2232,  2000, 10646],\n",
      "            [10021,  2404,  3723,  2001,  8826,  2011,  3183],\n",
      "            [ 2054,  2020,  1996, 10106,  1997,  2957, 11296],\n",
      "            [ 2054,  2001, 18379,  1996,  2744, 19117,  8975],\n",
      "            [ 2054,  2785,  1997,  2194,  2003,  1021,  5408],\n",
      "            [ 2054,  2106,  1996,  3519,  1997,  6004,  5323],\n",
      "            [ 1996,  4589,  4605,  2003,  1999,  2054,  2103],\n",
      "            [ 2054,  4127,  1997,  2300, 10796,  2024,  2045],\n",
      "            [ 2073,  2024, 29145,  2015,  2087,  3497,  2179],\n",
      "            [ 2054,  2515,  6275, 22610,  5354, 23777,  5020],\n",
      "            [ 2054,  2003,  1996,  2440,  2433,  1997,  4012],\n",
      "            [ 2040,  2020,  2198,  1042,  5817,  1055,  6077],\n",
      "            [ 2054,  2003,  2224,  7159,  2005,  1996,  4274],\n",
      "            [ 2054, 12652,  3092, 21442,  7373, 16106, 13941],\n",
      "            [ 2054,  2001,  2124,  2004,  1996, 17688,  2479],\n",
      "            [ 2054,  2003, 15333,  3363,  1051,  2081,  2013],\n",
      "            [ 6972,  8997,  2003,  2087,  3297,  2005,  2054],\n",
      "            [ 2054,  1055,  1996,  2110, 12652,  1997,  2662],\n",
      "            [ 2054,  2079,  2887,  2082, 11408,  2298,  2066],\n",
      "            [ 2054,  2024,  1996,  6177,  1997, 26572, 20367],\n",
      "            [ 2054,  2106, 29554,  2015,  3046,  2000,  2203]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "            7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [4],\n",
      "            [5],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['959'], ['4285'], ['2448'], ['3465'], ['28'], ['19'], ['4551'], ['2447'], ['2069'], ['1845'], ['2036'], ['2788'], ['5180'], ['5076'], ['4702'], ['1221'], ['2546'], ['3735'], ['3879'], ['3294'], ['4142'], ['4516'], ['216'], ['4377'], ['5091'], ['2140'], ['4673'], ['687'], ['4580'], ['4578'], ['2362'], ['1186']],\n",
      "    text: (tensor([[ 2054,  2003,  1996,  6614,  5139,  2278,  6708],\n",
      "            [ 2054,  9843,  2051,  2079,  2057,  2444,  1999],\n",
      "            [ 2054,  2003,  1996,  7117,  1997,  2035,  4763],\n",
      "            [ 2054,  3333,  1015, 22997,  2519,  1999,  3150],\n",
      "            [ 2171,  1037,  5439,  2607,  1999, 21381,  3509],\n",
      "            [ 2054,  2003,  2019,  5754, 17287,  3064, 24751],\n",
      "            [ 2040,  2001,  1996,  2034,  4111,  2046,  2686],\n",
      "            [ 2029,  2003,  1996,  2087,  2109,  3274,  2565],\n",
      "            [ 2054,  2003,  1996,  5675,  2000, 18422, 14255],\n",
      "            [ 2054,  2003,  2745,  4027,  1055,  2690,  2171],\n",
      "            [ 2054,  1055,  1996,  2880,  2653,  1997, 11337],\n",
      "            [ 2054,  2515,  1996, 13445,  2832,  4372, 14162],\n",
      "            [ 2054,  1055,  1996,  1057,  1055,  3212, 14825],\n",
      "            [ 2054,  2001,  1996,  2757,  2158,  1055,  2192],\n",
      "            [ 2054,  2003,  1996,  2307,  2137,  2155, 20943],\n",
      "            [ 8362,  2154,  2003,  6334,  2006,  2054,  3058],\n",
      "            [ 2054,  2515, 10250, 25099,  2812,  1999,  2394],\n",
      "            [ 2054,  2515,  1996,  2171, 19347,  2812,     0],\n",
      "            [ 2040,  2003,  1996,  3954,  1997, 13229,     0],\n",
      "            [ 2054,  2003,  1037,  9850,  1997,  7815,     0],\n",
      "            [ 2054,  2515,  6413,  2015,  2769,  2812,     0],\n",
      "            [ 2040,  6791, 14916, 19513,  1999, 24592,     0],\n",
      "            [ 2054,  2003,  1055,  3630, 21131,  2015,     0],\n",
      "            [ 2054,  2003,  1037,  3571,  1997, 10394,     0],\n",
      "            [ 2054,  2515, 23969,  2290,  3233,  2005,     0],\n",
      "            [ 2054,  2712, 20626,  1996, 26164,  3470,     0],\n",
      "            [ 2054,  2003,  2197,  3382,  2005,  4176,     0],\n",
      "            [ 2054,  2003,  1037,  3571,  1997, 23996,     0],\n",
      "            [ 2054,  2515,  1996,  2171,  9606,  2812,     0],\n",
      "            [ 2054,  2024,  1996,  2698,  9252, 15516,     0],\n",
      "            [ 2040,  2003,  1996, 12168,  1997, 15761,     0],\n",
      "            [12582,  2375,  6051,  1999,  2029,  2143,     0]], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4132'], ['4439'], ['1001'], ['4024'], ['3179'], ['949'], ['1342'], ['4476'], ['3252'], ['4559'], ['4601'], ['1145'], ['683'], ['837'], ['224'], ['3476'], ['4831'], ['4069'], ['2808'], ['2992'], ['2520'], ['3891'], ['1456'], ['214'], ['1743'], ['1853'], ['1429'], ['3431'], ['3570'], ['5252'], ['2425'], ['1843']],\n",
      "    text: (tensor([[ 2040,  8826,  1996,  9587,  8649, 13564],\n",
      "            [ 2129,  4206,  2003,  1996,  3043,  9769],\n",
      "            [ 2043,  2106,  8956,  3629, 18445, 13085],\n",
      "            [ 2054,  2024,  1996,  2364,  2668,  6470],\n",
      "            [ 2054,  6087,  2191,  2039,  1037, 10098],\n",
      "            [ 2054,  2001,  1996,  9610, 21827,  9288],\n",
      "            [ 2054,  2079,  3017,  6529,  2903,  1999],\n",
      "            [ 2054,  2097,  1996,  4633,  2022,  2651],\n",
      "            [ 2054,  2110,  2515,  2798, 26211,  5050],\n",
      "            [ 1996,  3644, 12440,  2003,  2170,  2054],\n",
      "            [ 2054,  1055,  1996, 13048,  1997, 18740],\n",
      "            [ 2054,  2003,  6554,  2332,  1055,  3105],\n",
      "            [ 2054,  2003,  1996,  4678,  3367,  9226],\n",
      "            [ 2054,  2003,  2281,  1055, 18250,  5524],\n",
      "            [ 2054,  2003,  1996,  1021,  3371,  9907],\n",
      "            [ 2054,  2515,  5000,  9436,  4063, 10172],\n",
      "            [ 2054,  2003,  2110,  3392,  1997,  8506],\n",
      "            [ 2054,  2003,  6141,  7980,  1055,  9518],\n",
      "            [ 2054,  2001,  1996,  6585,  2000, 17550],\n",
      "            [ 2054,  2081,  4869,  2204,  8095,  3297],\n",
      "            [ 2043,  2079,  2017,  3269,  3467, 10500],\n",
      "            [ 2054,  2515,  1996, 26385,  2194,  9922],\n",
      "            [ 2054,  2003,  1996,  1039,  4730,  2653],\n",
      "            [ 2054,  2003, 22396,  5811,  3297,  2005],\n",
      "            [ 2054,  2003,  1037, 16475,  2080,  6045],\n",
      "            [ 5455,  4097,  2798,  3248,  2054,  6602],\n",
      "            [ 2054,  2614,  2515, 17096,  2899, 27590],\n",
      "            [ 2054,  2024,  2070,  2336,  1055,  2916],\n",
      "            [ 2054,  2024,  1996,  2732,  5233, 14549],\n",
      "            [ 2040,  2081,  1996, 16933,  3194,  9935],\n",
      "            [ 2171,  1037,  5474,  2697,  2103,  3780],\n",
      "            [ 2073,  2106,  2002,  2131,  1996,  2516]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [4],\n",
      "            [4],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['4039'], ['3087'], ['3752'], ['3605'], ['3578'], ['4284'], ['366'], ['843'], ['261'], ['159'], ['4872'], ['1149'], ['5214'], ['4171'], ['2105'], ['2299'], ['3303'], ['5095'], ['361'], ['4698'], ['2548'], ['92'], ['1720'], ['176'], ['3945'], ['4032'], ['4049'], ['4248'], ['3016'], ['1537'], ['1508'], ['851']],\n",
      "    text: (tensor([[ 2054,  2024,  3565,  7395,  2081,  1997],\n",
      "            [ 2054,  2024,  1996,  3340,  2081,  1997],\n",
      "            [ 2073,  2001, 24494,  9790,  2100,  8826],\n",
      "            [ 2040,  2003,  2198, 17719, 21502, 10700],\n",
      "            [ 2073,  2106,  5939, 17176,  4982,  2039],\n",
      "            [ 2171,  2176,  5021, 12970,  2055,  8221],\n",
      "            [ 2129,  3144,  2003, 12098,  8462, 20900],\n",
      "            [ 2054,  2003,  1996,  6493,  2394,  2773],\n",
      "            [13229,  2003,  1996, 22498,  2005,  2054],\n",
      "            [ 2054,  2003,  1037, 11394,  7117,  5033],\n",
      "            [ 2054,  2003,  1996,  2087,  2691,  2171],\n",
      "            [ 2054,  2003,  1996,  3949,  2005,  6245],\n",
      "            [ 2054,  2003,  1996,  8367,  1997,  3552],\n",
      "            [ 2054,  2003,  8223,  1999,  1996,  3274],\n",
      "            [ 2054,  2003,  2686,  7384,  2209,  2006],\n",
      "            [ 2054,  2003,  5980,  5215,  1055,  5798],\n",
      "            [ 2054,  2003,  2258,  1055, 20296,  5524],\n",
      "            [ 6972,  8997,  2003,  3297,  2005,  2054],\n",
      "            [ 9375,  1996,  6887, 10242,  7646,  2252],\n",
      "            [ 2054,  2024,  8026, 20936,  2389, 21374],\n",
      "            [ 2054,  2003,  1996,  3260,  1997, 18368],\n",
      "            [ 2054,  2024,  4562,  1998,  7087,  6089],\n",
      "            [ 2054,  2003,  1996,  2976,  6263, 11897],\n",
      "            [ 2073,  2106,  2796, 29593,  2272,  2013],\n",
      "            [ 2054,  2024,  1996, 16324,  1999,  4274],\n",
      "            [ 2054, 12779, 23442,  6683,  2006, 12071],\n",
      "            [ 2054,  2003,  1996,  3635,  1997,  2250],\n",
      "            [ 2054,  4676,  2038,  1996,  2087,  2372],\n",
      "            [ 2043,  2003,  1037,  2450,  2087, 14946],\n",
      "            [ 2073,  2106, 10189, 11012,  2121,  3627],\n",
      "            [ 2054,  2003,  1996, 12440,  2005,  3763],\n",
      "            [ 2054,  2287,  2628,  1996,  4421,  2287]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "            6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [5],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [5],\n",
      "            [2],\n",
      "            [4],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4],\n",
      "            [0],\n",
      "            [4],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['3165'], ['2329'], ['3441'], ['110'], ['3177'], ['4993'], ['601'], ['3729'], ['5128'], ['5313'], ['2215'], ['4699'], ['1143'], ['1453'], ['566'], ['2988'], ['5135'], ['1123'], ['2111'], ['4342'], ['787'], ['4757'], ['2482'], ['35'], ['170'], ['2593'], ['1089'], ['1943'], ['5436'], ['960'], ['3694'], ['3761']],\n",
      "    text: (tensor([[ 2054,  1055,  1037,  3287,  6965,  2170],\n",
      "            [ 2054,  2079, 18931,  2015,  6775,  2007],\n",
      "            [ 2129,  2898,  2003,  1996,  4448,  4153],\n",
      "            [ 2073,  2079, 28480,  2015,  2272,  2013],\n",
      "            [ 2054,  2106,  9822,  2272,  2067,  2004],\n",
      "            [ 2054,  2003,  1996,  2087,  2691,  4456],\n",
      "            [ 2054,  2003,  1996,  4562,  1997, 18007],\n",
      "            [ 2171,  1997,  2332,  4300,  1055,  4690],\n",
      "            [ 2054,  6459,  9002,  2000,  2049,  4454],\n",
      "            [ 2054,  3047,  2006,  2254,  2321,  3440],\n",
      "            [ 2073,  2515,  8945, 20534,  2272,  2013],\n",
      "            [ 2054,  2001,  1996,  2542,  2282,  2162],\n",
      "            [ 2054,  2003,  1037, 27291,  7473,     0],\n",
      "            [ 2054,  2024,  1996,  2698, 11915,     0],\n",
      "            [ 2054,  2003,  1037,  2665, 22132,     0],\n",
      "            [ 2040,  2764,  8962, 20051,  2818,     0],\n",
      "            [ 2054,  2003, 11917,  1999,  2833,     0],\n",
      "            [ 2073,  2106,  7102, 14695, 21754,     0],\n",
      "            [ 2054,  2024, 21243,  2081,  1997,     0],\n",
      "            [ 2054,  2001,  1996,  5409,  7064,     0],\n",
      "            [ 2043,  2001,  1996,  2307,  6245,     0],\n",
      "            [ 2054,  2024,  7280,  3156,  3316,     0],\n",
      "            [ 2054, 10585,  8826,  1996,  7905,     0],\n",
      "            [ 2054,  2079, 15111,  2015,  2903,     0],\n",
      "            [ 2073,  2024,  1996,  4749,  4084,     0],\n",
      "            [ 2054,  1055,  1037,  2460, 10228,     0],\n",
      "            [ 2054,  4245,  2572,  1045,  1999,     0],\n",
      "            [ 2054,  1055,  1996,  2417,  4774,     0],\n",
      "            [ 2054,  2769,  2001,  2109,  2182,     0],\n",
      "            [ 2043,  2024,  8351, 26822,  6826,     0],\n",
      "            [ 2054,  2003,  1996,  7915,  3274,     0],\n",
      "            [ 2054,  2024,  2070, 11327, 11744,     0]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "            5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')),\n",
      "    label: tensor([[0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [2],\n",
      "            [0],\n",
      "            [4],\n",
      "            [0],\n",
      "            [3]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['18'], ['4185'], ['4148'], ['4325'], ['559'], ['1444'], ['292'], ['5038'], ['1702'], ['3755'], ['2742'], ['291'], ['891'], ['3219'], ['4765'], ['2531'], ['2179'], ['1070'], ['373'], ['2550'], ['2710'], ['3382'], ['1162'], ['3277'], ['3842'], ['553'], ['148'], ['338'], ['2035'], ['2328'], ['4191'], ['1705']],\n",
      "    text: (tensor([[ 2054,  2003,  3157,  4960, 10063],\n",
      "            [ 2054,  2515,  5863,  3766,  2079],\n",
      "            [ 2054,  2003,  1037,  6270,  4231],\n",
      "            [ 2054,  2003,  1996,  2959,  9812],\n",
      "            [ 2054,  2024,  1996, 13649,  3741],\n",
      "            [ 2029,  1997,  2122,  2024,  6048],\n",
      "            [ 2054,  2079, 16773,  2655,  7701],\n",
      "            [ 2054,  2003,  2976,  3318,  4171],\n",
      "            [ 2054, 10662,  2001,  4027, 25218],\n",
      "            [ 2073,  2515, 24903,  2272,  2013],\n",
      "            [ 2054,  2515,  1037, 20466,  3067],\n",
      "            [ 2073,  2001,  5696,  8912,  2141],\n",
      "            [ 2054,  2024,  1996,  2698, 21560],\n",
      "            [ 2054,  2003,  1996,  3795,  4610],\n",
      "            [ 2054,  2024,  1996, 22162, 14243],\n",
      "            [ 2054,  2515,  1037,  2450,  2215],\n",
      "            [ 2073,  2003,  1999, 24163,  2241],\n",
      "            [ 2073,  2106, 16204,  2272,  2013],\n",
      "            [ 2073,  2515,  7967,  2272,  2013],\n",
      "            [ 2129,  2521,  2064,  2017,  2156],\n",
      "            [ 2054,  2515,  2019,  3750,  2079],\n",
      "            [ 2054,  2003,  1996, 16708,  2291],\n",
      "            [ 2054,  2024,  1996, 24471,  9777],\n",
      "            [ 2171,  1037,  2413, 14870,  2283],\n",
      "            [ 2054,  2003,  1037,  3269, 12448],\n",
      "            [ 2073,  2079,  5749,  2272,  2013],\n",
      "            [ 2040,  7137, 11867, 19042,  2618],\n",
      "            [ 2054,  2024,  1996,  2176,  3787],\n",
      "            [ 2054,  2003,  2757, 29346, 11339],\n",
      "            [ 2054,  2003,  3306,  6770,  2050],\n",
      "            [ 2073,  2079,  3737,  8974,  4088],\n",
      "            [ 2043,  2001,  3035,  3848,  2141]], device='cuda:0'), tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "            5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [3],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [3],\n",
      "            [4]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['1605'], ['636'], ['2519'], ['2902'], ['2786'], ['323'], ['2266'], ['5449'], ['947'], ['726'], ['846'], ['4630'], ['2686'], ['5231'], ['4337'], ['5395'], ['22'], ['1949'], ['653'], ['3579'], ['1091'], ['4205'], ['4448'], ['4663'], ['8'], ['1187'], ['429'], ['2189'], ['94'], ['791'], ['1452'], ['1888']],\n",
      "    text: (tensor([[ 2054,  2024,  3819,  9049,  2015],\n",
      "            [ 2054,  2079,  4257,  7529,  4521],\n",
      "            [ 2171,  1037,  2942,  2162, 11686],\n",
      "            [ 2171,  1037,  2931,  3275, 18815],\n",
      "            [ 2054,  2003, 15680,  4357,  6028],\n",
      "            [ 2054,  2024, 14414,  1055,  6087],\n",
      "            [ 2054,  4762,  2079, 24042,  2224],\n",
      "            [ 2054,  2003,  1996,  4860,  2651],\n",
      "            [ 2054,  2003,  2660,  2154,     0],\n",
      "            [ 2054,  2003, 11831,  9457,     0],\n",
      "            [ 2040,  2003,  6972,  8997,     0],\n",
      "            [ 2040,  2881,  2414,  2958,     0],\n",
      "            [ 2129,  2515,  7407,  3604,     0],\n",
      "            [ 2073,  2106,  5789, 21754,     0],\n",
      "            [ 2054,  2003,  1037, 21477,     0],\n",
      "            [ 6235,  1996,  2146,  2233,     0],\n",
      "            [ 2171,  2340,  3297, 18945,     0],\n",
      "            [ 2054,  2003, 18303,  7720,     0],\n",
      "            [ 2054,  2024,  5008,  3340,     0],\n",
      "            [ 2054,  2003,  1037, 15246,     0],\n",
      "            [ 2040,  2003,  6203,  9460,     0],\n",
      "            [ 2171,  1037,  3909, 25476,     0],\n",
      "            [ 2073,  2024, 11719, 21846,     0],\n",
      "            [ 2054,  4094,  5761, 17932,     0],\n",
      "            [ 2054,  2024, 11290, 16285,     0],\n",
      "            [ 2054,  5320,  6634,  4491,     0],\n",
      "            [ 2054,  2730,  3960, 20326,     0],\n",
      "            [ 2054,  5329,  2024, 10432,     0],\n",
      "            [ 2054,  2003, 24903,  2391,     0],\n",
      "            [ 2054,  2003,  4810, 23187,     0],\n",
      "            [ 3005, 25337,  2001,  6436,     0],\n",
      "            [ 2054, 17367,  2019,  4639,     0]], device='cuda:0'), tensor([5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "            4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')),\n",
      "    label: tensor([[2],\n",
      "            [0],\n",
      "            [3],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [4],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0],\n",
      "            [3],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [2],\n",
      "            [1],\n",
      "            [0]], device='cuda:0')\n",
      "})\n",
      "Batch({\n",
      "    id: [['60'], ['1721'], ['4564'], ['4641'], ['5338'], ['3280'], ['1427'], ['2963']],\n",
      "    text: (tensor([[ 2073,  2003,  1996,  7077],\n",
      "            [ 5900,  2003,  9919,  2054],\n",
      "            [ 2040,  8826,  3455,     0],\n",
      "            [ 2054,  2024,  5300,     0],\n",
      "            [ 9375, 26403, 27132,     0],\n",
      "            [ 2054,  2003,  2051,     0],\n",
      "            [ 2054,  2003,  2643,     0],\n",
      "            [ 2054,  2003,  9262,     0]], device='cuda:0'), tensor([4, 4, 3, 3, 3, 3, 3, 3], device='cuda:0')),\n",
      "    label: tensor([[3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2],\n",
      "            [2]], device='cuda:0')\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "enc = []\n",
    "grads = []\n",
    "labels = []\n",
    "enc_layers = {i: [] for i in range(num_layers)}\n",
    "\n",
    "\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=False,\n",
    "    indices=indices,\n",
    ")\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch in train_iter:\n",
    "\n",
    "        print(batch)\n",
    "        inputs, _ = batch.text\n",
    "        labels.append(batch.label)\n",
    "        inputs.requires_grad = False\n",
    "\n",
    "    #     embedded_tokens = clf.bert.embeddings(inputs)\n",
    "    #     embedded_tokens = torch.autograd.Variable(\n",
    "    #         embedded_tokens, requires_grad=True\n",
    "    #     )\n",
    "        encoded_all = clf(\n",
    "            inputs,\n",
    "            output_hidden_states=True,\n",
    "            # head_mask=head_mask,\n",
    "            # attention_mask=attention_mask,\n",
    "        )\n",
    "        # Skip the embedding layer [1:]\n",
    "        for i, enc_layer in enumerate(encoded_all[1][1:]):\n",
    "            enc_layers[i].append(enc_layer[:, 0].cpu())\n",
    "\n",
    "\n",
    "        encoded = encoded_all[0][:, 0]\n",
    "        enc.append(encoded.cpu())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    y = torch.cat(labels)\n",
    "    for k, v in enc_layers.items():\n",
    "        X = torch.cat(v)\n",
    "        enc_layers[k] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45480170",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enc_layers[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27410ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch({\n",
      "    id: [['929'], ['3557'], ['2485'], ['4861'], ['4268'], ['4895'], ['4261'], ['3601'], ['2526'], ['4800'], ['5375'], ['515'], ['1395'], ['253'], ['2173'], ['3307'], ['2827'], ['1692'], ['2269'], ['3664'], ['1148'], ['3327'], ['3923'], ['4443'], ['3472'], ['1296'], ['2737'], ['2024'], ['580'], ['1773'], ['1002'], ['4585']],\n",
      "    text: (tensor([[ 2171,  1996,  4802,  ...,  4895, 15464,  2098],\n",
      "            [ 2054,  2003,  1996,  ...,     0,     0,     0],\n",
      "            [ 2054,  2280,  2548,  ...,     0,     0,     0],\n",
      "            ...,\n",
      "            [ 2129,  2064,  1045,  ...,     0,     0,     0],\n",
      "            [ 2054,  2001,  2928,  ...,     0,     0,     0],\n",
      "            [ 2054, 17727,  8625,  ...,     0,     0,     0]], device='cuda:0'), tensor([32, 29, 26, 24, 24, 23, 23, 23, 23, 23, 22, 22, 21, 21, 21, 21, 21, 21,\n",
      "            20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19],\n",
      "           device='cuda:0')),\n",
      "    label: tensor([[1],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [2],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [1],\n",
      "            [1],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0],\n",
      "            [0],\n",
      "            [2],\n",
      "            [3],\n",
      "            [0],\n",
      "            [1],\n",
      "            [4],\n",
      "            [0],\n",
      "            [1],\n",
      "            [1],\n",
      "            [0],\n",
      "            [0],\n",
      "            [3],\n",
      "            [2],\n",
      "            [0],\n",
      "            [0]], device='cuda:0')\n",
      "})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2889323/28447427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0membedded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[0;32m---> 26\u001b[0;31m     encoded_all = clf(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0membedded_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         output_hidden_states=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/transformers/adapters/context.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     }\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;31m# append output attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "enc = []\n",
    "grads = []\n",
    "labels = []\n",
    "enc_layers = {i: [] for i in range(num_layers)}\n",
    "\n",
    "\n",
    "train_iter = make_iterable(\n",
    "    train,\n",
    "    device,\n",
    "    batch_size=args.batch_size,\n",
    "    train=False,\n",
    "    indices=indices,\n",
    ")\n",
    "\n",
    "for batch in train_iter:\n",
    "\n",
    "    print(batch)\n",
    "    inputs, _ = batch.text\n",
    "    labels.append(batch.label)\n",
    "    inputs.requires_grad = False\n",
    "\n",
    "    embedded_tokens = clf.embeddings(inputs)\n",
    "    embedded_tokens = torch.autograd.Variable(\n",
    "        embedded_tokens, requires_grad=True\n",
    "    )\n",
    "    encoded_all = clf(\n",
    "        embedded_tokens,\n",
    "        output_hidden_states=True,\n",
    "        # head_mask=head_mask,\n",
    "        # attention_mask=attention_mask,\n",
    "    )\n",
    "    # Skip the embedding layer [1:]\n",
    "    for i, enc_layer in enumerate(encoded_all[1][1:]):\n",
    "        enc_layers[i].append(enc_layer[:, 0].cpu())\n",
    "\n",
    "    encoded = encoded_all[0][:, 0]\n",
    "    enc.append(encoded.cpu())\n",
    "\n",
    "    mean = encoded.mean()\n",
    "    mean.backward()\n",
    "    enc_grad = embedded_tokens.grad.data\n",
    "    grads.append(enc_grad.norm(p=2, dim=(1, 2)))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "y = torch.cat(labels)\n",
    "for k, v in enc_layers.items():\n",
    "    X = torch.cat(v)\n",
    "    enc_layers[k] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3126b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.encoder.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ab4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = enc_layers[-1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1748e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Sample 2\n",
      "Sample 3\n",
      "Sample 4\n",
      "Sample 5\n",
      "Sample 6\n",
      "Sample 7\n",
      "Sample 8\n",
      "Sample 9\n",
      "Sample 10\n",
      "Sample 11\n",
      "Sample 12\n",
      "Sample 13\n",
      "Sample 14\n",
      "Sample 15\n",
      "Sample 16\n",
      "Sample 17\n",
      "Sample 18\n"
     ]
    }
   ],
   "source": [
    "from cka import *\n",
    "\n",
    "n = 18\n",
    "\n",
    "lin_vals = np.empty((n, n))\n",
    "rbf_vals = np.empty((n, n))\n",
    "for i in range(100, 1000, 50):\n",
    "    A = X[i:i+50]\n",
    "    print(f\"Sample {i//50 - 1}\")\n",
    "    for j in range(i, 1000, 50):\n",
    "        B = X[j:j+50]\n",
    "        lin = linear_CKA(A, B)\n",
    "        rbf = kernel_CKA(A, B)\n",
    "        i_mod = i // 50 - 2\n",
    "        j_mod = j // 50 - 2\n",
    "        lin_vals[i_mod, j_mod] = lin_vals[j_mod, i_mod] = lin\n",
    "        rbf_vals[i_mod, j_mod] = rbf_vals[j_mod, i_mod] = rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a95f274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(np.flip(rbf_vals, 1), xticklabels=range(1, 18+1), yticklabels=range(18, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c3d2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98248242 0.96114412 0.95121319 0.90460212 0.71041576\n",
      "  0.47315452 0.38221755 0.31722107 0.27903575 0.25892686 0.24506719]\n",
      " [0.98248242 1.         0.99294096 0.98335407 0.95183908 0.75358897\n",
      "  0.50744447 0.41371993 0.34471121 0.30324662 0.28150918 0.26641857]\n",
      " [0.96114412 0.99294096 1.         0.99445655 0.96767089 0.76605118\n",
      "  0.51650029 0.42217762 0.3524165  0.31063183 0.28872567 0.27348558]\n",
      " [0.95121319 0.98335407 0.99445655 1.         0.97601547 0.78270474\n",
      "  0.53881083 0.44590866 0.37730722 0.33579883 0.31386207 0.29857912]\n",
      " [0.90460212 0.95183908 0.96767089 0.97601547 1.         0.86372819\n",
      "  0.64402416 0.55500195 0.48563069 0.44082381 0.41642609 0.39986809]\n",
      " [0.71041576 0.75358897 0.76605118 0.78270474 0.86372819 1.\n",
      "  0.91641715 0.85514805 0.80074403 0.7619774  0.73903904 0.72382307]\n",
      " [0.47315452 0.50744447 0.51650029 0.53881083 0.64402416 0.91641715\n",
      "  1.         0.98668085 0.96352048 0.94102505 0.92561751 0.91487866]\n",
      " [0.38221755 0.41371993 0.42217762 0.44590866 0.55500195 0.85514805\n",
      "  0.98668085 1.         0.99073546 0.97514698 0.96322383 0.95479626]\n",
      " [0.31722107 0.34471121 0.3524165  0.37730722 0.48563069 0.80074403\n",
      "  0.96352048 0.99073546 1.         0.99368034 0.98627515 0.980397  ]\n",
      " [0.27903575 0.30324662 0.31063183 0.33579883 0.44082381 0.7619774\n",
      "  0.94102505 0.97514698 0.99368034 1.         0.99771465 0.99458776]\n",
      " [0.25892686 0.28150918 0.28872567 0.31386207 0.41642609 0.73903904\n",
      "  0.92561751 0.96322383 0.98627515 0.99771465 1.         0.99915245]\n",
      " [0.24506719 0.26641857 0.27348558 0.29857912 0.39986809 0.72382307\n",
      "  0.91487866 0.95479626 0.980397   0.99458776 0.99915245 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(lin_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e25b09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98822128 0.96864577 0.94506764 0.84834738 0.58058964\n",
      "  0.38203942 0.30834932 0.27336096 0.25623951 0.2498741  0.24393084]\n",
      " [0.98822128 1.         0.98886123 0.96045117 0.87905716 0.61475402\n",
      "  0.41201909 0.33673577 0.30072946 0.28261005 0.27595218 0.26954692]\n",
      " [0.96864577 0.98886123 1.         0.9828193  0.90749149 0.63409695\n",
      "  0.42791082 0.35237271 0.31687092 0.29899749 0.29216579 0.28537392]\n",
      " [0.94506764 0.96045117 0.9828193  1.         0.93184827 0.66351566\n",
      "  0.46338771 0.3904026  0.3567184  0.33894004 0.33143854 0.32377679]\n",
      " [0.84834738 0.87905716 0.90749149 0.93184827 1.         0.83521269\n",
      "  0.66546147 0.5968039  0.55941694 0.53621035 0.52402475 0.51286493]\n",
      " [0.58058964 0.61475402 0.63409695 0.66351566 0.83521269 1.\n",
      "  0.94082216 0.89526446 0.86034934 0.83374846 0.81842072 0.80571088]\n",
      " [0.38203942 0.41201909 0.42791082 0.46338771 0.66546147 0.94082216\n",
      "  1.         0.9877828  0.96883966 0.94919752 0.9360177  0.92503854]\n",
      " [0.30834932 0.33673577 0.35237271 0.3904026  0.5968039  0.89526446\n",
      "  0.9877828  1.         0.99094239 0.97567427 0.96464111 0.95507823]\n",
      " [0.27336096 0.30072946 0.31687092 0.3567184  0.55941694 0.86034934\n",
      "  0.96883966 0.99094239 1.         0.99297577 0.98468996 0.97586278]\n",
      " [0.25623951 0.28261005 0.29899749 0.33894004 0.53621035 0.83374846\n",
      "  0.94919752 0.97567427 0.99297577 1.         0.99728635 0.99119932]\n",
      " [0.2498741  0.27595218 0.29216579 0.33143854 0.52402475 0.81842072\n",
      "  0.9360177  0.96464111 0.98468996 0.99728635 1.         0.99753495]\n",
      " [0.24393084 0.26954692 0.28537392 0.32377679 0.51286493 0.80571088\n",
      "  0.92503854 0.95507823 0.97586278 0.99119932 0.99753495 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(lin_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b913a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fda8257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Core set\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "617026dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entropy\n",
    "sns.heatmap(np.flip(lin_vals, 1), xticklabels=range(1, 12+1), yticklabels=range(12, 0, -1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc285785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 1000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"long-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"f1_micro\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=95,\n",
    "    linewidth=3,\n",
    ")\n",
    "g.set_ylim(0.89, 0.98)\n",
    "g.set_xlim(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d25a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `acuraccy` for parameter `y`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1434047/548833310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g = sns.lineplot(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ada-besov\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"labeled\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"acuraccy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sampler\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[0;34m(x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LinePlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m     p = _LinePlotter(\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    365\u001b[0m         )\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/gen/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `acuraccy` for parameter `y`"
     ]
    }
   ],
   "source": [
    "g = sns.lineplot(\n",
    "    data=df_tr[df_tr.index.get_level_values(\"mode\") == \"ada-besov\"],\n",
    "    x=\"labeled\",\n",
    "    y=\"f1_micro\",\n",
    "    hue=\"sampler\",\n",
    "    style=\"sampler\",\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    ci=95,\n",
    "    linewidth=3,\n",
    ")\n",
    "# g.set_ylim(0.82, 0.92)\n",
    "# g.set_xlim(500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44e34a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoAdapterModel, AdapterConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "d = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "\n",
    "def save_dataset(hfd, name):\n",
    "    hfd[\"train\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        5_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/train.csv\", header=False)\n",
    "    hfd[\"test\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        2_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/test.csv\", header=False)\n",
    "    hfd[\"validation\"].to_pandas()[[\"question1\", \"question2\", \"label\"]].sample(\n",
    "        1_000\n",
    "    ).reset_index(drop=True).to_csv(f\"data/{name}/validation.csv\", header=False)\n",
    "\n",
    "\n",
    "save_dataset(d, \"QQP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe182e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoAdapterModel.from_pretrained(\"bert-base-uncased\")\n",
    "a = model.load_adapter(\"adapters/TREC-2-BERT-pfeiffer\")\n",
    "model.add_classification_head(\"head\", num_labels=2)\n",
    "model.add_adapter(\"head\")\n",
    "model.train_adapter(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f14e35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jjukic/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c15a5dfd90473ba1783414b42d727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "d = load_dataset(\"glue\", \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5243de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'the kittens yawned awake and played.', 'label': -1, 'idx': 3}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"test\"][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fee3a0d468748c44cd2b5f7c2d15d26ebb787aed261e84470feedc3724e7bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
